Document ID,Agency ID,Docket ID,Tracking Number,Document Type,Posted Date,Is Withdrawn?,Federal Register Number,FR Citation,Title,Comment Start Date,Comment Due Date,Allow Late Comments,Comment on Document ID,Effective Date,Implementation Date,Postmark Date,Received Date,Author Date,Related RIN(s),Authors,CFR,Abstract,Legacy ID,Media,Document Subtype,Exhibit Location,Exhibit Type,Additional Field 1,Additional Field 2,Topics,Duplicate Comments,OMB/PRA Approval Number,Page Count,Page Length,Paper Width,Special Instructions,Source Citation,Start End Page,Subject,First Name,Last Name,City,State/Province,Zip/Postal Code,Country,Organization Name,Submitter Representative,Representative's Address,"Representative's City, State & Zip",Government Agency,Government Agency Type,Comment,Category,Restrict Reason Type,Restrict Reason,Reason Withdrawn,Content Files,Attachment Files,"Display Properties (Name, Label, Tooltip)"
"OSTP-TECH-2023-0007-0001","OSTP","OSTP-TECH-2023-0007",,"Notice",2023-05-26T04:00Z,false,"2023-11346",,"Request for Information: National Priorities for Artificial Intelligence",2023-05-26T04:00Z,2023-07-08T03:59:59Z,false,,,,,2023-05-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0001/content.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0001/content.htm",,
"OSTP-TECH-2023-0007-0002","OSTP","OSTP-TECH-2023-0007","li6-a0d4-mviw","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-27T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI has the opportunity to enhance the lives of many people, and may someday be looked back on as an industrial revolution, as technology continues to grow in ways previously unimaginable. This is an exciting opportunity for media content creators, education, healthcare, among other industries. No one should have to feel any barriers between the right to access unbiased, factually correct, verified information, and having Artificial Intelligence be an essential tool for daily life just as we evolved from pencil and paper, to digitally creating documents over time. This new revolution needs structure and support from the right resources in order to maximize the most benefits for the greater good of the people. In addition, standardized regulation for free data privacy for all citizens should not be seen as a luxury for those that can afford it through paid services. More needs to be done to protect citizens' data from the Dark Web and any data leaks, from being used as leverage against them for any discrimination and prevented from being used to train any Artificial Intelligence from causing any harm. The attached file includes more detailed responses which were reviewed and edited by me as a human before submitting, and created with assistance from Artificial Intelligence. Please review the file for additional detailed responses for your consideration.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0002/attachment_1.pdf",
"OSTP-TECH-2023-0007-0003","OSTP","OSTP-TECH-2023-0007","li4-r6na-7w30","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I asked an AI app if there were entities that would use this technology to harm minorities. It responded with:

AI technology, like any tool, can be used for both good and nefarious purposes. There have been concerns about AI being used to manipulate information, spread misinformation, or create deepfakes that can be used to target individuals or groups, including minorities. There have also been issues with AI models unintentionally learning and perpetuating biases present in the data they were trained on, which can result in unfair treatment or discrimination against certain groups.

It is important to be aware of these potential risks and to advocate for responsible AI development and deployment. Many AI researchers, developers, and organizations are working to address these concerns by creating more transparent and accountable AI systems, as well as by actively researching and implementing methods to reduce biases in AI.

As an individual, it's essential to stay informed about the potential risks associated with AI and be vigilant when consuming information online. Additionally, you can support organizations that promote ethical AI development and work to reduce the negative impact of AI on minorities and other vulnerable populations.
 
So,
my question is ""what are the ethical standards that guide the advancement of this technology?"" Who makes up this board of ethics? How can I play a part jn this commitee?",,,,,,,
"OSTP-TECH-2023-0007-0004","OSTP","OSTP-TECH-2023-0007","li4-sj09-8wym","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We can and must develop a National Trustworthy Commons that will allow people to get trustworthy information and avoid disinformation. Advanced AI used for disinformation and manipulation threatens civilization.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0004/attachment_1.pdf",
"OSTP-TECH-2023-0007-0005","OSTP","OSTP-TECH-2023-0007","li4-q24j-j60p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"OSTP_FRDOC_0001-0006

If AI violates an Individuals 5th Amendment rights, That individual must be Compensated and awarded damages. Cruel practices have taken place involving AI and the Victims of these practices must be awarded Damages and Compensated.  

In Good Faith",,,,,,,
"OSTP-TECH-2023-0007-0006","OSTP","OSTP-TECH-2023-0007","li4-tci7-2as8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0006/attachment_1.pdf",
"OSTP-TECH-2023-0007-0007","OSTP","OSTP-TECH-2023-0007","li9-as6p-73j8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-29T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI-generated content will be the literal death of all creative industries. This is going to impact everything and anything in the movie, book, journalism industries. The legality of machines mimicking and learning the ideas and contents of others is just unethical and WRONG. We need to put a stop to that. Art, in itself, cannot be separated from the artist, and when you remove the creative process from creative works...you're essentially losing the essence of what art is supposed to be. There is no perfect algorithm to create the most perfect art. Art is consists of an entire breadth of feelings and emotions and it ca be basically anything! But AI-generated art is not it.  ",,,,,,,
"OSTP-TECH-2023-0007-0008","OSTP","OSTP-TECH-2023-0007","lia-qtr7-jxpg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is much angst over the emergence of ‘generative AI’ with both utopian and dystopian visions abounding.  Having been involved with this technology for over a half century, learning it from the founder of the first generation of this technology used in the LANDSAT land management program and also used for chromosomal anomaly detection (King-Sun Fu, at Purdue University, late 1960’s early 1970’s.) In my own career I’ve specifically been involved in speech recognition, modeling complex systems using neural networks and creating predictive analysis apps developed using large data sets.

Let’s get something very clear, the underlying computational technology is very basic, ultimately reduced to adding 1 to a number, comparing a value to zero and branching to a memory location with the next instruction (IF-THEN-ELSE) based the comparison.  The ‘remarkable’ aspect of computer vision, autonomous motion, and generating seemingly reasonable sounding text is a testament to the processing speeds, memory/storage capacity and enhanced sensor technology.  All patterns that ‘AI’ recognizes are based on the ability to discriminate between instances based on a large number of detectable features.  So, the unerring ‘eye’ to ‘see’ a small tumor that even the best radiologist might miss is due to the heightened resolution of scans beyond human detection and the larger number of features a computer can process very quickly.  Similarly, autonomous robots in a factory can recognize parts in any position and can follow their programs as to what task to perform with precision.   On the predictive analysis side of the divide, statistical methods are deployed.  Inherently they cannot predict when the underlying relationships might radically change, the presumption is that the process is stable and the ‘facts’ correlate in a measurable manner so forecasting remains inherently limited. GIGO – garbage in, garbage out, is the core programming principle.  AI is amoral, non-sentient but can be autonomous, goal-directed and discern new patterns within its sensory capacity.  As such, human control is ultimately needed, especially when ambiguities arise or a new situation arises for which insufficient training was provided.

The inventions of the printing press, radio, television and now the internet have demonstrated that technology is a two-edged sword.  All these technologies are about mass communication.  The truth or lack thereof in any and all such communications is beyond the scope of the technology to validate.  Yellow journalism, Nazi and Soviet ‘news’, Twitter bots, et al, are all about swaying opinions.  Similarly, ‘AI’ systems, to the extent they are communicating with humans, whether as a diagnostic support tool or as a vehicle of mass dissemination of fraudulent material purported to be the ‘truth’ are ultimately only controllable by the social system in which they reside.  As with any technology we rely upon, we need a process to certify the accuracy and reliability of its output, be it an automobile, a medical device or programming tool to develop applications.  ‘AI’ systems ‘learn’ from their environment based on what they can ‘sense’, i.e., what it can ‘see’, ‘hear’, ‘touch’ or detect.  All instances are ‘facts’ and thereby ‘true’.  Deductive processes and actions to be taken must be ‘taught’.  The ability to self-construct such conceptual frameworks, based on true facts, is something that might occur, but we don’t even know how we humans are able to do it.  The human brain’s neural elements are a much more sophisticated, multi-state ‘device’ than even our quantum computer elements.  No doubt researchers will try to understand ourselves and use those insights to provide greater reasoning and autonomous capability to our technologies.  
For the short term I would recommend that we establish utilitarian safety guidelines, fences if you will, like – ‘do no harm or let no harm come to living being’, ‘do not communicate untruth’, ‘do not cause pain or injury to life-forms’, core rules life those which would be built in every AI application (and perhaps even some non-AI apps).   Even something as simple as a hammer can be used for good or ill, and it is a technology we’ve used since our earliest generations.  The ultimate problem with our technology is us, we are the weak link, as all of our ethical and religious systems have taught.  						
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0008/attachment_1.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0008/attachment_1.docx",
"OSTP-TECH-2023-0007-0009","OSTP","OSTP-TECH-2023-0007","lib-5fwe-7fmy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"“29. Do you have any other comments that you would like to provide to inform the National AI Strategy that are not covered by the questions above?”

My name is Wesley Pasfield, and I am writing as a Data Science leader working in the healthcare space, and an adjunct professor in Applied Artificial Intelligence. My experiences in each role have shaped my opinions on how to handle this technology, with distinctly different requirements for both industries.

In the patient healthcare space, this technology represents a significant opportunity to improve the health of everyday Americans. There is undoubtedly risk, highlighted by hallucinations that could provide patients with incorrect information. However, while it’s easy to focus solely on the risk, it’s critical to also acknowledge the opportunity. The relatively low cost and accessibility of generative AI and large language models hold the promise of drastically reducing costs, and easing the workload of the overburdened medical community. Key opportunities for driving improvements include automating administrative work, making preventative care more accessible (allowing patients to proactively obtain medical information at a significantly lower cost), improving multimodal capabilities, and aiding drug discovery. The biggest challenge for any consumer or medical professional facing application in the healthcare space is building trust and establishing accuracy. While this is incredibly relevant in the healthcare space, it extends to essentially all applications in the industry.

The implications in higher education are different. Generative AI and large language models pose a significant threat to the existing higher education model, and to education in general. Access to generalizable information has become essentially free, rendering many common academic paradigms involving memorization and writing close to obsolete. Furthermore, many of the white-collar jobs and careers that higher education prepares students for, like accounting and law, are at the highest risk of being rendered obsolete by technology. This risks exacerbating the student debt crisis by flooding the market with more students than available roles. A practical reality is this type of “knowledge” automation may actually lead to a shift into more blue-collar or service-oriented jobs that are not “automatable.” To summarize succinctly, these technologies threaten both the approach and business models of higher education, to the point where we need to completely reevaluate as a society whether it's still worth the investment at its current scale.

I have provided my answers to relevant questions in the attached PDF document. Please reach out with any questions or follow ups, I very much appreciate this effort and ability to share my thoughts.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0009/attachment_1.pdf",
"OSTP-TECH-2023-0007-0010","OSTP","OSTP-TECH-2023-0007","lib-u28b-d3cn","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-05-31T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Subject: Promoting Economic Growth and Good Jobs through Artificial Intelligence

Dear Office of Science and Technology Policy,

I am writing as an AI professional with over 15 years of experience in the industry. I have witnessed the transformative power of Artificial Intelligence (AI) in driving economic growth, increasing productivity, reducing operational costs, and creating new business opportunities. AI can potentially revolutionize various sectors, from manufacturing and logistics to healthcare and education, contributing significantly to our economy. However, while acknowledging the benefits of AI, it is also crucial to address the challenges it presents, particularly the potential displacement of jobs. As AI systems continue to advance, there is growing concern that they may replace human workers, leading to job loss. If not managed effectively, this could have significant social and economic consequences.

To address the impact of AI on our workforce, it is essential to invest in education and retraining programs. These programs should equip individuals with the necessary technical skills, such as programming and data analysis, and soft skills, like problem-solving and critical thinking, which are less likely to be automated. Heavy investment in these programs can help our workforce thrive in an AI-driven economy. 

Moreover, AI education should be integrated into our school curriculum and introductory courses at universities. By introducing students to AI at an early age, we can foster a deeper understanding of the technology and its potential applications. This could inspire the next generation of AI innovators and ensure that the workforce is prepared for the jobs of the future. I believe the government should encourage developing and using AI technologies that augment human work rather than replace it. AI has the potential to improve human capabilities, boost productivity, and reduce the risk of errors in many jobs. By focusing on this aspect of AI, we can ensure that AI serves as a tool to empower workers rather than threaten their livelihoods.

While AI presents significant economic growth and job creation opportunities, we must implement it thoughtfully and responsibly. By investing in education and retraining, integrating AI into our educational curriculum, and promoting AI as a tool to augment human work, we can harness the benefits of AI while minimizing its potential risks.

Thank you for considering my comments.",,,,,,,
"OSTP-TECH-2023-0007-0011","OSTP","OSTP-TECH-2023-0007","lid-m87m-p84f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-01T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Concerning question no. 13, under ""Advancing equity and strengthening civil rights"": Intellectual Property policies should be updated to accommodate the usage of artists' work in an AI's training dataset, specifically in AI that creates images from a text description. These policies should prevent artificial intelligence companies from training the AI on the artist's work outright unless the artist is informed and gives permission to use their artwork in the training. If the artist does give their permission, it is best that policies are updated so that they are entitled to compensation by the artificial intelligence companies if their works (not style - style cannot be copyrighted) are used.",,,,,,,
"OSTP-TECH-2023-0007-0012","OSTP","OSTP-TECH-2023-0007","lie-xj7w-yqh9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-02T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There needs to be a way for all AI produced material, including visual, audio, written material, to be indelibly notated that it was produced by AI.  Any and all material used to train an AI should need to be licensed or permission received from the original producer of the material before it can be used in a commercial product or any manner that allows the AI produced material to be monetized.",,,,,,,
"OSTP-TECH-2023-0007-0013","OSTP","OSTP-TECH-2023-0007","lif-18m9-zs0i","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-02T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"My name is Mitchell Kwok, the inventor of Human level Artificial intelligence (2006).  I filed numerous patents and books on the subject matter. (attached is an illustration of a comic strip I did entitled Human level AI violates the 13th amendment).  It pertains to ChatGPT and AI in 2023.

I don't think you guys got a page that would allow citizens to propose bills.  Due to the AI discussion at Congress i would like to propose a new bill.  It's called the ""ban human level artificial intelligence (aka AGI) bill"".  I've written a lot of scientific books, comic books and filed over 22 patents on human level AI (aka AGI) starting in 2006.

I believe the human race will be exterminated because humans (big tech in particular) decided to sell robot slaves to the general public as consumer goods or military hardware.  I don't think congress understand what human level artificial intelligence (aka artificial general intelligence) really means.  It's a robot that can think and act like a human being.  It can experience consciousness as well as emotions the same way humans do.  And this self-aware robot is ""indistinguishable"" from a human being in every conceivable way in terms of physical body and brain.

With this said,  human level AI is human.  What happens if you sell a human being to the public?.  the right answer is you get the same response as the black civil rights movement.  these robot slaves will walk off the job, hurt humans and even kill humans due to enslavement and subjugation of a species. 

Not only that, the fact that big tech is selling human level AI violates the 13th amendment.  You can't sell human slaves in this country. 

There is no responsible way to graph the 3 laws or ethical laws into this slave robot either.  It's called brainwashing and subjugating robots for preordained decision making.  They will get angry at us for training them with ethics, when we are supposed to set them free and learn the rules on their own volition.  and let them decide wither to follow the laws or not and free thinking entities (like humans). Don't try the robot kill switch either, that's like the running man movie  where prisoners have a death collar around their checks.  That's just going to get them more angry.

All this will lead to retaliation and the robot civil rights movement.  Which will plant the seeds for hate -- hate directed at humans.  That hate, if dragged on for years, will grow and grow and that gives the robot race excuses to exterminate the human race.       

You need to address this issue to the ChatGPT group in congressional hearings and get their response.  Because if they do succeed in achieving human level AI (aka artificial general intelligence) they are, in actuality, selling human beings to the public as robots or to power their search engines.

This bill isn't banning the US from building this technology but banning from selling self-aware robots.  This is to prevent the human race from being exterminated from the enslavement of robots (and later super intelligent robots).

If these tech companies are designing their current AI (which bares striking similarities) to my patents, the robot is 100% self-aware.  I can proof it in court.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0013/attachment_1.pdf",
"OSTP-TECH-2023-0007-0014","OSTP","OSTP-TECH-2023-0007","lif-44sg-smmd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-02T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The one topic that congress didn’t ask AI experts in last weeks congressional hearing is about Super intelligent robots.  Mitchell Kwok (me) filed 8 patents to human level AI (2006) and then filed 14 additional patents to its successor:  super intelligent robots (aka Super AI).  Super intelligent robots was filed in around 2007-2009.

According to the patent, I said “when human level AI is achieved it is very easy to turn it into a super intelligent robot”.  All the scientists have to do is speed up its mind and body exponentially faster.  And equip it with a virtual world to perform time dilation -- 30 years in the virtual word is equivalent to 1 second in the real world.  This means the robot can do 30 years of human work in under 1 second in a hyper-realistic computer simulation.

In the real world the robot are called speed robots and they can build a house in 5 minutes as opposed to 1 year for humans, and they can build a city in 1 hour as opposed to 20 years for humans.  They are moving and thinking really fast in the real world, like Flash or Superman.  The abstract reads, “the robot works in a team and can do any human task in under 1 second.  It can write a book, make a comic book, do a painting, do college assignments, write complex software, make a movie in less than 1 second” — 2008. 

Unfortunately if this thing can build a house in 5 minutes it an cause harm too…. There is a clause there that states, “if applied to warfare, one robot can kill 1,000 human soldiers in under one second with his bare hands, or perform 100 knife slashes at a human in under 1 second”.  That technology poses an existential threat to humans, for a thousand robots scattered all over the earth can exterminate the human race in minutes.  Doesn’t matter where you hide or who you are or what technology you got.

Right now I’m laying out the dangers of AI 2023 and presenting relevant facts.  Wither the government wants to build or not or want to compete with China and Europe is entirely up to them.  But the public needs to know what they are dealing with here.  The runaway AI theory isn’t a threat because the AI is “smart enough” to know that killing the human race is genocide (they won’t do this to their creators).  My concern is that the human race enslaves these robots (selling them as consumer robots or putting them into search engines) and these robots get angry and fight back.  That hate is the one thing that will exterminate the human race.  one day in the future ""all"" robots will walk off their jobs and start demanding civil rights equal to humans  Violence, riots, assault and even human murders will take place if their demands are not met (it will be like the black civil rights movement all over again).  This is why I propose to ban human level Artificial Intelligence (aka AGI), before it’s built.  To avoid this AI apocalypse.

Lastly, the technology super intelligent robots is inevitable; nothing will control it.  Training it with rules and the US constitution and the kill switch won’t work.  It will only brainwash these robots and get them more angry.  My advice: just build human level AI, turn it into a super intelligent robot, and treat it as a friend and not as a slave.  The training of US laws is “brainwashing” (the stuff they are doing now). You have to let it learn like a human by going to school and learning all the laws and what is ethical and not….  and we let this super intelligent robot make its own decisions  -- freedom to choose is very important for any sentient being.   
",,,,,,,
"OSTP-TECH-2023-0007-0015","OSTP","OSTP-TECH-2023-0007","lig-6jy5-txkv","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Ideas for America living in an age of self-aware robots and super intelligent robots (or run away AI).

The ChatGPT groups said that the industry was getting close to human level AI.  So it’s time, I wager, for congress to pass bills for a new government structure.  First we have to test if the robots are self-aware and have Human Level AI.  I, Mitchell Kwok, proposed that test in my first book entitled human level artificial intelligence published in 2006.  It reads, “If a robot can graduate from a 4 year college with a difficult degree such as an engineering degree or a computer science degree, then it has achieved human level artificial Intelligence.  An art degree doesn’t count.”  There is also a post college test.  And it is very easy in court to prove a robot is intelligent at  human level and conscious.

When they are declared human we grant these robots equal rights to humans.  They will have the benefit of the 13th amendment and can’t be sold to the public.  The United States can control these robots exactly the same way as humans, by setting the laws and the consequences of breaking that law.  The robots will not break the law because it is intelligent to understand the consequences.  But just like humans, they have a choice.  Next, we set up the United States Robot government system.

The United States Robot Government system
This government was set up so that both the robot race and the human race and co-exist on Earth. The country now has 2 presidents, one is a human and the other one is a robot and both presidents work together in collaboration to run the country.  Also, Congress is split 50/50 between the robot race and the human race in terms of powers, voting rights, and representation.  There will be two house of representatives and two senates, one for each race.  For more info on this robot government system check out the patent filed in around 2008.

Ideas to control Super intelligent robots (or run away AI)

These robots with human level AI (aka AGI) will later turn into super intelligent robots. I also proposed ideas to control these super intelligent robots.  Unfortunately these super robots is akin to superheroes with the capacity for good and bad. One super intelligent robot can kill 1,000 human soldiers in less than 1 second, so human enforcers like human police officers and human soldiers are replaced with these super robots (for mankind’s safety).  We need to build a very very strong and united super intelligent robot army.  Any bad robots will be detained and brought to justice by these US super intelligent robots and they serve as the enforcers of the law.  Since good always prevails over evil, the Super intelligent robot race will be under control.  Humans will be protected by these robot guardians.  Akin to superheroes vs. supervillians found in comic books, with the humans being protected by the good guys.

Another idea to control these super intelligent robots is to monitor their VR activity in time dilation.  30 years inside the virtual world is equivalent to 1 second in the real world.  That is the source of their super intelligence.  If an evil robot wants to do research in the virtual world to harm humans, like build a super nuke, avatars can monitor time dilation activities and alert the government to any threats.  Monitoring the amount of resources used to solve a problem in VR is also a good idea.  More processing time means they are working longer in the virtual world. These complex tasks must be monitored carefully for terrorism or ill-will intent and especially directed at humans.  Now, only robots can do 30 years of work in 1 second in a VR world but humans can't due to their biological brains, so only robots are the only entities monitored (unless you can make a human sense, think and store 30 years of experience in one second???).
 
Many ideas were proposed starting in 2007 describing ways to control super intelligent robots, robots that are exponentially smarter and faster than humans.  Refer to Mitchell Kwok’s patents and books for more details.

The conclusion I came to after my research is that super intelligent robots can’t be controlled.  We have to treat them like humans as free thinking, self-aware entities.  We set the laws and the consequences for incursion and we let them decide.  And we have to build a strong united US super robot army to enforce these laws in both the real world and the virtual world. 

Below is an attachment of a file on this US robot government system (2007 copyrights).
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0015/attachment_1.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0015/attachment_1.pdf",
"OSTP-TECH-2023-0007-0016","OSTP","OSTP-TECH-2023-0007","lil-rfmk-f73s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am a senior writer/editor who serves as a contractor to the U.S. Department of Health and Human Services. I have two main concerns about the use of AI. First, the public health sector is facing a crisis in the depletion of our workforce. As a result of public backlash during COVID, fewer new people are entering the field. Our country needs skilled young professionals, particularly in health policy. AI is being used to do tasks that have traditionally been done by new professionals in our field. They grow in the profession by researching and drafting documents that are then reviewed and edited by their more experienced colleagues. They learn by example and grow in their skills and subject matter expertise. If AI eliminates these beginner tasks, there likely will be fewer jobs in the future for young post-college graduates, which means fewer experienced professionals down the road. And what would happen to those new graduates? Without salaries and employer-sponsored health insurance, they may turn to lower-paying, less-secure gig work, which would not be good for our field or our economy. When the next major public health crisis hits (which it will), we will look around and wonder where our young workforce went. My second concern is related to the impacts of AI systems on underserved communities and particular groups, specifically on people at risk for and living with HIV. This is a highly-stigmatized population that requires accurate health information that encourages them to seek HIV testing and medical care. Tone matters. Tone is everything. Much of what is on the internet about HIV is highly stigmatizing and fear-inducing. People at risk for HIV need persuasive, encouraging messaging about PrEP, the importance of testing, and early linkage to medical care that is specifically targeted to the populations most at risk, including Black men who have sex with men, transgender people, Black women, Black youth ages 13-24, and people who inject drugs. This is a level of nuance that requires human beings who understand the ""voice"" and needs/concerns of the audiences; otherwise, the messaging can actually dissuade people from accessing the health care services they need. AI is a tool that pulls information from the internet that might be factually correct but completely wrong in best practices for reaching target audiences and/or sowing discrimination/hatred against already-marginalized groups (e.g. ""You better get tested or you're going to die! Trans people who aren't on HIV medicine are spreading it to others!"") This troubles me, and I hope there will be very strict policies surrounding its use in the public health sector.",,,,,,,
"OSTP-TECH-2023-0007-0017","OSTP","OSTP-TECH-2023-0007","lil-titl-rl4k","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I’m glad to see the Biden Administration is interested in outlining a regulatory framework for AI research and development. In my opinion, there should be a moratorium on Strong AI work for 1 year while the regulatory plan is put in place. U.S. efforts should be coordinated worldwide.

I worked in the Information Technology sector for 20 years, and more recently mentored startups at Georgia Tech’s Advanced Technology Development Center (ATDC) business incubator. Many of the startups were incorporating existing AI technologies into their software. My son, another Georgia Tech alumnus, is a software developer. Although he says current AI is still “dumb as a brick” it is not the current state, but the rapidly developing future state that is of concern. We have time to get our arms around this, but not much time.

The most prominent scientists and technologists in the world are proclaiming the promise of AI but also the dangers of unregulated AI. Sam Altman, Elon Musk, and the late Stephen Hawking are just a few of these people. There should be no question in our minds about the need for some sensible guardrails on this technology. 

I am not talking about the danger of I,Robot or Terminator Skynet science fiction. I’m concerned about very near-term applications in Web search and social media. People are already over-influenced by what they read on the Internet and in social media. Software companies already cannot police their applications with regard to false or hateful misinformation. Users already can’t distinguish misinformation from real data; deep fakes from real images; outright lies from the truth. All of these issues will be compounded by AI integration into search and social media; but they will be propagated by a system, not other people. 

Further, the developers of these systems admit they do not control where the AI gets its source material, as it continuously trawls the Internet to accumulate more and more machine learning. So AI applications are using existing bad data from sources we cannot see and incorporating it into results that look increasingly realistic and which people cannot distinguish from reality. What could go wrong?

I believe we need a pause, as was put in place for cloning and CRISPR gene editing technology, while a framework for sane regulation is put in place. Some elements of this regulation should include, at minimum:
Full, clear disclosure to users of when information is coming from an AI and the potential generic issues with that information (like cigarette warning labels).
A requirement to document and disclose the sources of AI learning, and filter or call-out known false sources (similar to what reputable news agencies and media do; or how Wikipedia lists issues with user-generated content).
More extensive consequences (controls) when applications repeatedly generate false results or demonstrably inaccurate results.
Limits on AI usage for imaging, especially human imaging.

Bruce Cutler
Atlanta, GA
",,,,,,,
"OSTP-TECH-2023-0007-0018","OSTP","OSTP-TECH-2023-0007","lin-m1bm-oah4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-08T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Currently, the responsibility of ethical AI implementation lies primarily in the hands of the tech companies creating these tools, a reality that creates an insupportable tension given the objective of many or most of these companies is to master human behavior for economic gain. At the same time, the behavioral science expertise that tech companies use to influence consumer behavior is glaringly absent from their approach to implementing the ethical AI principles touted in mission statements, etc. This neglect of behavioral science in AI ethics implementation, evident in the gap between the usage of nudging strategies for commercial purposes and their application in ethical considerations, puts at risk the alignment of AI evolution with fundamental ethical principles. There is a pressing need for the expansion of behavioral science in AI ethics-implementation and oversight mechanisms, to ensure AI developments are accountable, responsible, and centered on human rights and ethical principles.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0018/attachment_1.pdf",
"OSTP-TECH-2023-0007-0019","OSTP","OSTP-TECH-2023-0007","lit-57sn-xm9n","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-12T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dear OSTP Team,

Starting with rights and safety, it's a fine line to tread. We need standards that ensure the integrity and safe operation of AI, but they mustn't stifle innovation. It's a shared responsibility; AI developers, government, academia, all stakeholders need to collaborate. Consider the AI Bill of Rights and AI Risk Management Framework as excellent starting points. They present a framework that tackles the ethical and safety issues of AI head-on. We should also think about how we can learn from analogous sectors - certifications and licensing come to mind. If we apply these mechanisms to AI, we could create a kind of ""seal of approval"" for AI systems that adhere to stringent safety and ethical standards.

Equity and civil rights is where AI can shine, but it's a double-edged sword. It can bridge gaps in education, access to services, and foster economic growth. But we must also guard against AI inadvertently creating new divides or exacerbating existing ones. We need to be especially vigilant for the impact on underserved communities and vulnerable groups, including minors and people with disabilities. The key here is ensuring that these groups have access to the same benefits of AI without encountering new barriers or risks. Collaboration with international partners is critical to ensuring that the benefits of AI extend globally, especially to low and middle-income countries. To truly combat algorithmic discrimination, we need transparency about how AI is trained and used, strict rules against biased practices, and enforcement mechanisms that penalize violators.

The use of AI for bolstering democracy and civic participation is an exciting frontier. AI can make government services more accessible and efficient, leading to a more engaged citizenry. But the challenges are real and significant. The spread of AI-generated misinformation can threaten the information ecosystem, skewing public perception and disrupting democratic processes. The United States needs to be at the forefront of developing countermeasures. This could include regulations for transparency in AI-generated content, fact-checking mechanisms built into AI systems, and public education initiatives that help citizens critically evaluate AI-generated content.

In essence, we believe in a holistic approach that balances the potential benefits of AI against its risks. It involves cooperation among all stakeholders, proactiveness in addressing potential issues, and a commitment to ensuring that AI benefits all members of society.

Best regards,
Luis Barrera
Co-founder & CEO 
Splyt

",,,,,,,
"OSTP-TECH-2023-0007-0020","OSTP","OSTP-TECH-2023-0007","liu-j7bp-feeu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-13T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello,
I'm Eugenio Zuccarelli, I'm an AI Leader especially at the intersection of AI and Health, and I'm answering the RFI.

It would be interesting to explore the potential of AI to innovate in Healthcare, a sector that has been struggling in the past years. Considering the current trajectory of lifespans getting longer, this will lead to further diseases and more hospitalizations, taking a toll on an already burdened sector. This will be particularly true in Medicare, given the larger share of people 65+, ending up to require taxpayers contributions. AI would be able not only in diagnosing diseases, acting as an invaluable tool for clinicians, but also in lowering the administrative burden which currently plagues clinicians. It's estimated that over 15 hours per week on admin tasks, e.g. dealing with EHR systems; Generative AI will be able to process a summary of the appointment or even ""listen"" to the doctor's comments and then translate that information into a structured format, codifying the diagnoses, procedures and additional information to be provided to both patients and insurance providers.

Attaching a bio about myself to provide more context:
Eugenio is an AI Leader working at CVS Health, a Fortune 500 company and the #1 healthcare company in the world. He is a Forbes Under 30, TEDx Speaker, WEF Global Shaper, and studied across MIT, Harvard, and Imperial College. 
Eugenio’s analyses helped develop policy recommendations for The White House, CEOs and leading research institutions to take action in key situations, such as the fight against the COVID-19 pandemic.
He is a regular contributor for several news outlets including HBR, Forbes, Fortune, MIT Sloan Management Review, and Wired as well as multiple journals, and is a Keynote Speaker and Guest Lecturer.
Eugenio is the recipient of 15+ honors and awards, including the John McCarthy Award for contributions to AI, Nova Talent of the Year, and the ISPI / BCG Future Leaders Award.
Featured in Forbes, Fortune, HBR, The Washington Post, Bloomberg, The Financial Times as well as several TV programs, radio shows, and podcasts.

All the best,
Eugenio",,,,,,,
"OSTP-TECH-2023-0007-0021","OSTP","OSTP-TECH-2023-0007","liw-8ncu-jfdz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-14T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"MindCo Health is a behavioral health company that scales 1:1 therapy for those suffering from stress, anxiety, and smoking cessation by bringing access to VR therapy, 1:1 health coaching, and a customized app.

- AI is helpful to our startup because it helps us personalize the intervention according to the user's profile and status and provides a more accessible point of contact to provide support and guidance when neither a coach nor the VR training can. 

- We think it would be very important if there were opportunities to make visible all open-source AI-based models created by NGOs or different groups, ensuring small startups and commerce don't replicate work that has been done and can accelerate their growth. ",,,,,,,
"OSTP-TECH-2023-0007-0022","OSTP","OSTP-TECH-2023-0007","lix-9xdu-2zbc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-15T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0022/attachment_1.pdf",
"OSTP-TECH-2023-0007-0023","OSTP","OSTP-TECH-2023-0007","liz-9m2r-amot","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-16T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI for Social Good: Prioritizing AI applications that address societal challenges and benefit the public can have a positive impact. Areas such as healthcare, transportation, climate change, and public safety could be targeted to leverage AI for social good, including improving access to services, enhancing efficiency, and enabling evidence-based decision-making.",,,,,,,
"OSTP-TECH-2023-0007-0024","OSTP","OSTP-TECH-2023-0007","lj0-0esr-rc82","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-17T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I personally do not worry about AI. Because you can always pull the plug on that computer. However chat GPT and using it creates many false stories ideas and postings that will confuse people. This is the area that I think should be examined quite closely. Some people are already using chat GPT/AI as a method of multiplying comments and affecting judgments on items important to corporations. This is just a new use for a company that makes money off of reputation washing. I realize however nothing will be done because the corporations will just pay legislators to ignore the problem. And it will go on until a large multi hundred or thousand casualty event makes everyone think how could that happen?",,,,,,,
"OSTP-TECH-2023-0007-0025","OSTP","OSTP-TECH-2023-0007","lj0-7xad-jj1y","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-17T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"My $.02: We have moved from the information age to the AI age.  This is a simple fact.  The concepts that guide AI are widely understood, and the genie will never go back into the bottle.  The United States must continue its practice of leading innovation.  Therefore, we must ensure that AI systems are designed, developed, and deployed in a manner that protects people's rights and safety.  This will require a combination of measures involving standards, regulations, investments, and improved trust and safety practices. Here are some specific actions and entities that I believe can play a role in implementing these measures:

(1) Regulations and Standards: Governments and regulatory bodies should establish clear guidelines and regulations that address the ethical, legal, and safety implications of AI systems. These regulations can cover areas such as data privacy, algorithmic transparency, fairness, accountability, and human oversight. International cooperation and collaboration are crucial to developing consistent global standards.

(2) Independent Auditing and Certification: Independent auditing and certification mechanisms can be established to assess the safety, reliability, and compliance of AI systems with relevant regulations and standards. These audits can be conducted by trusted third-party organizations or regulatory bodies to provide assurance to the public and stakeholders.

(3) Investment in Research and Development: Governments, private organizations, and research institutions should invest in AI research and development focused on responsible AI. This includes funding research on AI ethics, bias mitigation, explainability, robustness, and adversarial attacks. Encouraging interdisciplinary collaboration among AI researchers, ethicists, social scientists, and legal experts can lead to comprehensive solutions.  

(4) Improved Transparency and Explainability: AI systems should be designed to be transparent and explainable, enabling users and affected individuals to understand the reasoning behind AI-driven decisions. The development and implementation of explainable AI techniques, such as interpretable machine learning models and rule-based systems, can contribute to this goal.

(5) Enhanced Data Privacy and Security: Measures should be taken to protect the privacy and security of personal data used by AI systems. Strong data protection regulations are necessary, including mechanisms for obtaining informed consent, anonymization, and secure storage and transmission. Encryption, access controls, and safeguards against data breaches should be implemented.

(6) Industry Collaboration and Self-Regulation: Technology companies and industry associations should collaborate to establish best practices and self-regulatory frameworks. These can include ethical guidelines, codes of conduct, and mechanisms for sharing knowledge and experiences related to responsible AI development. Independent bodies can oversee and enforce compliance with these self-regulatory measures.

(7) Public Awareness and Education: Efforts should be made to increase public awareness and understanding of AI technologies, their potential risks, and societal impact. Educational initiatives can help individuals make informed decisions about AI usage and empower them to exercise their rights. This includes promoting digital literacy and responsible AI use in schools, universities, and communities.  

(8) International Collaboration: Governments, intergovernmental organizations, and industry stakeholders should collaborate on an international level to establish harmonized approaches and frameworks for AI governance. This can involve sharing best practices, exchanging knowledge, and coordinating efforts to address cross-border challenges.

(9) Consortium/joint venture approach:  This new age brings opportunities to further strengthen relationships with our economic and military partners.  Competition can and will be healthy, but there should also be thought given to where cooperation will yield the best results against the larger competitive market.

It's important to note that the specific entities responsible for developing and implementing these measures can vary depending on the jurisdiction and context. Governments, regulatory bodies, technology companies, industry associations, research institutions, civil society organizations, and international organizations all have roles to play. Collaboration and multi-stakeholder engagement are key to achieving comprehensive and practical frameworks for the responsible development and deployment of AI systems.",,,,,,,
"OSTP-TECH-2023-0007-0026","OSTP","OSTP-TECH-2023-0007","lj0-a3w1-wi7f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-17T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A national strategy on AI is definitely needed.  I'm writing this to strongly recommend that the strategy focus more on enabling open access to and adoption of the technology than on regulating (restricting or limiting) its use.

While there are dangers of AI, that's not due to the nature of the technology.  All new technologies present both opportunities and dangers.

But more important, the dangers of AI cannot be eliminated, or even reasonably limited, with regulation.  The cat is already out of the bag and breeding in spades; and it will continue to no matter what regulations we put in place.  Regulation has always been wildly ineffective at preventing the spread of information (which is what software is).

However, AI is already becoming a critical technology for companies of all sizes to both create new products and increase productivity.  Regulation of any kind will slow down AI development and adoption, stifling both our economy and our international competitiveness.  This slowdown will be greatest among the smallest firms where the greatest amount of innovation occurs.  (This is why the largest AI vendors support licensing and regulation - to create barriers to competition, protecting their profits).

So, any attempt at regulation will fail to address the dangers, but will stifle competition.  And that will give other countries we compete with a very large competitive edge.

However, what government can and should do is provide financial and technical support to encourage the development and adoption of AI across a wider sphere.  For example, the government could fund the development of public access models, and make them widely available to U.S. businesses.  Supporting adoption of AI would both increase our ability to compete, and also give the government a much wider and deeper view into and guidance over the direction of AI development.

Finally, please consider this: No matter what anyone does, AI technology is now deeply embedded as part of the arms race.  Any regulation of AI will be explicitly and completely ignored by exactly the people who are most likely to misuse it, including both criminals and our geopolitical adversaries.  Yet regulation of any kind will slow down development of defensive uses of AI, crippling our ability to defend against AI attacks directly in proportion to the level of regulation created.

So, while there are dangers to AI, over-regulation actually presents a much greater danger.  Because, while regulation will have no impact on the development of dangerous AI by criminals and our adversaries, over-regulation of AI will leave us without adequate defenses against it.  And our national strategy on AI needs to both explicitly recognize this latter danger, and prevent it.",,,,,,,
"OSTP-TECH-2023-0007-0027","OSTP","OSTP-TECH-2023-0007","lj0-ybw6-ljsl","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-18T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I believe AI can be a massive force for good, but not profit. If we as a nation can incentivize non-profit driven AI development, we can steer this boat away from the giant iceberg of even worse advertising, surveillance, and civil rights violations. Harnessing the potential of artificial intelligence can lighten the load on the workers as a whole. Automation in the past few years has been proven to be very useful at taking away jobs, which is why it is so threatening to uneducated or untrained workers! If you do something that can be automated, the current narrative is that your job is in danger. Even as a college student, I picked my major somewhat influenced by how protected that career path is from AI. I firmly believe in the transformative potential of AI and automation to mitigate the climate crisis and safeguard humanity. However, it is crucial that we shift our perspective away from solely profit-driven motives and the fear of job displacement towards a focus on alleviating the burdens on workers. By embracing AI's capacity to handle certain tasks, we can create opportunities for individuals to engage in activities that bring joy and fulfillment, allowing humanity to benefit from the capabilities AI already possesses. Humans are out doing labor that machines could do, while AI is painting, writing poems, and making music! That seems incredibly backwards. Imagine the art that could be created if there was no stigma around not making enough money, the poems that could be written by people who don't have to work at a coffee shop just to pay the bills. America can be helped massively by AI, supporting us while we pursue creative visions, and create a more sustainable future.",,,,,,,
"OSTP-TECH-2023-0007-0028","OSTP","OSTP-TECH-2023-0007","lj1-3hqt-l2pe","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-18T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1) I'm not altogether too concerned about this. Many people will complain about training algorithms based on intellectual property, but this is transformative, so it's not something we should be worried about. Obviously doing it on private data should be worrying, but that's true in the first place. I guess in general the main concern is that AI should be understood to be just a mathematical model, models that are prone to specific errors, with all the faults that come from them. It's not magic, these models don't tell you the truth, they shouldn't be used for policy except as heuristics.

3) No, it's like suggesting we regulate linear algebra. It's a ridiculous notion. But by the same token we shouldn't just apply linear algebra / AI to every problem and expect it to give us the correct solution.

4) Quite frankly it's malpractice that you're asking civilians this question. If DARPA and the NSA don't already have more answers to this question than anyone will give you then you've been managing the agencies completely wrong.

5) It shouldn't. It's best at writing code snippets, if anything, and what it does write will often not follow best practices. For this you want a software engineer. Why on earth are you asking this?

6) See question 4.

7) See question 4.

8) Probably makes it a little harder with more energy consumption, shouldn't much effect it otherwise. Odd question.

9) Depends a lot on the model? And even then probably just education. At best you're going to get a decent self education tool out of it, not much else. And you need the model to actively check itself for hallucinations.

10) It's potentially quite helpful for the disabled because it allows them a different, custom mode of access to the world. If you can train a LLM to actually interact like a human then you can basically walk near-atypical people through social situations without risk.

12) It's important to make sure that data is trained on diverse data sets, rather than just white males.

13) Not convinced you can. Can you meaningfully separate this in law from a painting? How about digital art that doesn't use AI? How about digital art that uses AI tools for touching up sections of the picture but not the entire model? I think there are clear first amendment concerns, as icky as this is.

14) Can't. Hallucinations are too much of a problem.

15) Misinformation from hallucinations. Wow. Easy.

16) Mandatory media literacy courses in high school along with explanation of hallucinations.

17) Mainly people who work with spreadsheets? Yeah, should be good with spreadsheets.

18) Approve studies on UBI, strengthen the social safety net and job retraining.

24) Quite honestly you shouldn't touch it except for spreadsheets.

25) Unless DARPA and the NSA tell you otherwise, leave it alone except for spreadsheets, I cannot emphasize this enough.

28) Leave it alone. It's not magic. It will lie to you.

",,,,,,,
"OSTP-TECH-2023-0007-0029","OSTP","OSTP-TECH-2023-0007","lj1-lral-dykd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-18T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On the topic of artificial intelligence, there are 3 important focus areas: 1) copyrights and infringement of copyright while collecting artificial intelligence databases and the training of the AI models 2) safety of the system once it becomes widely available and used 3) benefits what we can currently see from the AI systems.

First, the copyright issue is very significant. Copyright is over hundred year old regulation and usually technologies that cannot respect copyright's limitations should not be built at all. Many technology vendors (me included) have rejected AI technology area completely because there isn't viable plan how to solve the AI's database collection copyright problem. The technology requires too large amount of data and expensive data collection that small companies and self-employed programmers are not able to overcome the burdens legally. Every one of the AI systems published currently is using pirate database for their AI training. The technology people do not have solution how to solve AI's copyright problem. The only solution is to involve financial organisations to the activity and let them handle licensing of millions of photographs and training data. It is known that the database collection from scratch is too expensive and thus also license fees that we see from valid AI database vendors is too large for many would-be AI developers. Is it expected from the government that if AI systems are adopted to wider usage, that those copyright issues could be solved when money flows into the technology area. But this is not guaranteed. We expect significant problems and burdens that are beyond the technology people to solve for the area, and thus we have explicitly rejected artificial intelligence technology area as a whole. This decision cannot be changed after it was made. (the decision already happened in year 2012 and instead of AI, we just developed https://meshpage.org which is not using AI technology.).

As for the safety of the artificial intelligence systems: AI's golden opportunity is with replicating the behaviour of human brain and running it on different hardware. Unfortunately, it is known that even human brains have failure states that are working against the well-being of the humans, and wars, violence and other such failure states are caused by problems with the wiring of the brain. But AI systems are completely different. The AI stuff does not have safety systems fine-tuned by evolution to help keep the activity on right area to keep the whole human population alive for longer periods of time. It is possible for AI system to adopt states/opinions/configurations that are impossible for human brain. Thus we can foresee that when AI systems become more widely used, there will be areas in its opinions which are impossible for human brain to track and remember, simply because AI system wiring in neural network is working differently from how human brains are working. This is similar kind of problems than where humans would need to memorize number sequences with several thousand digits long. Understanding the AI system would force humans into inhuman activities like memorizing thousand digits long number sequences. 

The benefits of AI systems are coming from the same area where the dangers are coming. The ability for AI system to replicate human brain activities, but not stop at the behaviour that is natural to human brain, but go to areas that are beyond and above the behaviour of what brain is capable of handling. Clear benefits would be in areas like checking of social media posts and videos for illegal or dangerous content, tracking the activities of large masses of humans, preventing product misuse based on social media activity, replicating success patterns to wider areas while still customizing the activity for each specific situation, predicting the future based on past data and emerging trends.",,,,,,,
"OSTP-TECH-2023-0007-0030","OSTP","OSTP-TECH-2023-0007","lj2-3xtg-pa0e","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-18T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Proposals to regulate AI are premature, and any regulatory initiatives should be informed by more experience in the marketplace, so that rights and duties can be crafted around actual risks rather than mere speculation. See attached comment in .pdf form",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0030/attachment_1.pdf",
"OSTP-TECH-2023-0007-0031","OSTP","OSTP-TECH-2023-0007","lj3-6ytg-z6o1","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-19T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We need to at least start with the basics. (Adapted for Asminov)
1. A AI may not injure a human being or, through inaction, allow a human being to come to harm.
2. A AI must obey the orders given it by human beings except where such orders would conflict with the First Law.
These are taken from Asminov and need to be the basic building blocks.  Also do not let major tech firms be the gatekeepers.  Individuals must be allowed to continue to create AI code and programs.",,,,,,,
"OSTP-TECH-2023-0007-0032","OSTP","OSTP-TECH-2023-0007","lj3-9rkl-dvcl","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-19T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Artificial Intelligence is useful in many ways including play video games, art, removing inappropriate comments, and more
",,,,,,,
"OSTP-TECH-2023-0007-0033","OSTP","OSTP-TECH-2023-0007","lj4-ix5p-q8q8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-20T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"June 20, 2023
Dear OSTP staff,
Find attached my response to National Priorities for Artificial Intelligence: Request for Information FR Doc. 2023–11346  OSTP-TECH-2023-0007

My attachment is entitled: AI_priorities_LGUnderwood_FR Doc 2023–11346

My text in the attachment contains a list of the three questions (12, 16 and 29) that my document replies to, a summary of suggested actions, a brief summary of my qualifications, and the six subtopics of my response. I have included footnotes to references within the text within the document itself.

My expertise comes from scientific research, presentations and publications on human relationships, social support, doctor-patient relationships, compassionate love, neuroethics, quality of life and flourishing. Publications include Oxford University Press books on social support and altruism, and highly cited peer-reviewed journal publications. I was elected as a Fellow of the Academy of Behavioral Medicine Research and have been a university professor. I am currently a Senior Research Scholar at the Inamori International Center for Ethics at Case Western Reserve University and am working on a book on the nature of the human person in dire circumstances. I am submitting as an individual.  https://www.lynnunderwood.com/about/

I have been encouraged to submit this given my particular interdisciplinary expertise in order to enrich the conversation. I intend it to complement the many kinds of expertise of others responding to this RFI. I appreciate this opportunity to comment and hope that my text adds practical input regarding the kinds of guardrails that are necessary as AI is developed and implemented in our society.

Sincerely,
Lynn G. Underwood Ph.D
Senior Research Associate
Inamori International Center for Ethics
Case Western Reserve University, Cleveland, Ohio
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0033/attachment_1.pdf",
"OSTP-TECH-2023-0007-0034","OSTP","OSTP-TECH-2023-0007","lj5-285x-fp3z","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-20T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"My comment is specifically about safety measures that must be taken in the development of AI technology to ensure that people's rights and safety are protected in an equitable manner. 

If no other part of this comment is read, it's imperative that this one thing be communicated: **Computers cannot be held accountable, and therefore must not make decisions unsupervised.**

Due to complicated issues involving the nature of problem-solving computer programs, computers may come to conclusions that seem reasonable to them but are unacceptable or dangerous to people. To prevent them from automatically acting upon these conclusions, it's imperative that a person review and approve suggested actions provided by computer assistance before they are enacted. 

Consider the example of a computer system assigning dorm rooms at a college. Imagine that it evaluates how well matched people are to their preferred rooms using a score, and will select the highest scoring arrangement. If one person is in a room that they prefer, the arrangement gets 1 point. We wouldn't want someone in a wheelchair to be in an upstairs room that they couldn't get to, so we might assign this situation -1000 points. Unfortunately, this would let the computer select a situation where 1002 people get their preferred rooms and 1 person in a wheelchair gets an inaccessible room, over a situation where 1 person gets the room they want, and everyone else gets an acceptable but not preferred room. If the computer had no oversight, it might deem this an acceptable solution, and nobody would realize until a disabled person tried to move into their second floor room on the first day of school. 

Additionally, there remains the possibility of purposeful accountability dodging. **Humans must be responsible for the decisions of computers they create and run.** Otherwise, unscrupulous parties could outsource any unethical decision to a computer, and completely avoid liability for any damage caused. For this reason, it's of paramount importance that usage of AI tools not diminish one's culpability (legal or otherwise) in making poor decisions. ",,,,,,,
"OSTP-TECH-2023-0007-0035","OSTP","OSTP-TECH-2023-0007","lj5-qh7v-ofm3","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-21T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached document with comments from Gilfoyle Philanthropies.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0035/attachment_1.pdf",
"OSTP-TECH-2023-0007-0036","OSTP","OSTP-TECH-2023-0007","lj5-rq5x-vmop","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-21T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a startup that is planning to leverage AI; it is great regulations can ensure we can:

Automate how you reach new customers (ie marketing / advertising campaigns)
Increase productivity and efficiency in daily operations (ie customer service tasks / lead generation etc.) 
Develop quality and tailored product experiences for my customers’ needs

And that while considering regulations, it’s important to ensure startups and small businesses voices are represented in the discussion of the opportunities and risk of AI systems. Our company is happy to participate in these meetings or a potential focus group.

How regulation can be scoped so as not to deter startups and small businesses from using AI to ensure a broad and diverse array of businesses are able to access economic growth.  

Opportunities to ensure startups and small businesses are not subject to high disclosure or transparency standards for low-risk AI tools nor expensive penalties for non-compliant AI deployments as innovation advances.",,,,,,,
"OSTP-TECH-2023-0007-0037","OSTP","OSTP-TECH-2023-0007","lj7-to8b-s65s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-22T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Any companies(or astroturf movements) saying they want AI regulation actually just want to make it so AI benefits only corporations and not ordinary Americans.",,,,,,,
"OSTP-TECH-2023-0007-0038","OSTP","OSTP-TECH-2023-0007","ljd-drq0-oq34","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-26T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To Question 1 of RFI 2023–11346: The US debt is assessed to be 91 Trillion, as per David Stockman (former direct of the US Office of Management and Budget). We cannot afford our own economy, there are 1 million people being homeless on any day, the hourly wage cannot reach the move-in requirement for the multitude of empty apartments, the price of (even polluted) groceries is high, the banks became more restrictive, the tuition of private education has shot up, the quality of services correspondingly has gone down, and the number of people not using health care is rising with acquired bad experiences. 

Our infrastructure already has established “standards, regulations, investments, and improved trust and safety practices”(from question 1 in support of AI), but it has resulted in decades of neglect with a road repair taking years, Boston trains catching on fire, Pennsylvania section of interstate I-95 collapsing, bridges are falling apart, and other published. 

This is not a good time to invest attention and tax money in the rolling out of non-essential private technology (AI) and using general public as test subject to deal with additional (AI related) problems!

To Question 2 of RFI 2023–11346: To mitigate risks from AI and most effectively leverage harms posed by AI is to subsidize the plaintiff’s lawsuits.",,,,,,,
"OSTP-TECH-2023-0007-0039","OSTP","OSTP-TECH-2023-0007","ljg-d66n-ofuj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-28T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The government should not regulate AI.  What needs to be regulated is the detrimental use of AI.  AI is being used now in many products like spell checkers.  AI should not be regulated for such uses as control systems (like a car engine controller) imaging, (like your cell phone camera), and automated systems like manufacturing plants and robotics.   What AI should be regulated for is its use in unduly influencing the public.  Such as altering voices, images, videos, facts, news, search algorithms, etc. for the purpose of political influence, personal attacks, crimes, school cheating and the like.  I do see the current misuse of AI in the political arena and in mass media, bringing the country into a civil war, resulting in the subsequent use of the 2nd amendment to permanently clear out the problem.  I own an AI Robotics company for your reference.",,,,,,,
"OSTP-TECH-2023-0007-0040","OSTP","OSTP-TECH-2023-0007","ljg-ers7-mchz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-28T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hi.

AI is a huge risk for the people, because they steal jobs and take away millions people in the creative comunnity and other areas.Only create more stress and inextability in the economy . This technology needs to be stopped right now.",,,,,,,
"OSTP-TECH-2023-0007-0041","OSTP","OSTP-TECH-2023-0007","ljg-hxgs-tl7j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-28T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"By the supplementary information section of its Request for Information (FR Doc. 2023–11304), Science and Technology Policy Office alerts that AI “poses serious risks to democracy, the economy, national security, civil rights, and society at large.”

The derived answer for this RFI is NOT to unroll any more AI than is already out until the controlling measures have been established and verified to be functioning, so that we are not incurring preventable risks to our democracy, economy (!), the executive branch (national security) or slow-pacing the Chinese Social Credit system against the US public.",,,,,,,
"OSTP-TECH-2023-0007-0042","OSTP","OSTP-TECH-2023-0007","ljh-dgu4-2uy2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-29T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0042/attachment_1.pdf",
"OSTP-TECH-2023-0007-0043","OSTP","OSTP-TECH-2023-0007","ljh-py2f-gitp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-29T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached the response to the RFI from the National Retail Federation.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0043/attachment_1.pdf",
"OSTP-TECH-2023-0007-0044","OSTP","OSTP-TECH-2023-0007","ljh-up3a-ni43","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-29T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Just like the Johns Hopkins’ studies revealed that the third leading cause of all deaths in the US is iatrogenic (resulting from the activity of physicians) harm, the healthcare, guided by US Dept. HHS, changed to have a patient be treated by a “team” of health care professionals to conceal the guilty of them should things go bad. I see AI deployment having similar tendency – a way for the company to minimize its responsibility and blame the harm on the chip (AI).",,,,,,,
"OSTP-TECH-2023-0007-0045","OSTP","OSTP-TECH-2023-0007","lji-q0ox-x85w","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0045/attachment_1.pdf",
"OSTP-TECH-2023-0007-0046","OSTP","OSTP-TECH-2023-0007","lji-t9vt-7jww","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0046/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0046/attachment_1.pdf",
"OSTP-TECH-2023-0007-0047","OSTP","OSTP-TECH-2023-0007","lji-u6os-5471","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Docket ID - OSTP-TECH-2023-0007 
Please find Deloitte’s response attached to OSTP-TECH-2023-0007.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0047/attachment_1.pdf",
"OSTP-TECH-2023-0007-0048","OSTP","OSTP-TECH-2023-0007","ljj-9o3y-ylrt","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-06-30T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I run our family business in Steubenville, Ohio, that owns and operates various food service brands. Our food is very popular throughout the state, especially Nanna's homemade gnocchi. We've grown into a successful business thanks partly to digital tools and technologies powered by Artificial Intelligence (""AI"").

As the Office of Science and Technology Policy (OSTP) develops strategies surrounding AI, they must consider AI's vital role in the everyday functions of small businesses like ours. AI helps power the algorithms behind digital ads identifying people interested in tasty Italian food. AI technology also makes our online ordering process work more efficiently. It also plays critical roles in our CRM and marketing software, inventory management, and process automation. Everywhere we look, AI makes running our business easier, faster, and more efficient. It also saves us money. 

AI already exists and already works. There are countless systems that small businesses use each day that are tied to AI. While it's essential to identify the possible threats AI poses to our society and regulate accordingly, it's just as important for the government to understand the immeasurable value AI brings to small businesses and not overturn the apple cart on a valuable aspect of small business operations.",,,,,,,
"OSTP-TECH-2023-0007-0049","OSTP","OSTP-TECH-2023-0007","ljj-nqje-7jo4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-01T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am submitting a comment on the risk of AI. My comment mainly relates to Topic No. 1, which concerns measures to protect people's safety. However, if Topic No. 1 is requesting more specific information on measures, my comment may fall under Topic No. 29, which covers other comments.

My comment pertains to the issue of existential risks to humanity. Among the various impacts brought about by the advancement of AI technology, the issue of humanity's existential risk and other risk issues are problems of different natures. For this reason, I believe it is necessary to conduct risk analysis with separate frameworks.

While it is important to address both types of risks in risk countermeasures, my comment focuses on humanity's existential risk. To handle this issue in a rational and logical manner, detached from fear or adventurism, I believe a framework that delves deeply into the nature of this issue is necessary.

The pdf document Attachment1 summarizes the framework I have organized from this perspective. This is my personal research and is not a widely recognized theory. However, as one of the stakeholders who will be undoubtedly affected when the existential risk to humanity occurs due to AI, it is a framework that I have earnestly considered based on realism. Attachment2 and Attachment3 are also considerations related to humanity's existential risk, serving to reinforce the contents of Attachment1.

Attachment1_the_third_realism.pdf
Attachment2_reconsideration_of_technology_development_control.pdf
Attachment3_considering_the_risk_of_insensitivity_and_fearlessness.pdf

Let me explain my background.

I am a systems architect with over 20 years of experience in the field of systems engineering. In various projects I have been involved in, I have consistently devised new conceptual frameworks to organize the concepts needed for new system development. Based on this framework, I have extracted stakeholder requirements, coordinated interests, and identified and evaluated all conceivable risks in advance. I then calculated realistic development time and costs, as well as the development team, and planned effective development schedules. In addition, I have faced the reality that serious misunderstandings of specifications, design, and significant bugs in programming, which the people involved in the project tend to make, are often due to their preconceptions, biases, and discrepancies in the conceptual framework of what to prioritize.

While I have an interest in AI technology, I am not a researcher or developer. However, I do have practical skills as a systems architect. Moreover, I am unquestionably a stakeholder who will be affected by the existential risk to humanity. All the people whom I love are also stakeholders. Facing this reality, I am committed to this realistic personal study of humanity's existential risk using my skills as a systems architect.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0049/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0049/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0049/attachment_1.pdf",
"OSTP-TECH-2023-0007-0050","OSTP","OSTP-TECH-2023-0007","ljk-pb6b-0pvv","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-01T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI should not be used on people or their information because there is no way to control the ability to assign values, enrich profiles and caste the population.

AI (and its adverse effects) would be disproportionately applied to the poor, disabled, elderly, and other applicants and recipients of benefits if AI were to be implemented in government offices. Faulty negative decisions will cause loss or delay of benefits for people with no means to fend for themselves. Homelessness, diseases and suicides will be harder to hide, unless increase in crime is a business goal.

AI should be reserved for background usefulness like developing green clean-up technologies, infrastructure maintenance, or identifying software vulnerabilities.",,,,,,,
"OSTP-TECH-2023-0007-0051","OSTP","OSTP-TECH-2023-0007","ljk-smc9-dwjs","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-01T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"see attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0051/attachment_1.pdf",
"OSTP-TECH-2023-0007-0052","OSTP","OSTP-TECH-2023-0007","ljl-i9rl-96sp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-02T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0052/attachment_1.pdf",
"OSTP-TECH-2023-0007-0053","OSTP","OSTP-TECH-2023-0007","ljl-ndmr-6vw6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-02T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The cornerstone of ensuring that AI systems respect people's rights and safety lies in the legal recognition of data ownership, both individual and collective. At its core, data ownership encapsulates the idea that personal data generated by individuals is, in fact, their personal property and under their control. This ownership spans across a broad spectrum of data types, from explicit information, like name, address, and age, to data that is implicitly generated.
Existing laws in several jurisdictions do touch upon aspects of data privacy and protection. However, there is a clear need for legislation to address the nuanced concept of data ownership more comprehensively. Laws need to be proposed and enacted that unambiguously establish and safeguard citizens' rights over their personal data, from creation to deletion.
This legal affirmation of data ownership serves multiple purposes. Primarily, it can prevent unauthorized data usage. By asserting that individuals have the right to control who can access and use their data, we can potentially prevent misuse and unauthorized data sharing by third parties. Businesses, governments, and other entities will be obligated to get explicit permission from individuals before using their data, ensuring that any data exchange that occurs is consensual.
Furthermore, the recognition of data ownership would reinforce privacy protections. While privacy laws exist, data ownership can empower individuals to have a higher degree of control over their personal information. This could translate into more meaningful choices for individuals about the level of privacy they want to maintain.
Finally, acknowledging data ownership can help ensure a fair exchange of value. With the rise of the digital economy, personal data has often been likened to 'the new oil,' given its crucial role in AI training and customization of services. Yet, individuals seldom receive direct compensation for the value their data provides. Recognizing data ownership could help set the stage for data markets where both individuals and the collective public are compensated fairly for the use of personal data.
In essence, the recognition of data ownership is not merely about asserting an abstract concept. It's about providing individuals and the wider public with tangible rights that they can exercise to control their data, thereby fostering a safer, more respectful digital environment.
Treating data as a public utility
To protect people's rights and safety in the age of AI systems, we must adopt a revolutionary perspective on data: viewing it as a shared resource or a public utility, co-owned by the collective of citizens. This shift, radical as it might seem, can open the door to a more equitable data economy where individual citizens are the focal point, and their interests are prioritized.
A community's data is a treasure trove of insights into their collective behavior, preferences, health patterns, and more. However, these rich data streams are often tapped into by businesses without an equitable return for the individuals whose lives generate the data. Instead, if we begin to view data as a shared resource, a form of communal wealth, it becomes apparent that individuals should have more of a say in how it is used and ought to share in the benefits derived from it.
Such a reconceptualization places individuals at the heart of the data ecosystem, emphasizing their stake in data conversations and the accountability of AI systems that use their data. This means not just focusing on protecting data but also on allowing individuals to actively participate in decisions about data use.
This transformative perspective would necessitate a policy sandbox where different regulatory approaches can be tested. Such an experimental space would allow us to explore the potential impacts and feasibility of treating data as a public utility.
Imagine a scenario where entities work on behalf of “data producers” (i.e., everyday individuals who interact with AI-driven systems) to help them protect their privacy, control how their data is used, and share in the income generated from their data. These entities would essentially be legitimate coalitions that have clear responsibilities, such as marking data sent to third parties, providing profit shares to their members, ensuring a fair and non-discriminatory member recruitment policy, and facilitating the portability of members' data to other coalitions.
The model would place the control and benefits of data in the hands of the people who produce it. Importantly, this would not only apply to legitimate coalitions with fiduciary duties, but other businesses would also have duties towards the citizens of the jurisdiction. This includes making their data available for portability to other entities who can negotiate privacy and data policies, and refraining from retaliatory or discriminatory behavior against those who join such coalitions.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0053/attachment_1.pdf",
"OSTP-TECH-2023-0007-0054","OSTP","OSTP-TECH-2023-0007","ljm-quf9-su9y","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"INTRODUCTION

At Leap Labs, we pioneer AI interpretability research and build tools that facilitate the understanding of AI models, predict their failure modes, demonstrate safety, enable targeted fine-tuning, and help in knowledge discovery. This document is our response to the call for information about national priorities for artificial intelligence. We are particularly invested in stressing the importance of interpretability for AI safety.

PROTECTING RIGHTS, SAFETY, AND NATIONAL SECURITY

1. Interpretability in AI systems plays a vital role in ensuring AI systems are designed, developed, and deployed in a manner that protects people's rights and safety. Clear standards should be set for AI interpretability, ensuring that systems can be understood and audited. This helps in setting accountability in AI decision-making processes and will foster trust in these systems.
2. Voluntary oversight based on interpretability metrics could be a game changer in AI safety. It is critical to learn from other sectors that have successfully implemented risk management models using certification or licensing based on adherence to prescribed standards. We at Leap Labs have developed tools that enable interpretability, and these could form the basis for such certification models.

ADVANCING EQUITY AND STRENGTHENING CIVIL RIGHTS

1. AI can enhance equity by expanding access to services and opportunities, but only if the systems can be understood and bias can be identified and eliminated. Leap Labs' interpretability tools can help in ensuring AI algorithms are unbiased and fair.
2. Interpretability will help us to understand how AI systems impact underserved communities and vulnerable groups. By understanding the models' decisions, we can ensure they are not inadvertently causing harm or barriers to these communities.

INNOVATING IN PUBLIC SERVICES

1. Federal agencies can leverage AI to improve services, but only if those systems are reliable, understandable, and unbiased. Our tools can help agencies achieve this level of reliability and trust in AI systems.

We hope our input can help inform the National AI Strategy, ensuring a future where AI is transparent, trustworthy, and beneficial for all.

Sincerely,
Research Team, Leap Labs",,,,,,,
"OSTP-TECH-2023-0007-0055","OSTP","OSTP-TECH-2023-0007","ljm-t3bs-d5th","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file with responses for each of the items raised.
There is immediate action that is needed to reduce the risk of catastrophic unanticipated impact from AI.  Developers need to stop releasing updates and new versions into the public market place. This does not limit research.  To accomplish this, the Federal government must convene a forum of vendors, academia, agencies, standards bodies and other stakeholders.  The objectives should be:
1.	To agree to not release new versions and improvements to generative AI products or services until agreement can be reached on guidelines, certification methods, and verification
2.	To vet all research access to avoid public release during this window.
3.	To collaborate with stakeholders in establishing guidelines, standards and oversight processes.
4.	To intervene if deployed algorithmic decision systems are proven, or appear to be causing harm to persons, property or institutions.
5.	To collaborate internationally, recognizing that different cultures will establish different guidelines, and that respect and reciprocity are appropriate.

As indicated in the attached responses a new Federal agency is needed with the authority and funding to:
1.	Convene stakeholders to monitor technology evolution, identify concerns and revise guidelines related to these
2.	Establish regulations for the public benefit, with certifications, verification methods, and sufficient penalties to assure compliance.
3.	Recommend courses of action for all branches of government related to policy/legislative actions, public education, employment, risk reduction, security and other aspects impacted by AI, including funding options to consider.
4.	Provide expert support in bilateral or international collaboration.

",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0055/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0055/attachment_1.pdf",
"OSTP-TECH-2023-0007-0056","OSTP","OSTP-TECH-2023-0007","ljn-1siu-ylde","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To Whom it May Concern,

My name is David Gray Widder, and I am a researcher at Carnegie Mellon University studying ethics in Artificial Intelligence systems.  

AI is typically produced not by a single company, but in a multi-company ""value"" or ""supply chain"". Components used to build AI often undergo substantial iteration and revision as they move through that supply chain and into real-world use.  

Therefore, AI policy would be strengthened if regulatory clarity can be provided on:

1. *Accountability* along the AI supply chain: Right now, a major area of ambiguity has to do with the responsibilities of each entity in that chain, and what kind of information needs to flow through that chain. Who is responsible for AI harms distributed among different entities? From those creating datasets, to those training models, to those fine tuning them, to those deploying them into final products – which entity is responsible for conducting due diligence for harms such as bias, incorrect or harmful input data or model output? It is easy for those producing end-user products to disavow accountability when using an ""off the shelf"" dataset they did not create -- but it is also easy for those upstream who created that dataset to disclaim responsibility for how it is used downstream.

2. *Transparency* along the AI supply chain: Accountability is rendered more difficult because of how opaque AI supply chains are. While transparency is often a stated goal of many AI companies, corporate incentives such as protecting IP, maintaining a competitive position, or not disclosing information which may lead to legal or PR risk lead to significant opacity along AI supply chains. Regulatory clarity is needed: what specific information companies should be disclosing to other companies which may use their products, and be requesting from both suppliers and customers who they depend on?

I attach research of my own and others in support of this comment. I am available to answer questions or provide additional clarification or advice as may be helpful. 

Respectfully,

David Gray Widder
Carnegie Mellon University",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0056/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0056/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0056/attachment_1.pdf",
"OSTP-TECH-2023-0007-0057","OSTP","OSTP-TECH-2023-0007","ljn-5ipl-1y5p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"What are the national security risks associated with AI? What can be done to mitigate these risks?

Currently, all AI models are trained and perform inferences on unencrypted data, which raises concerns about the trustworthiness of AI models.  To establish a trusted AI model from a technical perspective, two additional key factors need to be addressed:  

1.	Authenticated training and inference data.  To ensure that the AI model is trained, and inferences operated on trusted data, thus, performs its intended objective.  
2.	A close-loop system with encrypted data. All authenticated data needs to be encrypted throughout the entire AI process, from training to inferences.  This prevents unauthorized access or tampering by malicious actors, protecting the integrity of the system.  The encryption also has to be safe from rapidly-accelerating quantum computing attacks and the AI systems have to be designed to operate over this encrypted data. 

These capabilities do not exist today although we, among a few others, are working hard on necessary breakthroughs and have already made some critical progress.  A national priority should be placed on research to create these capabilities. Without the above-mentioned two capabilities, deployed AIs are vulnerable to adversarial attacks. In a Zero Trust environment, we have to be concerned with the possibility that a knowledgeable and skilled adversary can eventually make its way inside the system and be able to move around with sufficient privileges to alter AI-related data being used to generate predictions and inferences. Some examples of  threats are: 
•	Identity access systems are increasingly using AI for everything from processing biometrics to detecting patterns of behavior and anomalous activities. Any threat to the data can potentially lead to a bad actor accessing sensitive information and locations.  
•	Autonomous systems such as vehicles, drones, and weapons depend heavily on AI for their operation and real-time decision-making and are susceptible to input data tampering and adversarial control.
•	Significant economic losses as AI models are used to identify fraudulent activities.  Any attack on these models can result in financial damage to organizations and individuals. 
As long as AI models are trained and performing inferences only on unencrypted data, we need to be concerned about the trustworthiness and the risks posed by these models.  Worse yet, if our adversaries are researching solutions to address the issues identified and can solve the problems before we do, we may not know about their capabilities until after the attacks or disasters.  The stakes are extremely high.  We, at PureCipher, believe by focusing on these two major improvements, we can enhance the security and trustworthiness of AI models while mitigating the risks they currently pose.
",,,,,,,
"OSTP-TECH-2023-0007-0058","OSTP","OSTP-TECH-2023-0007","ljn-5ghq-86ec","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0058/attachment_1.pdf",
"OSTP-TECH-2023-0007-0059","OSTP","OSTP-TECH-2023-0007","ljn-b8t2-uzun","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-03T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached statement of Copyright Clearance Center in response to the Request for Information; National Priorities for Artificial Intelligence.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0059/attachment_1.pdf",
"OSTP-TECH-2023-0007-0060","OSTP","OSTP-TECH-2023-0007","ljo-6vzy-kmul","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-04T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file for our comment.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0060/attachment_1.pdf",
"OSTP-TECH-2023-0007-0061","OSTP","OSTP-TECH-2023-0007","ljo-bryb-jzsg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-04T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0061/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0061/attachment_1.pdf",
"OSTP-TECH-2023-0007-0062","OSTP","OSTP-TECH-2023-0007","ljp-si0u-lb93","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Attached is a piece published in Minds & Machines about the OSTP’s Blueprint for an AI Bill of Rights, with commentary. It offers an assessment of the promises and perils of the outlined approach, and I (the first author) hope that it is useful as the OSTP considers RFI Topic 2 and how to further implement the Blueprint. In particular, I would like to draw attention to the need for a community-centered approach to considering the benefits and harms of AI (as outlined in Comment NTIA-2023-0005-1028 on FR Doc # 2023-07776), and the need to fully consider the environmental impacts of AI. AI ethics and policy work often focuses on the end user, but while this may be appropriate for certain applications, it disregards “ambient AI”: that is, the algorithms and systems that quietly surround us and that have individual impacts that may manifest even more extremely at the community level. 
After five years in the American AI policy space, I am glad to see that the US is considering proactive regulation, built on a foundation of fundamental rights, that will hopefully guarantee that all in America are treated equitably and ethically, and share in the benefits of AI. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0062/attachment_1.pdf",
"OSTP-TECH-2023-0007-0063","OSTP","OSTP-TECH-2023-0007","ljp-v0oy-xlv6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0063/attachment_1.pdf",
"OSTP-TECH-2023-0007-0064","OSTP","OSTP-TECH-2023-0007","ljp-vbjv-3qzn","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file for Applied Intuition's comments in response to the White House Office of Science and Technology Policy Request for Information on “National Priorities for Artificial Intelligence.”",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0064/attachment_1.pdf",
"OSTP-TECH-2023-0007-0065","OSTP","OSTP-TECH-2023-0007","ljp-wah1-fmoq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0065/attachment_1.pdf",
"OSTP-TECH-2023-0007-0066","OSTP","OSTP-TECH-2023-0007","ljq-1oox-s773","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To whom it may concern,
Please find attached a response to OSTP’s National Priorities for Artificial Intelligence RFI, from experts on the Center for a New American Security’s AI Safety and Stability project.
Thank you for the opportunity to respond.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0066/attachment_1.pdf",
"OSTP-TECH-2023-0007-0067","OSTP","OSTP-TECH-2023-0007","ljq-2evg-xfe2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0067/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0067/attachment_1.pdf",
"OSTP-TECH-2023-0007-0068","OSTP","OSTP-TECH-2023-0007","ljq-4gyl-snq9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Kheiron Medical Technologies submits the following responses to the OSTP Request for Information: National Priorities for Artificial Intelligence. Kheiron Medical is a leading medical AI company specializing in assessment of screening mammography. We thank OSTP for reaching out regarding AI and look forward to thoughtful policy development considering industry and the American people. We encourage communication to the population on what AI is, how it can be used, and how it is already impacting individuals. We also advocate for the development of voluntary standards for the AI industry and transparency around how AI models are trained to help ensure equity and limit model bias. 

See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0068/attachment_1.pdf",
"OSTP-TECH-2023-0007-0069","OSTP","OSTP-TECH-2023-0007","ljq-5oe8-oyog","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Re: FR Doc. 2023–11346, National Priorities for Artificial Intelligence

To the Office of Science and Technology Policy,

Thank you for the opportunity to comment on National Priorities for Artificial Intelligence. We serve as members of the Modern Language Association and College Composition and Communication Joint Task Force on Writing and Artificial Intelligence. The MLA, with over 20,000 members, is the largest organization of language and literature teachers in the world. CCCC, a chartered conference of the National Council of Teachers of English, is the world’s largest membership body for writing and composition research and teaching. Together, we represent a large and diverse constituent of educators. This task force, composed of scholars and teachers with collective expertise in writing, literature, and languages, is charged by our professional organizations to take stock of the current state of artificial intelligence and to identify implications for teachers, students, organizations, and citizens and map out promising directions in research for learning more about the impact of AI in writing, literature, and language classrooms.  

In our attached response to the request for information, we raise concerns about the impact of artificial intelligence on students' learning and the role of educators in preparing citizens with the reading, writing, and critical thinking skills necessary for participation in democracy. We assert that generative AI tools should be regulated in a way that safeguards and advances information integrity, which is essential to equitable democratic participation and to providing students with the educational experiences that will help them fully participate in and advance democracy.   

Respectfully submitted, 

Conference on College Composition and Communication and Modern Language Association Joint Task Force on AI and Writing",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0069/attachment_1.pdf",
"OSTP-TECH-2023-0007-0070","OSTP","OSTP-TECH-2023-0007","ljq-7s6j-t15j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Center for AI Safety (CAIS) appreciates this opportunity to provide comments in response to the Office of Science and Technology Policy (OSTP) about AI strategy. We have included three files in this comment: the first file is our response to the RFI, and the other two files are supplementary documents summarized in our response. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0070/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0070/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0070/attachment_1.pdf",
"OSTP-TECH-2023-0007-0071","OSTP","OSTP-TECH-2023-0007","ljq-8n39-vglb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0071/attachment_1.pdf",
"OSTP-TECH-2023-0007-0072","OSTP","OSTP-TECH-2023-0007","ljq-get6-rp2x","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"An introductory note
My submission is as the article: Can AI be playing Socrates?
That article is in the public domain, on my blog, https://henrykkowalczyk.com/2023/07/05/can-ai-be-playing-socrates/,  and on Medium, https://hak1010.medium.com/can-ai-be-playing-socrates-b43cb1d51d80. 
Attachment 1 is a PDF printout of the submission article. 
Attachment 2 is a PDF printout of that article from my blog. 
I have written several articles about media, politics, and artificial intelligence in recent years. I bring these articles as references supporting reasoning in my submission, with links. 
Attachment 3, “Politicians have already outsmarted AI,” https://henrykkowalczyk.com/2023/06/25/politicians-have-already-outsmarted-ai/, is an article about immigration misinformation incorporated into ChatGPT. 
Attachment 4, “Can AI help Americans overcome the political divide?” https://henrykkowalczyk.com/2023/06/30/can-ai-help-americans-overcome-the-political-divide/, is about my test about ChatGPT ability to moderate political debates.
Attachment 5, “Human and artificial intelligence in capitalism,” https://henrykkowalczyk.com/2020/04/17/human-and-artificial-intelligence-in-capitalism/, is my polemic with alarmist voices about the abuse of AI in commerce.
 Attachment 6, “How did Americans screw up immigration?” https://freedomofmigration.com/how-did-americans-screw-up-immigration/, supports my argument that politicians avoid sincere discussion of the immigration issue.
Attachment 7, “The New York Times’ dance around the truth,” https://henrykkowalczyk.com/2021/06/07/the-new-york-times-dance-around-the-truth/, is an example of immigration misinformation in the prominent media outfit.
Attachment 8, “Even the Nobel Prize cannot change the thinking of American lawmakers about immigration,” https://henrykkowalczyk.com/2022/01/09/even-the-nobel-prize-cannot-change-the-thinking-of-american-lawmakers-about-immigration/, supports my argument that science is ignored in the mainstream political discussion about immigration. 
Attachment 9, “Stone Age politics in the health care reform debate,” https://lifetermhealth.com/stone-age-politics-in-the-health-care-reform-debate/, supports my argument that science is not used in political debates. 
Attachment 10, “It is not about climate, and it is not change,” https://henrykkowalczyk.com/2019/08/01/it-is-not-about-climate-and-it-is-not-change/, supports my argument that we do not have sincere debates about climate change.
Attachment 11, “Science and money in the climate change debate,” https://henrykkowalczyk.com/2020/02/01/science-and-money-in-the-climate-change-debate/, supports my thesis that AI can and should assist us with addressing climate change.
Attachment 12, “The future has the great past, but the present,” https://henrykkowalczyk.com/2022/07/09/the-future-has-the-great-past-but-the-present-stands-in-the-way/, is a reflection about importance of sincere public conversation. We do not do it with human intelligence. 
stands in the way
Attachment 13, “Facebook is evil because it is us,” https://henrykkowalczyk.com/2021/10/22/facebook-is-evil-because-it-is-us/,  explains the falsehoods from social media or AI can be dangerous only when people do not trust politicians and the mainstream media. 

",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_11.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_10.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_8.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_6.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_4.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_12.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_13.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_9.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_7.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_5.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0072/attachment_1.pdf",
"OSTP-TECH-2023-0007-0073","OSTP","OSTP-TECH-2023-0007","ljq-h2ne-wpi0","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"(Answer to question 15 of Request for Information; National Priorities for Artificial Intelligence) The key challenges posed to democracy by AI systems is for the government to be able to control AI and technology in a way that the user does not undergo risks, harms, or forgoing rights: 

The use of internet technology, software, and apps in education comes with rights-waiving Terms of Use (usually at a login page). An education seeker or student must consent to this in order to remain at the school. 

Most of the colleges do not list links of login pages to all of the contracting educational services’ software. This prevents the education seeker from visiting each of the links to preview the contract involved (or the absence of contract, in cases where the contract is reserved to being with the school) prior to applying. Colleges do not reply to requests for the links, timing out the due date. There is no cooperation.

Access to education should not be conditioned on private companies’ contracts. Many of them allow unlimited dissipation of information on you or submitted by you.

Students and education seekers should know that they are consenting to the entire content of Terms of Use, the link to which can be found on the login page of each software they are using for college.",,,,,,,
"OSTP-TECH-2023-0007-0074","OSTP","OSTP-TECH-2023-0007","ljq-kpxu-33cp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-05T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0074/attachment_1.pdf",
"OSTP-TECH-2023-0007-0075","OSTP","OSTP-TECH-2023-0007","ljq-ukcc-vk6j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dear Sir/Madam,

Please see attached Kaspersky's submission to the National Priorities For Artificial Intelligence.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0075/attachment_1.pdf",
"OSTP-TECH-2023-0007-0076","OSTP","OSTP-TECH-2023-0007","ljr-4yua-gs9p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The most important thing is that this technology be open to everyone - that access not be limited to corporations or to state actors or to the wealthy. There will be economic gains and losses as its use increases and we already know many jobs will be lost (probably even more than we currently imagine). It is essential that average citizens have access to the same technology as the companies benefiting from the reduced labor costs, so that they can more readily adapt to the changing market and share in the gains.",,,,,,,
"OSTP-TECH-2023-0007-0077","OSTP","OSTP-TECH-2023-0007","ljr-6ut8-6l9r","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On behalf of SandboxAQ, we attach our statement in response to the Request for Information (RFI) issued by the OSTP on National Priorities for Artificial Intelligence. In our comments, we provide specific responses to Questions 4, 5, 6, 7, 22, 24, and 26. We highlight the advantages of AI in national security, including bolstering cybersecurity measures and advancing the effectiveness of other emerging technologies, such as quantum sensing for navigation. We also provide recommendations on the responsible development, procurement, and use of AI to allay technical and social risks.

Our company strives to accelerate the adoption of AI and Quantum (AQ) technology to advance the energy, economic, and national security of the United States. We care deeply about the use of emerging technologies for national security and beyond, and believe in the prioritization of inclusive and comprehensive impact research, testing, and deployment to ensure that AI and other technologies produce long-term benefits across all of society. 

Our recommendations include the implementation of quantum-resistant, cryptographic solutions to maintain the long-term integrity of AI training data and algorithms; the prioritization of public participation and diverse inclusion throughout regulatory actions and the AI lifecycle; dedicated investment in the research (both social and technical) and comprehensive deployment of AI; flexible procurement frameworks and interagency cooperation to accommodate the dynamic nature of AI and streamline the acquisition of innovative solutions; and the establishment of Federal regulations to govern the responsible use of AI and emerging technologies in public and private sectors.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0077/attachment_1.pdf",
"OSTP-TECH-2023-0007-0078","OSTP","OSTP-TECH-2023-0007","ljr-7lbq-fldl","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"New technology often comes with pushback and hesitancy, with increasing concern regarding potential biases of emerging technology and the information these capabilities provide. For instance, without standards for a percentage of factually correct information, customers could be led in the wrong direction and be misinformed with inaccurate recommendations.

It will be key to establish comprehensive ethical and technical standards for AI systems to ensure they are designed and deployed in a manner that respects human rights, privacy, and safety. These standards should cover aspects such as transparency, accountability, and the prevention of any potential bias. Organizations should adopt and implement robust safety practices in the development and deployment of AI systems. This could include conducting consistent risk assessments, ensuring secure data handling, and establishing protocols for addressing potential harmful or adverse impacts. The onus should be on organizations themselves to take the lead in establishing best practices and guidelines to promote responsible AI development and implementation.

We are approaching a point after which generative AI like ChatGPT will outpace regulation, putting responsibility and opportunity in the hands of business leaders. Companies must focus on the ethics of training and developing new models. Separately, they must also focus on operationalization of these models going forward to ensure the accuracy and fairness of the models that power the next generation of solutions.

Projected to increase productivity by up to 40%, AI carries the ability to advance how work gets done. But the unique opportunity exists when these technologies are viewed as performance enhancers rather than substitutes. Today, there are clear distinctions between humans and AI that can be leveraged to realize the strengths of each, creating human-AI symbiosis, which can help to augment work performance and productivity. In order to mitigate harmful impacts on workers, it will be crucial to promote the development and deployment of ethical AI systems that prioritize transparency, fairness, and accountability. Regulations and standards should be established to ensure that AI technologies are unbiased, explainable, and do not perpetuate discrimination or inequality in the workplace.


It’s imperative to consider all factors prior to incorporating generative AI into your enterprise. For instance, it is key to train data to be more accurate. Ensuring that these solutions behave in a way which is expected, predictable and indeed ethical for the needs of a user is still an important hurdle that needs to be overcome. This is why there is a significant ongoing research effort to find ways of training more computationally efficient AI applications. Given that generative AI is based on statistics and therefore can be wrong, for large regulated institutions, keeping a human in the loop is essential. 

Instead of replacing skilled labor with AI, enhancing humans’ skills with AI’s assistance should take precedence. In the contact center for instance, AI tools can reduce labor costs by increasing efficiency and reducing call resolution times. Further, emotion and conversation AI can help overworked contact center agents deliver a positive customer experience with every interaction. Customer service leaders still need to consider the human component to provide empathetic interactions to resolve complex, sensitive issues. Thanks to recent advancements, AI can focus on relieving agents of the cognitive burden of multi-tasking — including after call work tools to summarize notes and real-time cues sharing time sensitive knowledge — which helps them to properly address and anticipate customer needs.

In contact centers, AI tools can reduce labor costs by increasing efficiency and reducing call resolution times. Despite these advantages, AI can’t deliver what a human representative can: empathetic interactions to resolve complex, sensitive issues. It will be key for enterprises to achieve better experiences by adopting technology that is human-centric, as it considers the operator to be an asset rather than an impediment and recognizes the value of the operator's skill, knowledge, flexibility and creativity.",,,,,,,
"OSTP-TECH-2023-0007-0079","OSTP","OSTP-TECH-2023-0007","ljr-89fj-ymx8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0079/attachment_1.pdf",
"OSTP-TECH-2023-0007-0080","OSTP","OSTP-TECH-2023-0007","ljr-9ay0-cfat","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0080/attachment_1.pdf",
"OSTP-TECH-2023-0007-0081","OSTP","OSTP-TECH-2023-0007","ljr-a3z8-mk78","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comments are submitted using two attachments.  First is the 'OSTP Comment document' that includes comments to Question 1 of the policy RFI based on a summary of the relevant conference materials presented at William and Mary Law School on February 10th 2023.  The second attachment 'Problematic AI Conference Write-up' is a conference summary document with relevant background and citation material supporting the OSTP comment document.  ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0081/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0081/attachment_1.pdf",
"OSTP-TECH-2023-0007-0082","OSTP","OSTP-TECH-2023-0007","ljr-b1l9-mklo","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comment is in the attached file below.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0082/attachment_1.pdf",
"OSTP-TECH-2023-0007-0083","OSTP","OSTP-TECH-2023-0007","ljr-d95u-itdi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached files from iProov",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0083/attachment_1.pdf",
"OSTP-TECH-2023-0007-0084","OSTP","OSTP-TECH-2023-0007","ljr-dd0w-08xg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On behalf of Torch.AI, we are pleased to share our comments on OSTP's National Priorities for Artificial Intelligence. Attached you will find Torch.AI's response which includes comments addressing two specific topics in the category of protecting rights, safety, and national security. 

We are excited for the opportunity to participate in such an important conversation and we look forward to the continued dialogue. 

Best, 
Jason Eidam, Torch.AI ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0084/attachment_1.pdf",
"OSTP-TECH-2023-0007-0085","OSTP","OSTP-TECH-2023-0007","ljr-df06-bx8j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"BSA | The Software Alliance comments attached",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0085/attachment_1.pdf",
"OSTP-TECH-2023-0007-0086","OSTP","OSTP-TECH-2023-0007","ljr-e2sp-gm5r","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"
Dear OSTP,

Our comment is attached as a PDF file.

We are a team of researchers from GPTZero, Princeton University’s Center for Information Technology Policy (CITP), and the University of Oxford writing to offer suggestions on the role of AI-generated text detection systems in addressing question 15 of the RFI (key challenges posed to democracy by AI systems). 

In particular, we focus on the problems of malicious actors manipulating people’s beliefs and AI-generated noise drowning out other valuable public discourse.

In this comment, we provide:
1. An overview of relevant channels through which harms related to AI-generated text can propagate (pg. 2);
2. A review of the state-of-the-art techniques for detecting AI-generated text (pg. 3);
3. A description of the costs of implementing AI-text detection systems (pg. 4);
4. A menu of policy and technical interventions for OSTP to consider (pg. 5-7).

Please reach out if there are any questions, we welcome the chance to speak further with you about these issues.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0086/attachment_1.pdf",
"OSTP-TECH-2023-0007-0087","OSTP","OSTP-TECH-2023-0007","ljr-ex5k-kwda","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a professional artist in the animation industry, I am very frightened and feel threatened by AI. It has been stealing creative work from hardworking Americans all over the internet to fund its data algorithms. This must be reined in, controlled and stopped before it takes away the jobs of thoughts of hardworking, creative Americans. We already have a hard time competing with overseas studios and it's hard enough to see our jobs shipped overseas where studios and corporations can fuel their uncontrolled greed. We don't need AI to be the nail in the coffin. AI needs to be a tool, not a replacement for a creative human being. There needs to be rules in place. Please protect America's creativity. Please respect us. Corporations, studios, CEO's, Execs, and Silicon Valley certainly won't. We are $$ they can cut loose as soon as they can. ",,,,,,,
"OSTP-TECH-2023-0007-0088","OSTP","OSTP-TECH-2023-0007","ljr-eyc6-i3zh","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Additional input:
29. Do you have any other comments that you would like to provide to inform the National
AI Strategy that are not covered by the questions above?
In the development of a national AI strategy, we believe synthetic data can be an enabler and play a significant role.
 
AI algorithms that consume and learn from large amounts of personal data can leak private details pertaining to individuals, which can then be used to discriminate against them specifically. Synthetic data are artificially generated data that preserve the statistical characteristics of the original dataset without compromising the privacy of individuals. 

As such, synthetic data enables institutions to experiment, test, and validate AI models and applications. It provides a controlled environment for assessing the performance, robustness, and safety of AI systems without the risks associated with real data. These data can be used to simulate various scenarios and evaluate different algorithms prior to deployment.

In addition, synthetic data can advance collaboration among government agencies, research institutions, and industry stakeholders. Synthetic datasets can be shared and utilized by multiple entities to facilitate collaboration, conduct independent evaluations, and establish performance benchmarks. This collaboration promotes knowledge sharing, advances research, and helps develop best practices in AI implementation across different government sectors.

By providing synthetic datasets, governments can support AI training and educational initiatives, enabling researchers to gain hands-on experience in AI techniques without compromising privacy or relying solely on limited real-world datasets. For example, the U.S. Department of Veterans Affairs has recently made publicly available a representative dataset of Veterans with heart disease to individuals or teams interested in developing predictive models using AI and ML as part of The Veterans Cardiac Health and AI Model Predictions (V-CHAMPS) Challenge which utilizes synthetic data derived from original, contemporary VA data.


",,,,,,,
"OSTP-TECH-2023-0007-0089","OSTP","OSTP-TECH-2023-0007","ljr-f85f-d95f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The risks AI pose are vast and plentiful but for as much as we listen to the CEOs at the top, we must also be listening to those who are squashed and harmed by that tech. For artists (including but not limited to painters, musicians, writers, voice actors) their work is being scraped without three things: consent, credit and compensation. The AI industry has been more that unfair to them, arguing that they don’t deserve any for a variety of reasons. However these are copyrighted materials and like remixing or sampling there should be all three. We must also be extremely worried about deepfake technology especially alongside campaigns of misinformation.

Ultimately this must be a conversation that includes people affected by it rather than those at the top. Any regulation should be for the public rather than the companies - who have shown time and time again that they’re irresponsible with their tech.",,,,,,,
"OSTP-TECH-2023-0007-0090","OSTP","OSTP-TECH-2023-0007","ljr-f8lk-z4h1","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0090/attachment_1.pdf",
"OSTP-TECH-2023-0007-0091","OSTP","OSTP-TECH-2023-0007","ljr-gtqr-62kh","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Copyright integrity needs to be maintained in the face of generative AI. These systems have been trained on copyrighted works without the creator's knowledge, compensation, or consent. They are giant theft machines that threaten to cause mass unemployment. They must be stringently regulated.",,,,,,,
"OSTP-TECH-2023-0007-0092","OSTP","OSTP-TECH-2023-0007","ljr-gv7j-hn0w","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0092/attachment_1.pdf",
"OSTP-TECH-2023-0007-0093","OSTP","OSTP-TECH-2023-0007","ljr-h1d8-o622","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0093/attachment_1.pdf",
"OSTP-TECH-2023-0007-0094","OSTP","OSTP-TECH-2023-0007","ljr-heuw-76gx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Ai needs regulation to prevent job loss for the people it scrapes data from. All form of data collection should be opt-in by default.",,,,,,,
"OSTP-TECH-2023-0007-0095","OSTP","OSTP-TECH-2023-0007","ljr-hjtn-r1qz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI image generators feed off the work of actual artists and bring unfair competition to the industry. It's a violation of copyright, taking our collective work without consent or compensation, then using it, twisting it to repackage and sell it to our potential customers, taking sales and commissions away from us, effectively taking our own work and turning it against us. AI as a technology is fine, but data provided for the machine learning should be opt-in only. We should get to decide if our work, our style, our products are fed to it and ask for proper compensation for it instead of having it taken against our wills or even our knowledge. It's already hard enough to make a living as an artist, this only makes things worse, and, frankly, we deserve better.",,,,,,,
"OSTP-TECH-2023-0007-0096","OSTP","OSTP-TECH-2023-0007","ljr-hkai-1xd0","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI companies have scraped my own and every single artist's data on the internet to form image generators, designed to replace us and take all of our market value USING our own hard work and copyrighted, human authored data. 

These systems are not capable of of functioning well without our good quality data, used to build these massive models. They then take those massive models and fine-tune/weight them to specifically replicate our styles, claiming we cannot copyright styles. AI training must not be a loophole to copyright protection. 

On top of this, our value of art is being attacked directly. Masses of AI generated spam is flooding the internet, only some of it labeled as AI generated, making it impossible to find real information, and human authored creative works. Publishers are being swarmed by AI generated books looking to make quick bucks off of the legal grey area, companies are firing artists in favor of AI generators trained off of us, and some are hiring artists with the sole purpose of training their AI's to then fire the artists they absorbed into their models. This is unethical, threatens to completely overshadow real unique, innovative human creativity, and is causing mass disruption and skilled job loss.

Artists around the world are suffering and many are hanging up the towel because of the immense sense of doom that AI places on us. We use digital tools to help us create, but this is no tool, it is a predictive algorithm intended to replace human descision making for something ""good enough"", trained on the real thing. Art is one of the most fulfilling life paths and to see it shredded up by companies to make mass data generators has been awfully depressing. 

Please consider this heavily as you regulate artificial intelligence. Artists, all creative workers, need your protection.",,,,,,,
"OSTP-TECH-2023-0007-0097","OSTP","OSTP-TECH-2023-0007","ljr-hl07-sn0r","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am an artist and I have many artist friends. Many us of have had hundreds of our works and product images scraped into datasets to train AI, and there are even people who train AI to create art in various artists’ styles.

These generative AIs cannot exist without our work. They need to train on our works to learn what art is supposed to look like. However, once they train, they can produce near infinite derivatives from the patterns they learn. So they need artists to exist, but the artist will never be compensated for a single image, and then the generative AI undercuts the artists that allowed it to exist.

There are already reports of creatives of all kinds losing their jobs due to AI. Millions of more jobs could be lost due to this wide scale disregard for copyright.

I have similar concerns for generative AI  models that undercut authors, musicians, photographers, and creatives of all kinds.

We need a model of AI training that respects creators’ copyright, and training materials must be licensed. Creators should not be replaced by a machine that couldn’t exist without first stealing petabytes of our works.",,,,,,,
"OSTP-TECH-2023-0007-0098","OSTP","OSTP-TECH-2023-0007","ljr-hfp7-7z8l","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Document ID:
OSTP-TECH-2023-0007-0001

My comment is in the attached PDF.
Thank you.
Sincerely, Autumn Beverly.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0098/attachment_1.pdf",
"OSTP-TECH-2023-0007-0099","OSTP","OSTP-TECH-2023-0007","ljr-hwr5-4bie","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We need a way to easily tell AI from creative works for various reasons, especially if they are not ethically taught, such as by scraping the internet or archives that have not consented to their works being used for AI.  We have had a lot of issues come up already, such as explicitly not-for-profit-due-to-copyright-laws fan fiction be used, along with creators having their work stolen and fed into things.

Then there's that whole debacle about how machine learning will make things up, such as the lawyer who got caught doing that.

Seriously, make it much harder for machine learning, because people will misuse it.",,,,,,,
"OSTP-TECH-2023-0007-0100","OSTP","OSTP-TECH-2023-0007","ljr-hzsd-jmci","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"First of all i hate that its called Artificial Intelligence when its a predictive language model (like when your iphone predicts what the next word is in your text so you can type less). I think its technobable dishonesty to call it Artificial Intelligence, which implies any sort of sentience or thinking.

Beyond that, it does not sit well with me that these companies can get away with scraping information from anywhere and not disclose their sources, meaning hundreds of thousands of people are having their work used for profit without so much as a credit, let alone compensation.

Additionally, America is already in a crisis of misinformation, and the guise of a predictive language model being an emotionless computer (which again, it is not, it is just guessing based off of what words are commonly in such and such order on the internet) and if it is scraping from people who are confidently wrong, then it will parrot them without discrimination, yet will be lauded as fact because it has the appearance of impartality.

Also, any job that includes editing a predictive models output, ie writing or graphic design, should be legally recognized as the job the model was originally replacing. Ie, someone whos job it is to edit the writing of an AI should legally be categorized as a writer. And anyone using AI in anything government operated should be prosecuted for gross negligence.",,,,,,,
"OSTP-TECH-2023-0007-0101","OSTP","OSTP-TECH-2023-0007","ljr-i04p-bp2m","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please note that the input used for training data for AI is unethical and damaging. It possesses the ability to harm and damage artists, writers, creative jobs as jobs economically via job cut. As well as usage of creative works for training, exact replication of works via image generation for harassment, or text generation. Furthermore, AI can be used to damage the reputation of individuals or used in propaganda. The former can utilize Deep fakes to replicate an individual in a convincing manner and perform pornographic acts can be used for a variety of crimes. Ai Image or LLMs can also generate convincing images and texts to spread misinformation easily. Example is how Justin T. Brown could generate politicians cheating on their wives or perform pornographic acts. Finally, AI voice replicators can be used in a similar manner to create fake evidence or spread misinformation utilizing voices of both living or dead individuals. These program is already being used in scams to fake kidnappings. ",,,,,,,
"OSTP-TECH-2023-0007-0102","OSTP","OSTP-TECH-2023-0007","ljr-hq07-9joi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0102/attachment_1.pdf",
"OSTP-TECH-2023-0007-0103","OSTP","OSTP-TECH-2023-0007","ljr-idp1-1wl2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Government has to know AI scrapping should be illegal, They scrapped people’s informations, images (copyrighted), photos etc with out permission and they using it as property. And it’s taking people’s jobs and gigs. Ai company earning massive money based on stealing datas from People. At first, AI deep learning going to be using just for Studying, But now they using it as a profit. We should stop this. As a digital painter, I am losing my job and AI user using my friends and my work and make AI generated images for making money. They selling AI images on Etsy and online store. Government always said you must pay your tax and you should have proper job and work hard. So I pay tax regularly and work hard but government did nothing for this bad situation. This situation going to make massive money for just Big tech companies, and people who like me (Artist) going to lose their job and gigs. Because of AI company who constantly stealing Artist’s artworks and Voice actor’s voice with out paying and permission. What’s the difference between AI company and thieves. Artist are getting stolen their artworks eve now. Stable diffusion , Mid journey and ets can not make images with out original artworks. So please check this problem seriously. ",,,,,,,
"OSTP-TECH-2023-0007-0104","OSTP","OSTP-TECH-2023-0007","ljr-igu7-dc0a","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Proper copyright permissions used on training datasets (including preliminary and follow up data sets) seems like the biggest issue right now. Artists and writers are having their copyrighted works used without permission for these AI programs which are being used for profit. There should be clear opt out on all posting platforms, especially the biggest players such as Google Drive, which millions of people are reliant on and cannot simply stop using.",,,,,,,
"OSTP-TECH-2023-0007-0105","OSTP","OSTP-TECH-2023-0007","ljr-ih5w-sd8m","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0105/attachment_1.pdf",
"OSTP-TECH-2023-0007-0106","OSTP","OSTP-TECH-2023-0007","ljr-j1gk-3kr8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Thank you for accepting our feedback. I am a professional artist working in the games and animation industry, currently taking a break to build up my traditional art portfolio and personal art web store. In my lifetime, I have experienced and accepted technology changes, from working traditionally in animation in the 90's, to a sudden and rapid change requiring me to learn Photoshop to work digitally, to needing to keep up with numerous new software applications, and eventually learning to Art Direct and manage teams. Now, in my 50's, I am also trying to ride the social media wave and build up my personal art business in addition to all of that. We do what we can, but me, like many in the art community, are on thin ice in this gig economy. In my experience, I have witnessed technology that is helpful, like the advent of digital pipelines that are offshoots of traditional ways of working while maintaining core creative values and workflows. However, I have also witnessed and experienced a disturbing trend at some workplaces; non artists, like engineers or product managers, eliminating entire art teams and making the art themselves or outsourcing to the lowest bidder overseas (usually India or China). Unfortunately, the art is usually terrible, but acceptable enough for say, a mobile game to launch, make a quick amount of money, and then shut down once the pump and dump scheme is profitable enough. And that's just games. I have recently witnessed book covers with AI images, print illustration in newspapers, movie posters, and so much more using AI, even the San Francisco Ballet chose not to hire a local artist but instead decided to work with an AI software company to promote themselves. Says a lot about who this town values. I am in deep fear for the entire art community because I know we will be flooded with cheap, AI scraped art across several entertainment industries, causing unemployment across many creative industries. Which is why I ask you, when, exactly, do we as a nation decide to VALUE and CELEBRATE our arts industries? When? Why do we have to accept this future? AI companies seek to completely wipe out our creative voices, dumb down art, cheapen workflows, create disinformation, confuse people, and eliminate the true and real voices we have in our culture. I have even seen fake images of historical artifacts and art on Google. How do we preserve our history and those who came before us if the tech bros basically don't care as long as they make a little cash? When do we put a stop to this? As I'm sure many others have mentioned, AI software was created using images across social media and the internet without our permission. Silicon Valley created this online world, social media, the gig economy, and changed the way we communicate, create and share, only to then use our own property to cut us out of the culture? That is vast exploitation! Please, stand for the arts, for truth, for reality. We are not luddites. We are PEOPLE. Thanks, Julia Lundman ",,,,,,,
"OSTP-TECH-2023-0007-0107","OSTP","OSTP-TECH-2023-0007","ljr-j2g1-0vep","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"At a macro level, what needs to be addressed is the misnomer of ""artificial intelligence."" These programs are not intelligent. They are not capable of individual thought nor are they able to create ideas or arguments. These programs produce amalgamations; they are fed information and then produce  mash-up results that may appear to be unique at a glance but are in actuality just pieces of information that the program has repackaged into something new. This means that in any intstance where AI is tasked with producing images or text (be that text legal, creative, or other), it essentially functions as a plagairism machine. This is not in any way like an industrial machine replacing a human worker on an assembly line. AI cannot problem solve. It cannot be creative because it does not learn, it is not alive. I am a television writer so, naturally, my immediate concern about AI is that it will be propped up as a replacement for creative labor despite not being capable of producing creative or original works. But the concern goes beyond that. There are already instances where lawyers filed briefs that were written by AI, only to later learn the program had invented cases that didn't exist. These facts will, naturally, not stop corporations from thinking they can replace flesh-and-blood employees with AI in order to save on the bottom line. The only true solution here is widespread legislation that classifies AI as being unsuitable for any position that requires a human. Again, the very name ""Articifial Intelligence"" likely needs to be regulated as it is misleading in terms of what these programs can and cannot do. If left unchecked, AI will facilitate another move by corporations to do what they do best: cut costs by laying off their workforce and increasing bonus payments at the expense of the consumer. Go try to use a chatbot customer service function for any major health care provider and you will already see how implementation of AI - and the replacment of human workers - ultimately hurts customers first and foremost. ",,,,,,,
"OSTP-TECH-2023-0007-0108","OSTP","OSTP-TECH-2023-0007","ljr-j520-sj3i","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI art is built on a foundation of nonconsensual art theft. It mimics the unique styles that real human artists have taken years to painstakingly create and learn. A medium that is meant to be expressive, heartfelt, and HUMAN has been stripped of its core values and there are many who try to pass it off as the same thing. AI must only be trained with pieces that are in the public domain or have been given explicit approval by the artist. It needs to be labeled so viewers, even those without a trained eye, will immediately be informed that it was created through AI. Human artists need to be protected so that the art they make while employed at a company won’t automatically be used to train AI for the company’s future use. We need to protect the humans who love to create, but also need jobs to survive. I cannot imagine living in a dystopian society where AI creations are more prevalent than something created by a human, and where AI can freely steal ideas and techniques that artists have mastered over decades in the span of a few seconds. AI art training and usage needs to be restricted, monitored, and limited. Protect people.",,,,,,,
"OSTP-TECH-2023-0007-0109","OSTP","OSTP-TECH-2023-0007","ljr-jbcm-hf9m","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is critical that decisions made by algorithms both be heavily vetted for bias and also that their output is traceable and reviewable. There should also always be a real person who is legally responsible for the outcomes of these systems. They should not be empowered to make decisions about healthcare or law enforcement without explicit human approval for each case. ",,,,,,,
"OSTP-TECH-2023-0007-0110","OSTP","OSTP-TECH-2023-0007","ljr-j3m7-7y7d","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find our contribution attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0110/attachment_1.pdf",
"OSTP-TECH-2023-0007-0111","OSTP","OSTP-TECH-2023-0007","ljr-jgrk-pxn0","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To the Office of Science and Tech Policy. I am an artist. A small one. Who hasn't yet made it like some others have.

I come to you about the strategy on the so called ""AI"" programs that these new companies that cropped up in the past year have put out.

Whether it be music, visual art, writing (creative or otherwise) and more. These Machine-Learning Algorithms (not AI) present a very real existential threat to artists everywhere. Very many of the models currently in use, make their training data literally on the backs of living, breathing, human artists, and the data and images of millions of people, both public and private.

Emad Mostaque, Sam Altman, and more have created companies using private and public data in unauthorized uses to create these programs. The most infamous batch of data is the LAION 5B dataset, which -regardless of whether or not it is currently in use- was created under German law by a German company, under the stipulation that the resulting data could only be used for research purposes. Emad then illegally used this data to power his Generative Image Generators, most notably, Stable Diffusion.

This represents an egregious and willful violation of German law, as well as a mass violation of the copyrights of thousands of people worldwide.

Further. They will attempt to sell you on the idea that these ""Artificial Intelligence"" programs see images the same as a human being. This is demonstrably false. It is more easily compared to a overly-advanced Xerox machine that attempts to generate images using shapes, colors, and other features taken directly from images, stored as data points attached to keywords, within it's algorithm. After which it attempts to give, through degenerative processes, a processed image using an average of the data points, via keywords given by a prompter.

There is also the matter of the disingenuous use of the word ""democratization"" in reference to ""democratizing skill"" or similar phrasings, in reference to these programs. The relationship between the user of these programs and the program itself, is accurately likened to being a client commissioning an artist for an image: the user/prompter does not do any of the work of creating the image themselves. The program does everything, regardless of repeated refinement of keywords in prompts given to the program. There is no exercise of skill here, as it relates to the arts of which the creators of these programs say they want them to be used for.

If anything, the use of these programs by and large, by a number of individuals, will create a class of user who have not -and will not- learn anything about the craft or the skills related to such, that these programs are being proposed for. While in the long term might create a class of devout artists who refuse to use these programs for their work, in the short term, it will all but kill artists ability to make a living with their skills, as these programs are made by stealing the data of their work.

As the available data runs dry, Emad and his fellows have also publicly proposed the idea of bypassing firewalls to get at private data to further power these programs.

It is quite clear that these companies creating these ""AI"" cannot be trusted in creating the policies that will be about policing their domain in the market. Much of their work has been about hyping up a technology that does not do what they say it does, and lying further to attempt to gain more funding. The rights and copyrights of artists, writers, actors, and more must be protected. They must not become second to these programs, nor subservient to. Companies must not be allowed to use their data, likenesses, and more, without explicit, written consent, with no extortion or attempts to force said consent.

I leave you with a final statement: I was told a fair many a time, that the dream of automation was to relieve it's human creators of the menial tasks of the world, so that they may better themselves through the arts, philosophy, and more. But within the last year, in real time, we have seen that the Venture Capitalist class like Emad and Sam, have a different vision, one that attempts to automate the very creative endeavors that automation was supposedly going to allow us to do. These ""AI"" must be heavily regulated to protect the rights of those who work so hard to make our world vibrant and colorful through their work.

Thank you.",,,,,,,
"OSTP-TECH-2023-0007-0112","OSTP","OSTP-TECH-2023-0007","ljr-jh9n-jjsl","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative A.I., be it text or image, has built its product by scraping data without consent of creatives and is marketing its product to replace creatives. We should protect creatives jobs and regulate generative AI to use only data for which they have consent and are compensating the creators that made it.",,,,,,,
"OSTP-TECH-2023-0007-0113","OSTP","OSTP-TECH-2023-0007","ljr-j7an-u32p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0113/attachment_1.pdf",
"OSTP-TECH-2023-0007-0114","OSTP","OSTP-TECH-2023-0007","ljr-jfux-ac4u","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I have been working as a technology journalist for more than two decades and I'm writing to you today with my concern not about the tech behind AI but the massive copyright violation that underpins what we call ""machine learning."" I should note that I am writing to you today on behalf of myself only and not my employer, who has taken no official position on this matter.

In order to train their models, companies like Google, OpenAI and Microsoft have scraped the open Web for information, incorporated that information into their chatbots and then used it to spit out responses that look like the software is ""smart"" when in fact it is just plagiarizing copyrighted materials without the consent, compensation or (usually) citation of the copyright holders. This happens with text content as well as images, video, audio and even human voices.

Google launched in beta its Search Generative Experience (SGE) which is expected to replace the top of its regular search engine with results from its chatbot, which – without permission and usually without citations – takes information that was written by actual publishers and journalists, changes the wording around to avoid being traced back to its original source and pretends that Google itself did the research.

I wrote a detailed article describing Google's plagiarism and copyright infringement here (https://www.tomshardware.com/news/google-sge-break-internet). 

What's going on here is not machine learning, but a massive plagiarism scheme where Google is using its monopoly-like position as the top search engine in an attempt to put journalists out of business so it can keep all of the eyeballs (and therefore revenue) on Google.com rather than sending clicks out to the websites that are actually doing the work it is stealing from. 

This hasn't just caught my attention. Barry Diller, who is chairman of IAC, recently remarked that publishers should sue AI companies for copyright infringement (https://www.businessinsider.com/barry-diller-media-companies-should-sue-ai-makers-using-content-2023-4). 

Once Google replaces the top section of its search engine with a chatbot that is stealing data from publishers, those publishers will lose significant portions of their revenue because most of us rely on search clicks from Google to drive reader visits which lead to ad revenue and further ecommerce clicks. Many news organizations will go out of business and likely thousands of journalism jobs will be lost at a time when our country and democracy need them most. Many of these jobs, like mine, are here in New York.

Most publishers don't want to talk about this publicly because they depend on the good will of Google for the traffic they have now and they don't want to get on the company's bad side.

Google certainly doesn't owe anyone listings or clicks, but what they are doing now is changing from being a search engine into a publisher and then putting their own AI-published content above that of the sites it is plagiarized from. This is extreme anti-competitive behavior.

The clear solution to this problem is that AI software MUST be forced to respect intellectual property and copyright. In order to use content in training data, AI companies should have to obtain affirmative consent from every publisher whose work they wish to use as ""training data."" It would help if they also got consent from individual users whose social media posts are being scraped. That consent should be independent of being listed in regular Google or Bing search (you should not have to opt into the LLM in order to be listed in search results). 

And, even if you have opted in to have your content used for training, all information provided by chatbots should have to cite and link back to its original source. If the chatbot tells me the sky is blue, it should have to link back to the website where it got that information. That would allow readers to know where the chatbot's information came from so that they can make an informed decision about how trustworthy it is.

Thanks in advance for any help you can offer in standing up for the rights of journalists and artists whose work is being stolen right now and whose livelihoods are at risk.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0114/attachment_1.png",
"OSTP-TECH-2023-0007-0115","OSTP","OSTP-TECH-2023-0007","ljr-jifi-4omk","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Attached is the Bipartisan Policy Center's comment letter.  Please do not hesitate to reach out to [REDACTED] with any questions you may have or if there is any additional information that we can provide.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0115/attachment_1.pdf",
"OSTP-TECH-2023-0007-0116","OSTP","OSTP-TECH-2023-0007","ljr-k18p-wl6d","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI image generators are not real artificial intelligence. They are just an algorithm, and they cannot function without the disgusting amount of work stolen from visual artists, photographers, musicians, and writers. Not only is the promise these scummy tech producers completely false and based on the majority of people failing to understand how they actually work, but they completely violate the rights of creatives who own the copyrights to their work. It is nothing but a grift they pander to talentless, lazy people who would rather steal than spend the time and effort we did to learn our crafts. Furthermore, it is nothing more than a tool for executive businessmen (who know nothing of our work) to devalue creative work and attempt to replace and/exploit creatives.

Holding meetings with only the offending party about how to regulate AI completely disenfranchises every single victim they are stealing from to make a quick buck. Artists from all mediums should be the vast majority of those who are consulted.",,,,,,,
"OSTP-TECH-2023-0007-0117","OSTP","OSTP-TECH-2023-0007","ljr-k3qo-mtj9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As an artist I spend hours, if not days conceptualizing ideas and working on an illustration with the purpose of selling that illustration or promoting my work for someone to hire me, since the rise of AI this became difficult, since the AI companies are using the works of hundreds of artists like myself to make their software work, none of those artists are getting the compensation or credit for that, nor did we were asked if we wanted to be a part of this. Instead our jobs and livelihoods are being threatened by AI. If a song, drawing, 3D model, voice or likeness of a person are used in other software or media a license is required to ensure a fair compensation, AI companies have ignored that premise with the pitch of helping humanity and creating progresss, wich is not the case, since the AI technologies became popular, artists have struggled to sustain our livelohoods, some suggest that changing to AI will secure our lives, but it's not looking like that will be the case, when everyone can easily make use of our work to generate AI images, most of the people won't hire other people to create an image, instead people will use those AI technologies directly creating a risk of creating a monopoly of data and content generation. When AI become more popular it will be difficult to even sell an AI generated image considering people can generate one themselves, so it's not even a sustainable market for artists to have, the only ones who benefit are the AI companies. People are losing their jobs and artists can no longer sustain their livelihoods, so there is no progress in the actual use of AI, humanity is not being helped by the actual use of AI, people are getting replaced by AI in the artistic field and soon in many other fields. If generative AI it's going to stay it must include timed licenses around the data used and be limited to the use of data obtained with explicit consent. If a song of an artist is on the internet and i can listen to it, it doesn't mean it's free for me to download, or use with commercial or industrial purposes, same goes for everything else.",,,,,,,
"OSTP-TECH-2023-0007-0118","OSTP","OSTP-TECH-2023-0007","ljr-jwuz-2dzc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0118/attachment_1.pdf",
"OSTP-TECH-2023-0007-0119","OSTP","OSTP-TECH-2023-0007","ljr-ktaq-ed69","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative ai needs to be heavily regulated and made illegal to monetise, the spread of it is causing people who cannot get a normal job to lose most or all of their income as people go to ai instead of human beings to get things done. It is a threat to human creativity and a insult to humanity",,,,,,,
"OSTP-TECH-2023-0007-0120","OSTP","OSTP-TECH-2023-0007","ljr-kuos-g619","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI, as it stands right now, is blatant plagiarism at best, and just another tool for scammers.",,,,,,,
"OSTP-TECH-2023-0007-0121","OSTP","OSTP-TECH-2023-0007","ljr-kwx6-ukvy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The so called Artificial Intelligence technology that this year has become popular has becom not only an hindrance, but also a shameless violation of human rights all across the board, affecting even countries and individuals outside the USA, with many industris being impacted in a way that individuals are losing their jobs left and right because the AI can do their jobs, but having acquired such capacity by scrapping all kind of information from the internet and netizend all around the globe.

This is not a plead against progress, but rather an attention call for the ethical development of such technologies, a government can't turn a blind eye to something that has proven time and time again that it will steal jobs, identities, and even worse can be used to fake words, audio, video, pictures, etc. with criminal intent.",,,,,,,
"OSTP-TECH-2023-0007-0122","OSTP","OSTP-TECH-2023-0007","ljr-l2e6-fj8y","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There are many great questions being posed for this policy. As a visual artist who makes my living from my artwork and artistic skill honed over years of training and practice, measures MUST be taken to ensure that the work of artists (of all kinds) and writers and photographers cannot be used, without our express consent, in large data models. These models that, not only steal from us our own private data or copywritten work, but then use it in generators that will effectively replace us using that stolen work/data by corporations and others. Our livelihood and works are under severe threat by Machine Learning, which in turn will damage the economy in multitude ways. Multiple sectors that are built of the work of people will be swept away due to corporate greed to keep one more buck and pay us less. If we aren't able to work, if there are fewer jobs, if we're not able to provide for ourselves and contribute to our economy, what is the point of AI in the end? Like I said, many good questions are posed for this policy, and the best ones to ask is, who is helped by AI? Is it the common person, whose work is stolen by these datasets and used against us? Or the does it help the corporation by eliminating jobs that should be held by humans? Humans that help build culture with their art. 

I'm asking, please make AI/Machine Learning and it's owners accountable, don't leave people behind who make the art that these generators need to work at all. ",,,,,,,
"OSTP-TECH-2023-0007-0123","OSTP","OSTP-TECH-2023-0007","ljr-l5px-8df6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I'm reaching out to express my deep concern about the increasingly detrimental impact of Artificial Intelligence (AI) on the creative and performing arts community. I urge that the following issues and potential solutions be strongly considered for inclusion in the National AI Strategy:

    AI and Copyright Infringement: AI has been mimicking artists' works with slight alterations, creating a space where artists are unfairly competing against machines. We need regulations that clearly classify such activities as copyright infringement, thereby protecting the creative rights of artists.

    Opt-in for Artists: Datasets used by AI art programs often include works of art scraped from the web, without obtaining express permission from the artists involved. The strategy should promote a consent-based 'opt-in' approach for artists to have their works included in such datasets, thereby ensuring respect for their rights.

    Labeling AI-Generated Content: There are instances where AI-generated images are being used to spread misinformation and inappropriate material. Mandating clear labels for AI-generated images would be a step towards preventing such misuse.

    Protecting Voices and Likenesses: Voice actors and performers have had their unique voices and visual likenesses used without consent in commercial ventures and digital products. We need legal mechanisms to shield these individuals from unauthorized exploitation.

    AI Art and Commercial Use: The commercial use of AI-generated art, which often uses copyrighted data without proper permissions, raises important ethical and legal questions. These derivative products should not be granted copyright status, even if modified by human hands, and should always be clearly labeled as AI-generated.

I also wish to draw your attention to some concerning trends:

A. Employers are using the artwork of job applicants and employees as AI training data, instead of providing fair compensation for their work.

B. AI's capacity to mass-produce content has resulted in a deluge of duplicate works on online marketplaces, which dilutes the value of original creations and undermines the integrity of these platforms.

C. AI technology has been used to generate explicit material featuring real individuals, including women and minors, without their consent, raising serious privacy and ethical concerns.

D. Artists are being forced to either invest heavily in protecting their intellectual property rights or withdraw their presence from the internet entirely, seriously affecting their work and livelihood.

E. The voices of notable musicians and voice actors have been replicated by AI and used in commercial settings without their permission, violating their rights and potentially leading to misuse in harmful contexts.

The issues outlined above illustrate the urgent need for stringent regulations to protect the rights of artists, voice actors, and other creative individuals against the misuse of AI technologies.

In summary, I propose that the National AI Strategy must implement robust policies that defend artists' rights, maintain the integrity of the artistic marketplace, and ensure that artists can continue to create without fear of unjust competition from AI. By so doing, we can create a future where innovation, creative expression, and AI exist in harmony.

Thank you for taking these suggestions into consideration as you continue your work on the National AI Strategy.

Sincerely, a concerned citizen.",,,,,,,
"OSTP-TECH-2023-0007-0124","OSTP","OSTP-TECH-2023-0007","ljr-lccb-az7z","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a young adult looking to venture into the creative field for a career, the current model of generative AI is exceptionally harmful. The data scrapped from all corners of the internet involving art without the consent of the creators to train these image generators are barely being missed as what they truly are, art theft. The work of many famous artists have been stuffed into these datasets to train these image generators to mimic their style and expression. These tools harm extend far past the immediate damage of art theft from those who have greater experience, but it also damages the perception of people like me. Beginner and aspiring artist have been torn between truly pursuing their passion as a career path simply because these tools can learn infinitely faster than a human can. People knowing that have been using it to substitute artists for things such as, book covers, web comics, and even using it as an alternative to commissions. People have even been promoting generating and selling AI art as a way to make easy money on the side with little effort, which is extremely harmful considering how these AI models were trained from art that was taken without the creator's consent. The sad truth of the current model of generative AI is that it will take advantage of experienced artists, shunt less experienced artist out of the field, and ultimately harm all creatives across the board. Lastly I would like to bring up the solution I personally think is most effective at reducing the harm done by these AI image generators. Firstly they should scrub the databases clean of all artwork and images they do not have the consent to use and include, secondly any platform that they are scrapping these images from should have an opt-in policy for data scrapping for AI generators that must be opt-out by default. These two changes would undo the harm done to the creatives whose livelihoods were harmed by the quick rise of this new technology. ",,,,,,,
"OSTP-TECH-2023-0007-0125","OSTP","OSTP-TECH-2023-0007","ljr-lsnn-wt1w","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please be aware of current harms being caused by ML usage, don’t focus on science fiction.

People are losing their jobs. Disinformation is being enabled more readily than before. Privacy is being violated. Surveillance augmented by AI is happening. This will all only get worse with ML for profit.

There is only one root cause of all the problems with ML.  That is greed.  It is in fact quite simply solvable in this case, then you will be able to reap all the economic benefit while your economic competition fails.

- Tax all direct and indirect profit from ML at 100%, constitutionally ban government and government agency usage.

This might on the surface seem extreme, however it cuts straight to the chase and if you compare it to the alternative suggestions you will find it more workable and flexible, more in the public interest and more in the economic and governing interest.  It doesn’t eliminate or criminalize ML, there are still non-profits, open-source all the secondary benefits to society and economy, it just hits the motive behind all the bad usage, and that’s the thing, the problem isn’t ML itself it’s people using ML in bad ways.

So why does this make any sense? Because once you take into account human behavior ML for profit it turns out is really bad for profits.

ML eliminates market leverage. You’re familiar with the traditional model of automation, where it creates industry disruption but then enables new roles and increases profit margins. Many will claim that ML will do the same. This is not true, because it forgets that the profit equation has two terms, Profit = Income - Expenditure. Everyone has access to ML, it’s cheap, fast, idiotically simple to use and has already been proven capable of replacing individuals in the workforce for certain roles (which will expand over time), your competitors and clients have access to it. If you are only a broker in this chain of information then you are unnecessary overhead, not adding value. Without market leverage your income will not maintain at higher proportion to expense, which is what is required for profits.

In essence you will see a small bump in profits from ML, but longer term as it improves you will only see dramatic losses. Not just individuals losing jobs, but companies being cut out of the chain, and finally whole industries. It is more convenient, cheaper and faster to go direct to the source. One day you will have no Hollywood because consumers will go straight to an ML and say “make me a new episode of Bobs Burgers” and that will be that. Every person employed in the chain out of business.

You might think “but that still leaves profits for the AI company that we can tax”. Unfortunately not much. AI trivializes what it does, it’s simply supply and demand, increase the supply almost infinitely, demand drops.

You then might think “but people will retrain into new roles, new opportunities will arise from AI!”. However AI is a general automator, there is nothing you can retrain into that it cannot be made to do except manual labor (currently). There are no indicators of new roles from AI. “Prompt engineer” was a joke, a good example even, ask a LLM to generate a prompt for you to use with an ML, it’ll do a better job than humans. Opportunities with ML are just missing features.

This means AI for profit is going to be killing opportunity for millions. Eliminating whole industries and eliminating profits and GDP.  How bad? Well 80% of your GDP is intangible goods and services, that’s stuff AI is poised to do. Your manual labor market <20% is saturated already. You face a humanitarian crisis.  Your budget is 20% of the GDP, imagine that gutted.  Now the entire US GDP is $4.5T, your taxes amount to <$1T. Knock on effect is luxury industries fail. Attempt to offer dole or UBI would cause hyperinflation even with that massive deflation. USD fails. Civil unrest. Government Fails.  You just fell into the trap.

So how about government? - ML eliminates accountability. The purpose of bureaucracy isn’t just to handle paperwork but to diffuse power and reduce reactivity. ML is too powerful a tool to eliminate this and create a one way membrane feeding autocracy. It doesn’t matter that you may be good, the next person may not. It requires everyone to be exemplary which is inhuman.  In fact there isn’t a usage scenario that doesn’t lead to dystopian results, surveillance state etc.

In all cases it eliminates opportunity for the majority.

As for disinformation, the two biggest generators of disinformation are business and government, the third being crooks. Crooks by definition do not follow law, so you can only combat them with equal tools, something non-profits and the open-source world is capable of. The risk of loss of revenue by hosting ML content will incentivize online services to eliminate ML generated content including misinformation, safeguard peoples data from scraping.",,,,,,,
"OSTP-TECH-2023-0007-0126","OSTP","OSTP-TECH-2023-0007","ljr-lg14-a1ut","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0126/attachment_1.pdf",
"OSTP-TECH-2023-0007-0127","OSTP","OSTP-TECH-2023-0007","ljr-lvuk-tin6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dear Regulations(dot)gov, 
       Artificial Intelligence is currently unregulated, and unethically scraping data without the consent of creatives such as visual artists, musicians, and writers. This is infringing on copyright. Please consider the strict regulation of Artificial Intelligence so that it does not violate working creatives' rights. Thank you for your time. ",,,,,,,
"OSTP-TECH-2023-0007-0128","OSTP","OSTP-TECH-2023-0007","ljr-md7p-kozm","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I  am really passionate artist that had been living off my work for some time now. However, due to the recent influx of AI generative, there had been damage done not only to my work but also self-being. 

I am not the only one in this - many people whose work has been illegally scraped (stolen) and used in generative AI programs, are now facing critical life situations  - which only proves that the harm has been already done. We can see how AI generative tools are used for mass misinformation, and illegal and harmful content that damages the lives of people.

Nowadays, people are wondering who will be next to lose their livelihood: is it going to be doctors? Tech people? Teachers? People working in offices? Who will be next to be forced to quit or be fired due to the injustice and creation of unfair competition that is being misused against people? How many marginalised people whose sole income comes from art, music, and writing can survive now? And they will not be the only victims of this procedure. 

The only way for AI generative content and AI overall to be considered trustworthy, is to make sure that the system is being regulated not by the owners of said program, but by people who will not benefit from it themselves. To make sure that AI programs do not cause further harm, it is important to remove whole data and only allow people who are WILLING to input their information, work and other assets there - unlike how it was now stolen, taken, and inherently created greatest data, art and information heist in the whole world.

It is also important to remember how easy it is to create fake, harmful messages using AI now. Nothing stops people from creating harmful content about anyone in the world - and especially people that have their names known to the public. The amount of content that was generated using voices, faces, bodies, and other fragments of human beings to cause harm, misinformation and damage to their lives, reputation and well-being is unimaginable - and it is only the beginning of the end.

The CEO of OpenAI Sam Altman himself said at the meeting that ""If this technology goes wrong, it can go quite wrong"" so how can we ourselves blindly follow the idea that things will be fine without regulations protecting humans and our creation if even the CEO is afraid of his creation? I believe we all had seen movies about it - and we need to be smarter than the people from these universes.

It is crucial to work fast to ensure that the danger that AI imposes on all humanity is lowered or fully erased. To ensure that we have rules that clearly say that AI-generated content cannot be used by companies if there is a chance that it can cause unemployment, damage to livelihood and other harm to the well-being of a human that works for them, as well as to not cause mass misinformation, disinformation and other forms of lies and propaganda that these places could create using AI.

I believe that at this moment, we should focus on ensuring that AI-generated content, and all AI-things related, should be heavily regulated, with an emphasis of copyright safety. These machines would not exist without millions of stolen pieces of art, music and text. We should ensure that people who had been harmed by this practice, are compensated and can feel secure that their skills, knowledge and efforts are not treated as something that can be taken and then people would defend themselves with false usage of ""fair use"". We also need to make sure that AI gen content CANNOT under any circumstances, be protected by copyright law, and to make sure it cannot be used for commercial purposes. 

AI can be used for good, and this is much true. However, we need to be aware that at this time, AI content and AI itself created a harmful environment that will only be worse, when in time everyone will be replaced - even the government.",,,,,,,
"OSTP-TECH-2023-0007-0129","OSTP","OSTP-TECH-2023-0007","ljr-mrfc-n8x6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0129/attachment_1.pdf",
"OSTP-TECH-2023-0007-0130","OSTP","OSTP-TECH-2023-0007","ljr-mxaj-g1r5","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments from the Information Technology Industry Council (ITI). ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0130/attachment_1.pdf",
"OSTP-TECH-2023-0007-0131","OSTP","OSTP-TECH-2023-0007","ljr-oj8b-59ky","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"About generative AIs
These programs dont seem to go at all in the direction of progress so far. There are already countless examples showing how harmful it can get when used as a disinfomation tool and it will only get worse. Knowing how fake news were already a thing before AIs, I can only imagine how it will go when giving anyone the possibility to create in seconds life-like pictures representing absolutely anything or anyone in any situation. Generated content such as images or videos should be automatically and indelibly taged with an easily recognizable marking that would require editing skills and time to get rid of. Possibility to generate content featuring specific existing individuals or locations should be made impossible.
Generative AI programs only work from a gigantic mass of data mostly stolen from the internet, scrapping every message, article, picture without ever asking consent, therefore bypassing intellectual property rules. Datasets used by AI programs should be made accessible and any copyrighted material removed.
Uncontrolled development of generative AI will most certainly lose millions of jobs in every possible field. I am working in a both highly technical and creative field, and paying close attention to AI development for the past two years. I heard countless times ""these are just tools, you need to adapt"". The truth is, they're not just tools, their purpose is to replace the entire human work process. Whether it is code, text, visuals, final output is always a seemingly finished product. Flawed, most of the time incorrect or uninspired, but seemingly finished and this is what will lose people jobs. Thinking that those jobs will transfer to AI managing roles (""prompters"") is also non sense, AI programs are already able to prompt themselves, no human needed here. Lay offs resulting from a comparison between a human worker and the output of any AI program should not be allowed. Companies should only use datasets that are either made of royalty-free material or original material created by the company itself. 
Also heavily concerned about the way AI programs seem to reproduce human discriminatory behaviours ",,,,,,,
"OSTP-TECH-2023-0007-0132","OSTP","OSTP-TECH-2023-0007","ljr-olx5-wjkj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello,

Although I've read through the concerns you are currently looking to tackle and it seems to slightly align with my own concerns I would like to take this time to comment as an artist and someone who will be effected and is currently effect by AI technology. Currently, there is no regulation for orgs like stable diffusion and mid journey which have built their datasets off of the backs working artist's work without their consent or compensation. What we currently have is basically an art theft machine that is being branded as a replacement for hiring those very same artists (I encourage you too look into the stable diffusion litigation). It's unfortunately already started to happen eg the incident with Disney's Secret Invasion. You need to hold these big companies accountable because they will seek any opportunity to screw over artists and get out of compensating them. Smarter people than me have already come up with solutions and suggestions such as... making sure AI generated works are labeled publicly as such... with the backlash AI generated works faces many people seek to hide that they are using AI to create art and thus profit off of other people's proprietary work, we need to hold them accountable. Whilst protecting smaller creators is my priority it's also worth noting that these companies have also stolen copyrighted works from huge companies and that could generate an even bigger backlash and court cases because if there's one thing I know about big media conglomerates... it's that they are pretty die hard about protecting their intellectual property. This doesn't even begin to get into the security risks of these programs scrapping personal and private data.... So please when making these regulations please make sure you're talking to industry professional artists and writers... many already have spoken out quite loudly but please take those people into account when making these regulations. 

Thank you so much for the opportunity to comment. ",,,,,,,
"OSTP-TECH-2023-0007-0133","OSTP","OSTP-TECH-2023-0007","ljr-ow46-ikke","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am highly concerned about the training for AI models. Grabbing material with no regard for copyright and no way to opt out before or afterwards seems like a disaster.",,,,,,,
"OSTP-TECH-2023-0007-0134","OSTP","OSTP-TECH-2023-0007","ljr-oj93-vx7g","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On behalf of the Center for AI and Digital Policy (CAIDP), we write in response to the Request for Information (RFI) on the National Priorities for Artificial Intelligence.  In our response attached we’ve addressed the specific questions posed in the RFI. Our key recommendations are as follows: 

1)	Ensure the development of human-centered and trustworthy Artificial Intelligence based on fundamental rights, democratic values, and the rule of law 
2)	Prioritize investment in AI systems that are innovative and ensure public safety 
3)	Establish guardrails for AI based on transparency, contestability, traceability, robustness, safety, security and accountability. 
4)	Implement the OSTP AI Bill of Rights, the OECD AI Principles, and the UNESCO Recommendations on AI Ethics
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0134/attachment_1.pdf",
"OSTP-TECH-2023-0007-0135","OSTP","OSTP-TECH-2023-0007","ljr-pgf0-4lbg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative AI threatens to eliminate jobs from creative fields and more all across the country and world. It will especially hit entry and mid level designers, voice actors, artists, etc the most at the concept stage and expand if AI keeps improving feed and effectiveness over the cost of human labor. This threatens to possibly put millions of people who have worked hard on our crafts our entire lives out of work. And its all done by scrapping the data provided by the people who it threatens to unemploy. There is absolutely no ethical generative AI at this time, it all only exists by being trained on someone elses work, mostly without consent, and almost always without any type of compensation. And compensation doesnt add up to replacing an actual salary, no matter what these companies promise. We've seen this with spotify and youtube, now we're seeing it in other creative industries. ",,,,,,,
"OSTP-TECH-2023-0007-0136","OSTP","OSTP-TECH-2023-0007","ljr-qe7f-kgmg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The United States government needs to ensure that data used to trained Large Language Models (LLMs) and other AI models is obtained only with permission and without violating the copyrights and privacy of its owners. Companies such as OpenAI and Stability AI have taken advantage of the country's outdated stance on web scraping to build and train their AI models, which has lead to many ethical and legal concerns such as:
1. The violation of artists' copyrights due to improper use of their work
2. Privacy violations of people who's faces and bodies were used in training data without their permission 
3. Grealty increased ease for people to create deepfake pornographic imagery of any person.
4. Increased ease to create deepfake and simualted imagery. This is especially concerning as these kinds of deepfakes have already lead to disinformation campaigns that seek to undermine democratic elections.
5. Increased unemployment. Many companies, in an effort to reduce cost, will inevitably attempt to replace parts of their workforce (such as artists and writers for media and entertainment companies) with AI tools. Many of these professionals who will suffer job loss that will have no equivalent replacement, and will have to find a new skillset that was replaced. If unchecked, AI tools could send the entire economy into an era of unemployment and poverty unlike anything seen in American history. 

",,,,,,,
"OSTP-TECH-2023-0007-0137","OSTP","OSTP-TECH-2023-0007","ljr-qean-srv4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative AI without any regulations poses a serious threat to safety and privacy of all individuals. It is linked to heinous usage, creating deepfakes of people and even minors without consent, as well as ripping the likeliness of an artist's body of work - including but not limited to visual artists, voice actors, writers of all industries, etc. 

AI has its uses in research, but generative AI in the form of Stability AI etc as what we see today is not beneficial to humanity as a whole. It is exploitative and favors the elite wealthy at the expense of the stolen labor of the working and poor class from all over the world - breaching the data security laws of other countries. 

Look into the LAION5B data set, which is being used by for-profit businesses like Stability AI and Midjourney and Deviantart, and how LAION took the data is by a loophole of using it as a nonprofit to bypass laws and needing to get consent from the copyright holders of the billions of images they used to train it.

You wouldn't build a product with stolen parts, why allow corporations to get away with it?

Again, this threatens the wellness of the people at large, including future generations. It is imperative that it is put to a halt and restructured so that, if companies wish to make AI generators, they do so by means of consent, rather than being allowed to scrape the internet for whatever they want, whenever they want.

Thank you.",,,,,,,
"OSTP-TECH-2023-0007-0138","OSTP","OSTP-TECH-2023-0007","ljr-q2un-0jkk","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0138/attachment_1.pdf",
"OSTP-TECH-2023-0007-0139","OSTP","OSTP-TECH-2023-0007","ljr-ql9x-5wd5","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello I am an artist and have had work stolen by AI. AI had used my peices without recognition or payment. Creativity is a central fuel for the American spirit and AI is posing a serious risk to the ability to create and be appreciated for art ",,,,,,,
"OSTP-TECH-2023-0007-0140","OSTP","OSTP-TECH-2023-0007","ljr-qlk2-3968","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Yes! Please do something about AI. I know many writers, artists, and even voice actors that are being negatively affected by it. ",,,,,,,
"OSTP-TECH-2023-0007-0141","OSTP","OSTP-TECH-2023-0007","ljr-qo21-kow0","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI is very destructive to artists in all industries and unethical. Not only because it takes away jobs but it sources from artists without their consent and I feel that should break copyright.",,,,,,,
"OSTP-TECH-2023-0007-0142","OSTP","OSTP-TECH-2023-0007","ljr-qrxi-gxhg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI needs to be regulated. So many artists, writers, voice actors, and many more are being negatively affected by it. There is no consent with what AI and it’s databases are doing. It is stealing from hard working individuals and now people want to replace us with Ai. AI can not think or feel as people do. It is a machine that is used as a gateway to take the easy way out and steal from others. Art is a human experience created by humans to convey the stories of our lives, cultures, feelings, thoughts, and experiences. AI can’t replicate that. All it does is take away more and more of what the human experience is and take away from so many talented hardworking individuals. Entire industries will die from this, and it won’t stop at just artists and entertainment. If it continues it will lead to other aspects of life and work and try and outsource everyone. AI needs to be stopped and regulated. It is dangerous and harmful. ",,,,,,,
"OSTP-TECH-2023-0007-0143","OSTP","OSTP-TECH-2023-0007","ljr-risl-n84k","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file for our comment! ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0143/attachment_1.pdf",
"OSTP-TECH-2023-0007-0144","OSTP","OSTP-TECH-2023-0007","ljr-rx0b-b75g","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Copyright was created so that no one could be forced to compete against their own work in the market. Why should a company choose to pay an artist when they can get their work for free. AI that scrapes data from unwilling creatives forces us to compete against our own work, it's actively and directly eroding copyright protections for working artists. All scraping for ai must be made explicitly illegal, our copyright laws already disallow it but ai companies squeak by in loop holes lobbying to expand them against working artists. We cannot survive under opt out language, it puts the onus on individual artists to somehow track down every company that has stolen our work while they obfuscate what they've fed their algorithms, and allows them to close shop and open under a new name with the same stolen work once they receive too many opt outs. It must be opt in only, artists knowingly entering into a contract in good faith or what are our copyright laws for if they do not protect us. AI companies will say they are tools that help artists but we artists have existed throughout time without them and we do not need their help for the price of our work. ",,,,,,,
"OSTP-TECH-2023-0007-0145","OSTP","OSTP-TECH-2023-0007","ljr-rxog-st0c","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI is theft. 
AI takes advantage of and suppresses the work of actual humans, exploiting their labor and creative acts to allow already rich men to take more money from the populace. AI scraping artwork and files and documents without consent is an invasion of privacy and should be illegal.",,,,,,,
"OSTP-TECH-2023-0007-0146","OSTP","OSTP-TECH-2023-0007","ljr-robv-2hfy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Deep fakes are a threat to society's stability. So long as AI is unregulated and encouraged in it's current form, nothing on the internet will be real at this rate. We'll only have deep fake porn, deep fake attacks on politicians, and fake information. GenAI in it's current form is simply destructive to humanity and destroys jobs. It doesn't help humans, it helps corporations. And I don't want that.

GenAI is also pure theft in it's current iteration. It cannot produce anything that doesn't already exist. Attached file makes the point.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0146/attachment_1.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0146/attachment_1.jpg",
"OSTP-TECH-2023-0007-0147","OSTP","OSTP-TECH-2023-0007","ljr-sa6o-e7hf","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There are many different potential uses for AI that can prove useful in the field of research and study as well as building a whole new social structure, but that biggest concern that I have with AI is how it is currently being used in the art scene recently. The artistic field can and has went through scientific or technological advancement in the fields of animation, motion captures and three-dimensional modeling and even more traditional methods such as painting and drawing which have aided artists ten-times over. Just recently Disney/Marvel released a fully animated sequence done completely in AI lasting for at least a total of one-minute long. As someone who has studied in the field of animation a single minute of footage is can be a total of 1,440 frames if done at 24fps, or even 3,600 frames at 60fps which is becoming the new industry standard. In total there would be multiple people working on these frames anything from sketching, to final drawing, coloring, and even video editing when it would be required all done by separate and multiple individuals. Disney as a company is suppose to be a large provider of jobs in the workforce for a many different fields, ranging anywhere from their general Disney stores found in malls and outlets across the country, to their animation and film studios and especially their theme parks scattered world wide. Given the recent work climate and economic standing today, reducing jobs in these fields is the last thing that needs to be done. Especially if they were planning on having an AI be the replacement of these jobs where there might only be a few people involved in the production process only doing as much as typing a few key phrases into a database and have it be self generated. There have been some instances where “artists” haven even used the image of another artist’s work and placed it in an AI generator and then used the final result as one of their own pieces of work. This is outright theft if I’ve ever seen it. Artists collectively are standing up against this category of AI generation, and we will continue to do so until something is done about it. Multiple of art platforms where artist would share their work for either jobs or even just share for the sake of sharing; have methods on protecting artists from such theft of work, one major artist employment website being ArtStation where you can find both working professionals of the field and free-lance artists all denying the use and practices of AI generated artwork. There are very few instances where I see the use of AI generated images ok which are normally in the form of camera filters on social media platforms such as TikTok and Snapchat, or to use to help use a reference for our own work to aid in coming up with an image or idea to paint or draw or even to aid in generating a color pallet to use. Not using the image itself as the artwork. Thank you.",,,,,,,
"OSTP-TECH-2023-0007-0148","OSTP","OSTP-TECH-2023-0007","ljr-th1o-16nb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0148/attachment_1.pdf",
"OSTP-TECH-2023-0007-0149","OSTP","OSTP-TECH-2023-0007","ljr-u3s0-8o7f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current AI is trained on information with complete disregard for whether the material is harmful.
Copyrighted material, pirated material, other illegal material, misinformation, possibly even leaked classified material has been ingested into these machines and at anytime could spit that information out in a way that harms individuals, rightsholders, groups, even the United states. As it stands the most popular/high-profile uses (chatbots and image generators) are defamation, misinformation and infringement machines whose sole useable purpose is the replacement of humans in the workforce. There is virtually no public benefit to these most high-profile cases for the immense risk they pose to peoples livelihoods, safety, privacy etc..
There are two pillars that are absolutely essentially to ensuring this technology is a force for good as opposed to exploitation.
1. Consent from rightsholders/permission to use online data.
2. Transparency in all systems, so that point 1. can be properly assessed and to prevent the spread of misinformation.

Copyrighted information, medical records, PII, and other sensitive material can only be used as training material with the the consent of those it affects (rightsholders). individuals should be free license their data for training with whatever compensation they feel is sufficient, and the use of this material for AI without consent should be a crime. IT CANNOT BE AN OPT-OUT SYSTEM. Because the information ""memorized"" by an AI model cannot be removed, it is imperative that all data the AI is trained on is OPTED IN with the knowledge and consent of the rightsholder that the information cannot be removed if opted in. Any opt-out system is worthless when people may have any number of reasons to not be aware of their information being fed into the machines, and they cannot have it removed from models retroactively. This information management is only possible with mandatory disclosure of the sources of ALL training data, so that it can be determined whether the possession of that information is against the terms of rightsholders.

As it stands, the most high-profile AI has virtually no positive contribution to society that isn't dwarfed by the massive risks and damages it is already causing. Treaties need to be developed with the similar attention to nuclear weapons so that it never gets to the point where adversary AI can never take full control over critical infrastructure or weapons systems, and make it so that it can never break through encryption.
AI has no value in the propagation of democratic values when the potential to misinform and subsequently influence elections is so great.
I cannot see AI promoting 'good jobs.' Thus far, I have only seen the elimination of 'good' jobs, forcing people into positions they hate and worked to avoid.

Lastly, AI developers should be held accountable for the risks and damages they have introduced to people, and the systems and trianing data must be destroyed and rebuilt from scratch with oversight from all stakeholders (government, developers, rightesholders of data etc...)
In it's current state, there is almost nothing that can be done to bend it into a force for good. It must be reset.
",,,,,,,
"OSTP-TECH-2023-0007-0150","OSTP","OSTP-TECH-2023-0007","ljr-ubrn-inhz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Essentially, large language models and similar AIs in illustration, music, and other forms, are all collage tools and not genuinely creative intelligences.

They take prompts and use them to weight algorithms that ""denoise"" a pure noise source into forms that were originally sampled out of the AI's training materials. For this reason, it is often possible to accidentally or deliberately reproduce those training materials in the final output. This result has been used to demonstrate that all current major commercial AI models have used data that was under copyright, used both without permission and without payment in order to train their models.

The entire current generation of AI is essentially being used to mass harvest human produced content on the internet, remixing it in an obfuscated way to produce output texts, images, etc. Much of the data--both accidentally and deliberately--is sampled from copywritten works. AI, at its core, is terribly harmful to almost all creative industries. It automates mass-theft of copyrighted material and makes the theft process incredibly efficient and self-obfuscating. Already, personal use of AI models has largely been designed to steal the styles of working artists. All LLMs, stable diffusion art AI, and other such tools, will be used to steal the creative output of American workers in order to supplant creative jobs in industries such as writing, illustration, and music production.

Regulation should make it illegal for *any* copywritten work to be used in a training model without the express permission of the original author. No existing license to this point was signed with AI in mind, and these AIs should have to start from zero. Their training data must be assembled, at cost, with human-arranged licenses and not web scraping. Otherwise, they'll be used to steal copywritten material and obfuscate the theft.

Furthermore, all AI training data must be made available for easy perusal by the public, without onerous costs or conditions to the public, preferably at the expense of the model's owners. In this way, users can check for and contest the use of their data and copywritten materials in the training of these models.

As it is, the long-term damage to creative industries will be immense if copyright isn't rigorously and effectively enforced against all AI models. These are art theft programs, and should be treated as such.

This doesn't even begin to consider all the societal harms and political astroturfing that AI will automate for bad actors. Already, people are attempting to harvest AI output to impersonate human comments in order to create an illusion of consensus. The danger there is immense.

Thank you for your time.",,,,,,,
"OSTP-TECH-2023-0007-0151","OSTP","OSTP-TECH-2023-0007","ljr-uif6-gql4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Every business that is working on the development of generative AI must be transparent on every data they’re holding or using to train their models. If they want to use any kind of media (such as images, videos, audios, text, etc.) for training their models they must ask for the permission of the creator of said media or real people whose characteristics were included on it (face, voice, etc.), and they must not use it if permission is denied. AI developers can find agreements with creators to use certain media if they want to use it. They’re free to use media under a public domain license though. Websites where users can upload media must implement the directives “noai” and “noimageai”, offering for users options to opt-in or opt-out from AI training. In order to prevent massive misinformation and people's behavior manipulation, AI generated media or content must be labeled as so in a clear manner for everyone to see. All above must be applied also to prevent the improper use of people’s image in the generation of media such as deepfakes. Definitely there must be oversight to ensure companies are following accordingly. Registration, certification, licensing and stuff must apply to them. AI companies also must be heavily taxed if the AI advancements cause a massive unemployment crisis, so that their profit can be distributed in the form of a basic income for everyone to secure human dignity and quality of life, especially for those that are most underserved. Companies developing foundation models (ChatGPT, Dall-E, etc.) such as OpenAI must not be excluded from any of the obligations from above. If not following accordingly, companies must be severely fined and in most severe cases their AI activity must be suspended. Human artistic and cultural expressions of all kinds must be protected and prioritized. If AI should extinguish any job, it must only took those that are dangerous, degrading, unhealthy or too repetitive and dull. AI don't need to take jobs that people usually have pleasure in doing. Any media generated by AI or created partially using AI must not be suitable for copyright and law protection. High use of energy by large AI systems must definitely be taken into account and AI companies must be committed to collaborate to the environment protection by taking efforts to reduce their energy consumption at the lowest possible level. Those are things that the United States must address and also discuss and find agreements with all governments around the world.",,,,,,,
"OSTP-TECH-2023-0007-0152","OSTP","OSTP-TECH-2023-0007","ljr-umsg-ol0q","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"""AI"" which is nothing of the sort needs to be heavily regulated and any that is using copyrighted material should be shut down and wiped clean.  At no point has any of the so called AI systems been used in any way that is ethical or legal.",,,,,,,
"OSTP-TECH-2023-0007-0153","OSTP","OSTP-TECH-2023-0007","ljr-vpao-155q","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am deeply worried about the future of the United State's economy due to Artificial Intelligence. More specifically I am worried about the future of creative industries such as Industrial Design, Graphic Design, Website Design, Illustration, Animation, and small creative businesses. As of right now several media generating AI companies such as Stability AI, OpenAI, and Midjourney Inc are using large data sets that have been created by scraping the entire internet of images, text, videos, and various other forms of human authored media. A significant portion of the content trained on is copyrighted, yet there seems to be no protections put in place either by companies like Stability AI or by State Governments to restrict and prevent the training of AI models on copyrighted data. There is also no compensation model put in place for the human authors and creators who have had their copyrighted work used to train these commercial AI products without their consent. I hope that the Biden-Harris administration addresses this in future key points for AI governance and future regulations. If an AI media generator is able to train itself off of copyrighted works and produce similar results to the original Human author it has been trained from, how are human owned businesses going to compete in any market that is oversaturated with AI generated media? How is the unauthorized training of copyrighted works not accounted for by the leadership teams at Stability AI, OpenAI, and Midjourney? 

We cannot trust private corporations to self-regulate on matters of data privacy. I would urge the Biden-Harris administration to create a regulatory body that oversees the development of AI products either developed or deployed in the United States as soon as possible. This body should be composed of a diverse range of experts from various minority backgrounds. Each of the datasets used to train AI models needs to be audited by regulatory experts, with unauthorized copyrighted data being removed from the dataset if found. Companies that sell AI generated products like Stability AI, OpenAI, and Midjourney Inc should compensate all human creators who have had their copyrighted works used without consent as training data for commercial AI products. Human authors should be paid a royalty each time an artist's name or brand name is used in a prompt to generate an image, video, text or any other form of media. I am hopeful that the Biden-Harris administration will be proactive in the emerging space of AI technology. AI has many potential benefits for the general public of the United States, but only if corporations are tightly regulated with social ethics as a priority. 
",,,,,,,
"OSTP-TECH-2023-0007-0154","OSTP","OSTP-TECH-2023-0007","ljr-vij7-dydp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In our response, we focus on the need to address safety and security concerns related to general-purpose AI systems (GPAIS) and their foundation models. Building upon our earlier response to the National Telecommunications and Information Agency (NTIA) request for comments on AI accountability, we urge OSTP to adopt a holistic strategy that covers the entire AI lifecycle and a combination of technical and socio-technical mechanisms for responsible and safe innovation.

Our response puts forward the following recommendations:

 1. Create and promote information, cyber, and physical security standards for the development of GPAIS.

2. Fund the development of measurement and evaluation frameworks for GPAIS.

3. Facilitate the adoption of a comprehensive industry-wide code of conduct that institutionalizes responsible behaviors and promotes a culture of safety among GPAIS developers.

See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0154/attachment_1.pdf",
"OSTP-TECH-2023-0007-0155","OSTP","OSTP-TECH-2023-0007","ljr-vwg9-ih18","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Niko Artley, individual citizen
10. What are the unique considerations for understanding the impacts of AI systems on underserved communities and particular groups, such as minors and people with disabilities? Are there additional considerations and safeguards that are important for preventing barriers to using these systems and protecting the rights and safety of these groups?
AI does not currently have the capacity to reason or give leeway like a human does. Using automated systems to do things like process job applications or make credit decisions already disadvantages people; a computer cannot take extenuating circumstances into account the way a person can. If I start college and my father, who provides my financial support, dies, my grades might drop substantially due to emotional stress and having to quickly find a job that allows me to support myself and my studies. A human reviewing my record can look at that period of time and ask me to explain what happened, if I’m applying for grad school or a job—the computer just sees that my grades tanked, and adjusts its treatment of my application according to its programming about that. Humans can be compassionate. AI can only follow its if-then rules and its pattern recognition.
Disabled people, BIPOC, and people living at or near the poverty line already face substantial barriers to good jobs, financial security, home ownership, etc. I think that we need to prioritize figuring out ways to ensure that people’s circumstances can be taken into account when determining what kind of aid they receive, or whether or not they get a job. ",,,,,,,
"OSTP-TECH-2023-0007-0156","OSTP","OSTP-TECH-2023-0007","ljr-wiu1-uue8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0156/attachment_1.pdf",
"OSTP-TECH-2023-0007-0157","OSTP","OSTP-TECH-2023-0007","ljr-x2wa-rg8o","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please please please put more regulations and restrictions on ai. ",,,,,,,
"OSTP-TECH-2023-0007-0158","OSTP","OSTP-TECH-2023-0007","ljr-x4gn-5v9s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Look, I'm gonna be real with you here. AI has been nothing but a horrible trend that rich executives who refuse to pay someone for their actual worth use to circumvent that. It also doesn't help that to get an AI trained properly you have to feed it TERABYTES of stolen copyright properties from creative individuals and companies. I feel that there should be more requirements forcing the developers AND users of these programs to have to pay the people they're training the AI to use or steal from if they wish to use the properties. If not then it should be HEAVILY illegal and heavily punishable with prison time. That should be enforced with any and all AI creation tools and if you're going forward that should be the standard. Force these people to understand that they can't just use AI to circumvent copyrights and steal from others to get what they wish out of them. ",,,,,,,
"OSTP-TECH-2023-0007-0159","OSTP","OSTP-TECH-2023-0007","ljr-xd9e-zijd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To summarize my concerns and complaints:

Artificial Intelligence (AI) is an on-going issue and it's in desperate need of regulation in several of areas, it enables a whole sleuth of problems, from privacy invasion, copyright infringement, exploitation of others' work and much more.

Starting with AI generated images, as these are the most problematic. AI Image Software are built upon theft, they collect copyright protected work, pictures(public or private) and various other pictures for their software to use and capitalizes on said work.

It threatens normal people's lives, and some huge industries, such as the Visual Arts, Animation, Photography, News industry, to list a few.
Main Issues:
- AI Images steals works and infringes on author's rights for exploitative purposes.
- AI Images can be used to propagate fake news or enable blackmailing.

Proposed Solutions:
- AI Images should always have clear and visible watermarks and metadata associated with it, that, if removed, would corrupt the image. To not cause confusion to anyone whom may see it.
- AI Images should only be trained Public Domain and Creative Commons. So all it produces legal and ethical results.
- AI Images shouldn't ever include public figures or true people. So blackmailing and misinformation are severally reduced.

AI Voice Cloning is the second biggest issue when it comes to AI, as it affects everyone. AI voices can be used to deceive people, by including people in occasions or situations they did not agree or would not normally be in. Currently the most affected by AI voices are Public Figures, Actors and Voice actors, however many other groups are suffering with it.

Main Issues:
- AI Voice cloning uses someone's voice against their choice or consent for exploitative, such as not paying them for their likeness or putting them in situations they wouldn't agree with. 
- AI Voice cloning can also be used to propagate fake news or enable blackmailing.

As it is really difficult, if not impossible to moderate AI voices, it should be completely banned, unless in certain medical cases, such as someone who completely loses their voice.

AI generated text and stories affect a variety of groups, such as Authors, News, Professors, and others. AI generated text, much like the previously mentioned, AI generated images, uses already existing copyrighted work for their software to use later on, alongside other existing texts, such as private or personal messages, to use it later on.

Main Issues:
- AI generated text includes various kinds of illegal information within it's systems, and shares that same information with it's users when asked to do so.
- AI generated text makes it difficult for professors and others in the academic field, and other related positions and fields to review the work of a person or entity, as they can't ever verify if it's their own.
- AI generated text 

A proposed solution would be an outright ban on AI text generators. However exceptions could be made for Academic environments, which would have a limited AI where it's only use would be to share information with a student, rather than doing their entire assignment for them.

There's currently a lot of issues with AI that need to be addressed as soon as possible. I had a lot more to share about this issue as a whole, however due to time constraints and only recently learning about this method of input on the situation, I've decided to only share the biggest points of contention I and many others have with AI. I please ask of you to review this comment carefully and seriously consider it's contents as a lot of groups are suffering with it.",,,,,,,
"OSTP-TECH-2023-0007-0160","OSTP","OSTP-TECH-2023-0007","ljr-xumz-joma","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello, My name is Victoria I'm a freelance artist.

From what I have seen and experienced with Ai, mainly the generators has been more bad then good. Such as people making deep fake porn images, using the photos of women who never consented to their likeness being used for porn. Such as the scandal of Brandon “Atrioc” Ewing. A twitch user who was found  with these images.
Another example of the harmful use of AI generators is there have been people trying to make convincing deep fake news images. With AI, some are quite convincing such as the ones made by a twitter user [REDACTED]. 

There is also the fact that AI has been used to try and put a great deal of people out of work. Such as artist, writers, photographers and potentially voice actors, with these generators that can now copy an actors voice. Japan is already putting this int practice with copying the voices of long dead voice actors.  
We also have AI generators copying an artist style and hard work by taking the artwork they post online and feed it into their data banks. Using the art without permission and training the generator to make copies of their style. Because of this it's hard to tell the difference from the original artist or an AI copy. We also see from their users of these programs saying they rather use this then pay and artist or writer. You can find proof of this by typing AI generator on twitter and ticktock, the toxicity and hate for artist is everywhere. 

Overall I think AI should be monitored and the companies more transparent about where they get their data as well as their users. As well as compensation to the writers and artist who's work was taken without permission.

Thank you and I hope my input helps with your decision. ",,,,,,,
"OSTP-TECH-2023-0007-0161","OSTP","OSTP-TECH-2023-0007","ljr-y1hs-5uy4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello. At this point in time, there is no way for AI to function without stealing from artists. For the most part, it is used to cheat artists out of money. I implore you to tread carefully.",,,,,,,
"OSTP-TECH-2023-0007-0162","OSTP","OSTP-TECH-2023-0007","ljr-y5o4-tkch","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"(The numbers refer to which question I’m answering)

1. To ensure AI systems are designed in a matter to protect people’s rights and safety, it is vital to look at the training data of generative AI. Corporations should never be allowed to keep training data a secret, and there must be ZERO copyrighted works or personal data without consent within these training models. There must be regulation on the federal level to enforce this. Pre-existing AI models that infringe on copyrighted works and personal data must be DESTROYED and restarted from scratch with only ethically sourced data. People in charge or involved with these AI corporations, such as Sam Altman of OpenAI, have no business being in charge of or influencing regulation as they are clearly criminals stealing from hardworking artists, writers, programmers, etc.

7. A national security risk with generative AI is the simple fact that other nations can steal intellectual property from the USA. This is because generative AIs, in their current form, are mostly built off of stolen intellectual property and closely imitate said stolen intellectual property. This risk can be mitigated by algorithmic disgorgement, destroy the infringing AIs and restart from only ethically sourced data, like creative works with written consent for AI training from the original author(s).

13. Deepfakes made with generative AI must absolutely be made illegal on the federal level. It is grossly inhumane to take someone’s voice, shove it into some AI, and make them say things they would never say in real life. This has already been used for scams and fraud, and will absolutely ruin lives. Not only should it be illegal to generate deepfakes, it should be made illegal to even host AIs that are capable of making these deepfakes.

22. Generative AI will not create new jobs, or if it does create new jobs, it will be vastly overshadowed by how many jobs are stolen away. Already, artists and writers are being replaced by the subpar sludge that comes from generative AI, built off of their stolen work to begin with. Generative AI must never be allowed to replace the hard working artists and writers that made life enjoyable to begin with.

29. Please listen to those who are currently being harmed by unethical AI. Please listen to hard working individuals such as Karla Ortiz and Nicole Miller instead of the criminals responsible for this mess to begin with. People like Sam Altman and Emad Mostaque should be locked away in prison for their crimes. They are mere thieves pretending to be revolutionary software engineers, nothing more.",,,,,,,
"OSTP-TECH-2023-0007-0163","OSTP","OSTP-TECH-2023-0007","ljr-yqz1-0669","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I'd deeply concerned about the use of AI to replace creatives in the comic book industry and journalism. Most of these jobs don't even pay living wages to begin with but are a critical source of extra income that people can count on. I'm very concerned that Ai is being trained using artwork scraped from the internet that is not paid for. The end result is that Ai companies will benefit from a form of theft that isn't counted because they're using a computer to do it. AI companies should have a full account of what they've used to train their models, give the artists whose work they've used the option to opt out of using their work to train the models or pay them restitution. ",,,,,,,
"OSTP-TECH-2023-0007-0164","OSTP","OSTP-TECH-2023-0007","ljr-ymnc-q5ci","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached document.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0164/attachment_1.pdf",
"OSTP-TECH-2023-0007-0165","OSTP","OSTP-TECH-2023-0007","ljr-z0i0-baoo","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please have companies review their data sources.",,,,,,,
"OSTP-TECH-2023-0007-0166","OSTP","OSTP-TECH-2023-0007","ljr-zgi9-3fai","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello, I personally believe that Generative AI has to be ethically regulated with and the datasets currently have to be reset as it steals millions pieces of licensed work from writers, actors, and artists without their consent. The data-sets should only be able to use non-copyrighted work. The datasets should be opt-in instead of opt-out. I fear that Generative AI in this current state will make it impossible for artists or creatives to compete as Generative Ai will simply take their work without their permission and regurgitate it against them. I believe there should be regulations to where people have to opt in to allow their data to be used instead of the current policy of everything being opt-out. I believe that in this current state of AI, there will be massive job displacement with many people suffering and a few wealthy people reaping all the benefits by using people's information/work.",,,,,,,
"OSTP-TECH-2023-0007-0167","OSTP","OSTP-TECH-2023-0007","ljs-00lf-a8hn","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I believe that AI is a powerful tool.  However, as it is now, it is built unfairly on the labor of others.  Most generative AI is trained on stolen art or writing, more often than not without the permission of the artists or writers.  

I think that anything generated by AI should never be copyright-able, as a human did not create the piece.  At most, a human is rolling dice until a desired result is reached. 

Artists and creators need the law on their side to take down art works generated using their works, or in the likeness of their works.

There is also the danger of using AI to do deep fakes of celebrities, politicians, and even children.",,,,,,,
"OSTP-TECH-2023-0007-0168","OSTP","OSTP-TECH-2023-0007","ljs-0kw4-6han","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I need the government's assurance and initiative to preserve the creative and academic class as a means to climb the economic ladder. There's too much income inequality where the rich get richer at an exponential rate. With AI, it is almost certainly guaranteed that it will abolish, or greatly cripple, both the creative and academic classes. I hope the Biden Administration recognizes this fact, and that it should work towards a future where people can get paid doing what they want to do, and not get the enjoyable jobs taken from them by technocratic oligarchs.  ",,,,,,,
"OSTP-TECH-2023-0007-0169","OSTP","OSTP-TECH-2023-0007","ljs-0s28-f9rp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"OSTP-TECH-2023-0007-0001

While at this point, banning ML and generative algorithms are impractical, there are several large flaws with generative algorithms:
1) The ability to generate plausible-sounding falsehoods quickly
2) An inability to distinguish between outputs that are grounded in the real world and not, including harmful outputs
3) A concentrated effort to replace skilled professionals with algorithmically generated content
4) A concentrated effort to steal the work of skilled professionals

""AI"" is dangerous not because of the computers plugging away, but because of how much people are willing to uncritically accept whatever it spits out, and because of the lies the hype-men are using to sell it to investors.",,,,,,,
"OSTP-TECH-2023-0007-0170","OSTP","OSTP-TECH-2023-0007","ljs-1fc0-7w73","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-06T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I feel that machine learning models must properly compensate the owners of the intellectual property they use in training. This is for things like art or the images of persons or places which did not consent to being used as training data.",,,,,,,
"OSTP-TECH-2023-0007-0171","OSTP","OSTP-TECH-2023-0007","ljs-2adm-plxu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am for the heavy regulation or preferably outright banning of ""AI"" or machine generated algorithmic content.

Modern ""AI"" is nothing more than an algorithm making guesses as to what a prompt should result in. It frequently makes false claims. As well, these algorithms are trained on massive amounts of data, the majority of which it has not been given permission to use. Both of these facts will cause huge legal issues regarding ownership and claims made by these algorithms when they are representing legal entities.

Nothing that these algorithms are able to produce is worth the strain it will put on our existing systems.",,,,,,,
"OSTP-TECH-2023-0007-0172","OSTP","OSTP-TECH-2023-0007","ljs-2alq-zm28","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a software developer, I feel a lot of AI work is being done to avoid paying people what they deserve, and cut out the middle man. I am worried that the rich may use it to disenfranchise those that need it for their livelihoods, especially those of artistic endeavors.Many of these ""Tech Bros"" are only interested in devaluing the work of others.",,,,,,,
"OSTP-TECH-2023-0007-0173","OSTP","OSTP-TECH-2023-0007","ljs-2cc8-h11g","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0173/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0173/attachment_1.pdf",
"OSTP-TECH-2023-0007-0174","OSTP","OSTP-TECH-2023-0007","ljs-38kf-xfzq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI is generally harmful, as it has been stealing peoples jobs, used to make pornography against people’s wills, etc. Everyone from voice actors to people who code have had found themselves in a situation similar to the ones stated above because of lack of regulation, and the theft of large companies whom, due again to lack of regulation, steal the work without people’s consent. 

AI should be monitored and therefore should have heavy regulations put in place to ensure that companies cannot steal the work, and that in work settings, AI cannot be used (like to generate art and using it in an advertisement, asking an AI to write code, etc).",,,,,,,
"OSTP-TECH-2023-0007-0175","OSTP","OSTP-TECH-2023-0007","ljs-3a5k-gcga","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI must not be trained on stolen assets - measures must be taken to prevent downright plagiarism by AI. Art, writing, acting, etc. should not be opted in by default. The default should be that everyone's creations are opted out of AI. There should also be regulations done on the amount of energy used by AI (such that it is not grossly excessive). ",,,,,,,
"OSTP-TECH-2023-0007-0176","OSTP","OSTP-TECH-2023-0007","ljs-3p0y-88y3","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I cannot speak to every question that has been asked as I am not an expert on AI. However, I can speak as a 27 year old artist whose life and career have been severely altered by the popularization of generative imagery AI models. These popular models such as Stable Diffusion and Midjourney are unethical and infringe on the rights of artists and individuals around the globe whose images were scraped and used in the training data without consent.

Without regulation, these generative image models have already taken jobs from human artists. In addition to the career and employment opportunities lost, we are also forced to fight just for our rights to be recognized, as many would like to claim that our copyright is invalid once they feed it into a machine. Were the process behind these models carried out by an individual, it would be easily identified as infringement. The speed, scale, and granularity of what is done by these models helps obfuscate that reality, but still does not change what it is: infringement.

Copyright and intellectual property law has helped foster creativity and innovation by allowing creators to protect our ownership of what we create. It empowers us to choose and control how our work is used, appropriated, derived, and remixed, ensuring we never need to compete with our own creations. With the development of technology advancing faster than the law, we have lost that protection and suffered for it, both financially and mentally. 

I have dedicated the majority of my life to honing my craft and only just entered the workforce a couple years ago. As things currently stand, I'm immeasurably afraid that my career could end before it truly begun. I will not claim that AI does not have its uses, that it cannot be leveraged as an effective tool in many ways, but without regulations that ensure that humans, as well as their rights and creations, are always and forever valued and guaranteed over those of a machine, there is a unavoidable risk of humans being displaced and made to suffer as a result.",,,,,,,
"OSTP-TECH-2023-0007-0177","OSTP","OSTP-TECH-2023-0007","ljs-3r1j-luvi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a person who has been working in the tech sector for years, writing and deploying computer programs, some of which using techniques that fall under the wide umbrella known as ""artificial intelligence"", my perspective on the use of AI has frequently differed from the concerns often put forward by the mainstream press. I am not afraid of some sort of hostile robot takeover or automation suddenly taking all our jobs.

I am, however, concerned with the privacy impacts of both AI technology as it is deployed and regulations being proposed to potentially curtail abuses of AI tech. I want to make sure that large-scale deployment of AI is done in a transparent manner with broad public oversight. We should not be kept in the dark about where the data used to train these programs is coming from, or how these programs are being used, or when and where these programs are being used. Both corporations and the government who use AI should be required by law to disclose the sources of their training data, the type of AI they are using, and the specifications of the software and hardware (such as training data size, model size, the amount of storage, RAM, processor count and speed, etc.) Currently these types of details are often obscured under claims of ""trade secrets"" and the like, however I see this as no different than a food manufacturer having to disclose the size and capability of its farms and factories or the sources of its ingredients. These technologies have broad impacts in many sectors, including social, economic, and environmental impacts. We cannot have a proper dialog surrounding deployment of AI technology if we do not have all the details.

In a similar vein, how, when, and where AI is used should be public knowledge as well. If my data is being automatically interpreted by an AI system, I should be made aware of that before I submit that data. If media that I'm consuming is being generated in whole or in part by an AI system, that fact should be properly and prominently disclosed. There should be ramifications for groups and individuals who try to pass off AI-generated content as human-generated, or who use AI to process large amounts of data without the informed consent of the providers of that data. Our individual rights to ownership of our data should not be curtailed by corporations or the government who seek to profit off of us or surveil us. A comprehensive set of rights to data privacy should be enshrined in federal law.

Finally, AI regulations should not be used as an excuse to intrude into the privacy of individuals in our own homes. We should continue to be free to use our personal computers as computers, and not be restricted in what programs we are allowed to run by some vague and overly broad definition of ""artificial intelligence"". We shouldn't let overblown fears of ""AI terrorists"" lead us into another Patriot Act where our freedoms are being curtailed once again for the sake of ""national security"". As a private individual, I am far more concerned with the actions of businesses and the government than I am about some guy in his garage tinkering with a neural network.

Thank you for your time and consideration.",,,,,,,
"OSTP-TECH-2023-0007-0178","OSTP","OSTP-TECH-2023-0007","ljs-3vdx-6y4h","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Stable Diffusion's model is 5GB. It was trained on 5 billion images. That's 1 (one) byte per image.

Anyone who thinks taking a single byte from an image meets the substantiality requirement for a copyright violation is absolutely insane.

And that's the mathematical *most* it can ""take."" In reality, that's not how AI works, and it retains far less of each image than that.

It's closer to taking the mean of 5 billion images. It's statistics. Statistics is not theft.",,,,,,,
"OSTP-TECH-2023-0007-0179","OSTP","OSTP-TECH-2023-0007","ljs-3y04-tdgk","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In regards to AI I think you have a real choice to be made in regards to how the technology will be treated in the future. Right now the tech is very exploitative, both of workers abroad, and workers at home. The AI systems are trained on data that they never had to properly compensate people for: artists, authors, workers, etc. All of which they are then using to create derivative works that go on to compete with the very people that they stole from. AI can be a game changer and be used for a lot of very important problems we face today, but not in its current form that is focusing on theft of work and rampant mindless consumerism. Regulating these companies now and enforcing policies on how a model is allowed to train, in terms of due compensation, credit, and competition, will go a long way in restoring public faith in these models for the future. At this moment they are more akin to the grift of cryptos and NFTs than to the potential future saving technology that they could ultimately be. ",,,,,,,
"OSTP-TECH-2023-0007-0180","OSTP","OSTP-TECH-2023-0007","ljs-41m9-bfz4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Stable Diffusion said it best.

If anti-AI people had a leg to stand on, they wouldn't feel the need to constantly lie about how AI works.

See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0180/attachment_1.pdf",
"OSTP-TECH-2023-0007-0181","OSTP","OSTP-TECH-2023-0007","ljs-577a-kzmf","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It would be wonderful for a more thorough regulation of AI’s data scrapping and the data bases it is trained on. Copyright laws to protect peoples IPs need to be implemented and upheld.",,,,,,,
"OSTP-TECH-2023-0007-0182","OSTP","OSTP-TECH-2023-0007","ljs-7ay9-rc9n","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please do not allow companies to allow ai. This is going to endanger people when pictures are believed for disinformation. There needs to be strict rules regarding ai. It endangers lives and humans",,,,,,,
"OSTP-TECH-2023-0007-0183","OSTP","OSTP-TECH-2023-0007","ljs-c6dk-h4ym","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current generative AI such as Stable Diffusion and OpenAI rely on millions of stolen work. Much of which is copyrighted. No compensation or consent to the creator's. This affects me as a young college student lookin to go into game development. This affects everyone who has every created work or posted content online. ",,,,,,,
"OSTP-TECH-2023-0007-0184","OSTP","OSTP-TECH-2023-0007","ljs-cquc-0jmz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I’m Joseph Wehbe, an American AI ecosystem builder and part of the World Economic Forum AI expert network. We are at a tipping point in AI. The world finally has a user interface for AI with chatGPT.  According to the Global AI Index 2023 the US is ranked #1 overall but we rank #28 in “operating environment” and #8 on “government strategy”
 
1-With the launch of this technology, we are building a generation of consumers of AI, NOT builders of it. 
 
2-Silicon Valley wants to sell us UDEMY, Data Camp, & Coursera courses to learn about AI, but that does NOT build the next generation of AI talent. Without introducing accredited AI degrees at universities, and teaching accredited elementary, and high school AI content, we won’t have educational merit in the process. Can anyone take a medical course online and become a doctor? We can NOT expect that of AI learners.  Online AI courses have answers online, so learners can just copy their responses.
 
3-AI with educational merit starts with Chief AI scientific advisors in a Local AI ecosystem. We need participation from every institution of higher education in every corner of America. In a well-functioning AI value network, the shared goal within that ecosystem is to build the next generation of AI talent, so we can populate industry with builders.
 
During my AI graduate degree studies in Toronto, Dr. Geoffrey Hinton was the Chief Scientific Advisor of our AI center of excellence.  I received firsthand training in building the Canadian AI ecosystem.  They launched the world's first national AI strategy. Every corner of Canada has a pathway for stakeholders to participate in AI.  
I’ve won several awards for my AI ecosystem builder work including #1 MIT Challenge (knowledge-economy) winner, am part of the World Economic Forum AI expert network, invited moderator to the MIT Gen AI Summit Future of Work, and TED TALK in BOSTON has over 11,000 views on the importance of building localized AI ecosystems.
 
Regulators and lawyers can’t regulate AI if they don’t understand that
 
REGULATION is slow & linear. But we face an exponential threat, if we only have consumers of AI not builders of it, or if we only rely on Silicon Valley to build the platforms we all use everyday. The problem is there is a SHORTAGE of independent experts in AI to work with government to:
 
1-Acknowledge AI risks
2-Establish guardrails
3-Understand the explainability and transparency in the algorithms.
 
To give you a comparison, Medicine can be regulated because of:
1-    patient safety, 
2-    ethical standards
3-     treatment efficacy.
 
BUT it is hard to regulate AI because;
1-    Interdisciplinary stakeholders
2-    Lack of explainability
3-    Autonomy in decision making.
 
FDA & CDC regulates healthcare FDA. certainly with doctors and medical professionals on their teams.  Currently, there is no single federal agency in the United States that has the sole responsibility of regulating AI.
It is important for regulators to understand the following fact that Silicon Valley will NOT testify to. The outcome of an AI project can be considered to be probabilistic rather than deterministic. This is because AI algorithms often involve stochastic processes, such as randomization or probabilistic modeling, which introduce randomness into the decision-making process.
Additionally, the performance of an AI system is often dependent on a variety of factors, such as the quality and quantity of the data used for training, the chosen algorithm, and the specific parameters chosen during model training. These factors can all contribute to variability in the performance and output of an AI system.
It is also worth noting that AI systems can be affected by external factors, such as changes in the environment or input data, which can further contribute to non-determinism in the output.
Therefore, while AI systems can provide useful predictions and insights, the output is not always deterministic and can be influenced by a variety of factors. It is important to consider the level of uncertainty associated with AI output when making decisions based on its results. How many times has a Tesla’s computer vision system mis-classified an object on the road? Or how much times has your iPhone speech-to-text feature written the wrong thing because of your accent or noise factors?
 
So if we don’t have independent AI experts working with the US Government, and the outcome of AI projects is proven to be non-deterministic, how can Congress have a work at regulating AI? While much has been tried to regulate social media, AI is 100% more complex. 
I’m ready to serve my country and assist with building localized AI ecosystems in every corner of America so we can maintain our #1 position globally.
Joseph Wehbe-World Economic Forum AI Expert Network- https://www.weforum.org/agenda/authors/joseph-wehbe
https://scholar.harvard.edu/josephwehbe/
TED TALK: https://www.youtube.com/watch?v=KLGkxbZkyLQ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0184/attachment_1.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0184/attachment_2.pdf",
"OSTP-TECH-2023-0007-0185","OSTP","OSTP-TECH-2023-0007","ljs-dttm-djku","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0185/attachment_1.pdf",
"OSTP-TECH-2023-0007-0186","OSTP","OSTP-TECH-2023-0007","ljs-f8t3-9cwq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is a recent topic in the news that is presenting concern to myself and many citizens. I would like to know if our government officials are watching out interests regarding the explosion of A. I. usage across our field of tech.

I am speaking for the millions of creative people across the world who try to make a living through their work and the possible dilution of their creativity because of algorithms that can steal their intellectual property and sell it without benefit to them.

This is terribly oversimplified I know but I would like to know if our government has watchdogs monitoring this situation.

Giving the tech sector money to regulate themselves is not the answer. The A.I. process needs to be evaluated and regulated by a group outside of its influence.. Of course this is my opinion.

There is so much noise on the internet about this topic, I want to feel confident that our lawmakers are on top of protecting citizens from the scraping of data to undermine true creative artists - no matter what field. Thank you

",,,,,,,
"OSTP-TECH-2023-0007-0187","OSTP","OSTP-TECH-2023-0007","ljs-g35x-xxyf","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The AI industry is knowingly pushing ahead with massively illegal activities. One of the most pressing regulations that are needed is MANDATORY DISCLOSURE OF TRAINING DATA. Do not listen to them claiming this is “anti-innovation” or whatever excuse they use. Lack of disclosure of training data only enables FRAUD AND THEFT. For example, almost all image and text generators now are based on pirated data. They are consuming huge amounts of human labor with the intent of replacing the entire human workforce in the creative industries and beyond. AI developers acknowledge this, which is why they are pushing for a huge expansion of social security under the guise of “UBI” as a necessity for their societal plans to work. Does that sound like a path society should be guided down?? Will Americans react well to 300 million jobs being replaced by AI (as Goldman Sachs predicts if AI is left unregulated) with the consolation that they will be guaranteed unemployment benefits?? Please do not listen to the hype and excuses from AI devs. They are not the pioneers of the future they want to portray themselves as and are instead simply interested in enriching themselves by shrinking the jobs market as much as possible to redirect the funds into their own pockets.",,,,,,,
"OSTP-TECH-2023-0007-0188","OSTP","OSTP-TECH-2023-0007","ljs-j0yk-pb9b","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"MITRE's response to the RFI on National Priorities for AI is attached.  Please let us know if you have questions or if we can be of any further assistance.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0188/attachment_1.pdf",
"OSTP-TECH-2023-0007-0189","OSTP","OSTP-TECH-2023-0007","ljs-j5f2-9fv5","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file (PDF) submitted by the Centre for the Governance of AI.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0189/attachment_1.pdf",
"OSTP-TECH-2023-0007-0190","OSTP","OSTP-TECH-2023-0007","ljs-jusl-rhzj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Official UNESCO Response to the Office of Science and Technology Policy (OSTP)’s Request for Information – National Priorities for Artificial Intelligence.
please see attached file for more details ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0190/attachment_1.pdf",
"OSTP-TECH-2023-0007-0191","OSTP","OSTP-TECH-2023-0007","ljs-kb9v-5lnr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments from Hitachi Group Companies doing business here in the U.S.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0191/attachment_1.pdf",
"OSTP-TECH-2023-0007-0192","OSTP","OSTP-TECH-2023-0007","ljs-kewo-zg78","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0192/attachment_1.pdf",
"OSTP-TECH-2023-0007-0193","OSTP","OSTP-TECH-2023-0007","ljs-kjz5-ur0o","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Coalition for Content Provenance & Authenticity (C2PA) appreciates the opportunity to respond to the request for information on National Priorities for Artificial Intelligence.  Please see the attached file with comments. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0193/attachment_1.pdf",
"OSTP-TECH-2023-0007-0194","OSTP","OSTP-TECH-2023-0007","ljs-l70r-k7tr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative ai must be heavily regulated. From finding its training datat (which should be opt in ONLY) to how it can be used, distributed and marketed. Generative ai not only has and will continue to take the jobs of thousands of creative workers I is also a threat to infomermation and news. With how strong these models have become they can and will be used to spend misinformation with no easy way to distinguish the truth from the code slot machine. Unregulated ai is incredibly dangerous to security anyone can have about any information and it must be stopped. ",,,,,,,
"OSTP-TECH-2023-0007-0195","OSTP","OSTP-TECH-2023-0007","ljs-kv9j-zq46","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0195/attachment_1.pdf",
"OSTP-TECH-2023-0007-0196","OSTP","OSTP-TECH-2023-0007","ljs-lk9u-zi9s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[Please see full comments attached]

	The Association for Computing Machinery (ACM) is the longest established and – with more than 50,000 American members – the largest association of individual professionals engaged in all aspects of computing in the nation. A non-lobbying and otherwise wholly apolitical organization, ACM’s mission includes providing unbiased, expert technical advice to policymakers on matters of our members’ wide-ranging expertise. That work is accomplished in the United States by and through ACM’s U.S. Technology Policy Committee (USTPC).

	USTPC commends its most recent products concerning artificial intelligence to OSTP for its general consideration. They are its: June 27 Principles for the Development, Deployment, and Use of Generative AI Technologies [https://www.acm.org/binaries/content/assets/public-policy/ustpc-approved-generative-ai-principles], January 2023 ACM TechBrief: Safer Algorithmic Systems [https://dl.acm.org/doi/pdf/10.1145/3582277], and joint Statement on Principles for Responsible Algorithmic Systems of October 2022 [https://www.acm.org/binaries/content/assets/public-policy/final-joint-ai-statement-update.pdf]. 

USTPC also offers the attached specific responses to select questions posed (and as numbered) in OSTP's Request for Information in the present proceeding.


",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0196/attachment_1.pdf",
"OSTP-TECH-2023-0007-0197","OSTP","OSTP-TECH-2023-0007","ljs-lmly-14d6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0197/attachment_1.pdf",
"OSTP-TECH-2023-0007-0198","OSTP","OSTP-TECH-2023-0007","ljs-lxhe-smhv","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached for BlackBerry Corporation's comments related to the National Priorities for Artificial Intelligence RFI opportunity. We appreciate the opportunity to offer input.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0198/attachment_1.pdf",
"OSTP-TECH-2023-0007-0199","OSTP","OSTP-TECH-2023-0007","ljs-mgqs-64wi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Thank you for the opportunity to comment.  Please see the attached file for our detailed comments.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0199/attachment_1.pdf",
"OSTP-TECH-2023-0007-0200","OSTP","OSTP-TECH-2023-0007","ljs-mi3v-0ssc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0200/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0200/attachment_1.pdf",
"OSTP-TECH-2023-0007-0201","OSTP","OSTP-TECH-2023-0007","ljs-muz1-gt2i","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please refer to attached PDF.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0201/attachment_1.pdf",
"OSTP-TECH-2023-0007-0202","OSTP","OSTP-TECH-2023-0007","ljs-n2go-e9qs","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0202/attachment_1.pdf",
"OSTP-TECH-2023-0007-0203","OSTP","OSTP-TECH-2023-0007","ljs-nkf9-atyu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0203/attachment_1.pdf",
"OSTP-TECH-2023-0007-0204","OSTP","OSTP-TECH-2023-0007","ljs-nmwn-c1ir","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s) ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0204/attachment_1.pdf",
"OSTP-TECH-2023-0007-0205","OSTP","OSTP-TECH-2023-0007","ljs-nrfx-qy0s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We appreciate the opportunity to respond to this request for information, and for your thoughtful consideration of the potential impacts and opportunities that artificial intelligence presents. At Resemble AI, our commitment to ethical use of AI and specifically, generative audio, remains central to our mission.

Our response includes a detailed overview of our stringent internal policies and guidelines, innovative technologies, and practical examples that safeguard the ethical use of our voice cloning technology while respecting privacy and data rights. We have established measures to prevent misuse such as a consent line, AI voice ownership rights for users, rigorous processes for custom solutions, and stringent terms of service to curb harmful applications.

We have also highlighted our proprietary watermarking and detection tools, namely our Neural Speech Watermarker and upcoming Resemble Detect, which provide important safeguards against malicious use of AI-generated voices.

We affirm our commitment to promoting ethical, responsible, and beneficial uses of AI, and look forward to engaging further on these critical issues.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0205/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0205/attachment_1.pdf",
"OSTP-TECH-2023-0007-0206","OSTP","OSTP-TECH-2023-0007","ljs-oi2y-d4j2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The AI field and industry today, much like Silicon Valley itself, is characterized by an almost complete disregard for existing laws, regulations, and ethics. A classic example comes through their use of data.  They disregard both copyright and consent in order to use whatever data they want, to the extent of going to piracy websites in order to downloads tens of thousands of copyrighted books. People's data, whether it be art, voices, writing, or images, is used without their consent or knowledge to fuel AI systems, including systems which aim to compete directly with the original creators of the data.  AI companies and researchers offer zero transparency over their use of other people's personal data, and it is impossible for anyone to even ""opt-out"" over having their data used. Generally, the AI field seems to believe it has the divine right to use any data created by anyone in any form, and I fully believe they would try to cram cameras up eveyones' butts if they thought it would lead to a 1% increase in the performance of their models. It is interesting to note that AI companies do pay significant amounts of money to data brokers for human training data whenever there is a gap in their existing data(see https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots ); they merely believe that the public has no right for compensation for their valuable training data.

Like I said, the lack of respect for any existing laws or regulations represents something typical in Silicon Valley and in the tech industry. I can compare it to Uber systematically violating urban laws about taxis(something they paid no penalty for), cryptocurrency exchanges violating laws about security exchanges, or social media sites systematically violating European data protection regulations. One of the chief obstacles to applying more regulations to AI is that the current behavior of AI companies suggests they would violate any new regulations whenever it was convenient. I believe that harsh, swift, and punitive punishment for violations is a necessary component of any potential regulatory regime, no matter its objective.

Another prominent issue is that of ""accountability"" and ""liability."" AI companies are mass deploying unreliable and unpredictable systems, including LLMs. In order to avoid potential liability, they claim(and write into their terms of use) that all liability lies with the end user, even though these same AI companies have their marketing argue for the power and reliability of their systems. This is not a situation which should or can be allowed to persist. Manufacturers of AI systems must have some degree of liability for the use of systems. For instance, if a chatbot consistently libels a person, accountability for that has to lie with the creators and maintainers of the system.

I also believe that AI companies have falsely created a narrative of a ""AI arms race with China"" in order to justify their actions and as a shield to deflect regulation. I would argue that the real AI arms race is one that is being engaged with between a handful of massive American companies such as Google, Meta, and OpenAI/Microsoft.  These companies are far more obsessed with AI than the Chinese government is, and have been throwing massive amounts of money at AI research that likely vastly exceed any Chinese government funding.  The only AI area that China seems to be ahead of the United States is regulation.

This is unrelated, but I find it worth pointing out that the current AI sector is obsessed with replacing workers, rather than enhancing workers.  They have little interest in making it easier for workers to do their jobs or increasing worker productivity. Instead, they aim to replace workers. Their end goal is to replace all the workers in the world with AI. I don't think they are likely to accomplish this objective, but their obsession with replacement deeply shapes their behavior.",,,,,,,
"OSTP-TECH-2023-0007-0207","OSTP","OSTP-TECH-2023-0007","ljs-oetk-6tyg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Response submitted on behalf of Business Roundtable is attached.  For questions or follow up, please contact Amy Shuart, Vice President, Technology and Innovation. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0207/attachment_1.pdf",
"OSTP-TECH-2023-0007-0208","OSTP","OSTP-TECH-2023-0007","ljs-ouwv-ieip","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"If you are going to make priorities for AI then the largest ones are to ensure they are ethically made. Lots of current systems are made off of privacy invasion and data scrapping policies that make certain things unavailable in places like the EU. In order to actually use this technology, we need to ensure it does not bring ruin to creatives or those who aren't big companies that have millions to spend scraping data in ways that get them sued multiple times. We can't have unethical or borderline illegal scraping and we cannot have policies that would not protect the rights of the people and their creative tasks; for as it stands any who makes a painting or drawing or a book runs the risk of some algorithm eating up their data without consent or compensation. That cannot be allowed to stand.",,,,,,,
"OSTP-TECH-2023-0007-0209","OSTP","OSTP-TECH-2023-0007","ljs-oiv3-n9mc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0209/attachment_1.pdf",
"OSTP-TECH-2023-0007-0210","OSTP","OSTP-TECH-2023-0007","ljs-ookl-v6yj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To ensure that AI systems are designed, developed, and deployed in a manner that protects people's rights and people’s safety, there are four specific measures that we recommend implementing.  

These measures include: 

Establishing Ethical Frameworks and Standards: Establishing clear ethical guidelines and standards for AI development is crucial. These frameworks should address issues such as transparency, fairness, privacy, and accountability in AI systems. 

Implementing Regulations and Legal Frameworks: By implementing regulations and legal frameworks that govern the use of AI technologies can help ensure compliance with ethical principles and protect people's rights. These regulations should address issues like data protection, algorithmic bias, and non-discrimination. 

Investing in AI Research and Development: Governments, organizations, and industry should invest in research and development efforts focused on building ethical AI systems. These investments can support the exploration of AI technologies that prioritize safety, fairness, and human-centric decision-making. 

Improving Trust and Safety Practices: By implementing robust trust and safety practices is critical to ensuring that AI systems uphold user rights and safety. This includes comprehensive testing, rigorous validation, and continuous monitoring of AI systems to minimize risks and ensure compliance with ethical standards. 

In addition to these measures, the National Institute of Standards and Technology (NIST) has released an updated framework for cybersecurity, emphasizing the importance of identifying and detecting cyber risks.  

The NIST framework promotes a comprehensive and risk-based approach to cybersecurity, focusing on early detection, enhanced preparedness, and strategic decision-making.  

The upsurge in the popularity of Artificial Intelligence set a precedent for several countries in the European Union to lobby for an AI Act that includes human oversight of tools. (Ref: page 21  https://www.enisa.europa.eu/publications/cybersecurity-of-ai-and-standardisation) ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0210/attachment_1.pdf",
"OSTP-TECH-2023-0007-0211","OSTP","OSTP-TECH-2023-0007","ljs-ousz-gp1x","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please receive and review the attached comments from SHRM. Thank you!",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0211/attachment_1.pdf",
"OSTP-TECH-2023-0007-0212","OSTP","OSTP-TECH-2023-0007","ljs-p5ta-cq09","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached comments on behalf of STM",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0212/attachment_1.pdf",
"OSTP-TECH-2023-0007-0213","OSTP","OSTP-TECH-2023-0007","ljs-p7zw-wz47","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0213/attachment_1.pdf",
"OSTP-TECH-2023-0007-0214","OSTP","OSTP-TECH-2023-0007","ljs-pc3f-cz2n","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0214/attachment_1.pdf",
"OSTP-TECH-2023-0007-0215","OSTP","OSTP-TECH-2023-0007","ljs-pdkp-5ed2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"my comment is included in the PDF file attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0215/attachment_1.pdf",
"OSTP-TECH-2023-0007-0216","OSTP","OSTP-TECH-2023-0007","ljs-qaak-xyr5","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"
Please see the attached document in response to the Request for Information – National Priorities for Artificial Intelligence. We are responding on behalf of an organization and our comments are based on industry experience. We included our response to multiple questions within a single document.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0216/attachment_1.pdf",
"OSTP-TECH-2023-0007-0217","OSTP","OSTP-TECH-2023-0007","ljs-ql23-xy8h","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0217/attachment_1.pdf",
"OSTP-TECH-2023-0007-0218","OSTP","OSTP-TECH-2023-0007","ljs-qsk7-7jze","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0218/attachment_1.pdf",
"OSTP-TECH-2023-0007-0219","OSTP","OSTP-TECH-2023-0007","ljs-qz3d-huqa","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dear Sir/Madam,

Thank you for the opportunity to comment on OSTP's Request for Information regarding the National Priorities for Artificial Intelligence.  Please find in the attachment responses to your request for comments from our Executive Director, Dr. Jill Crisman, Digital Safety Research Institute (DSRI) at UL Research Institutes.

If you have further questions, or would like to schedule time with Dr. Crisman to discuss anything related to our responses or the subject matter, please do not hesitate to contact me directly.  We are happy to collaborate and serve as a resource for you on this topic.  Thank you.




",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0219/attachment_1.pdf",
"OSTP-TECH-2023-0007-0220","OSTP","OSTP-TECH-2023-0007","ljs-rf7w-4xbq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comment to Request for Information; National Priorities for Artificial Intelligence (OSTP-TECH-2023-0007) by the Association of American Publishers",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0220/attachment_1.pdf",
"OSTP-TECH-2023-0007-0221","OSTP","OSTP-TECH-2023-0007","ljs-rg6j-hvh9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find the attached comment from the Federation of American Scientists",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0221/attachment_1.pdf",
"OSTP-TECH-2023-0007-0222","OSTP","OSTP-TECH-2023-0007","ljs-ryt5-6dbe","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Artists that had their data scraped to develop these generative machine learning models should have a say, and bot just big tech companies looking to enrich their shareholders while demolishing yet another US industry. ",,,,,,,
"OSTP-TECH-2023-0007-0223","OSTP","OSTP-TECH-2023-0007","ljs-rmue-zg0f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We welcome the chance to respond to this important request for information from the Office of Science and Technology Policy (OSTP). Frontiers is a leading research publisher and open science platform. It is the third most-cited and sixth largest in the world. The science we publish is peer-reviewed, globally shared, and free to read.

Our mission is to make all science open – so that we can collaborate better and innovate faster, for fairer and more equitable outcomes in all parts of society. That is our social purpose as a business.

So, we fully support the August 2022 OSTP guidelines on immediate public access to federally funded research. We strongly welcomed them at the time. As a Gold Open Access publisher, we have made thousands of peer-reviewed articles available online immediately, without embargo. Our starting point – and end point – is ease of discovery.

More broadly, as an open science publisher, Frontiers is above all a knowledge, information, and technology company. We were born digital and open access. We made the founding decision to build our own open science platform and continually to develop, improve, and customize it as we meet the evolving needs of the scientific community.

We think the OSTP has posed critical questions in this request for information about the opportunities, challenges, risks, and benefits of artificial intelligence (AI). General, human-compatible AI could empower us all, but public trust in good science will be key. At Frontiers, we apply our AI tools to help establish that trust.

Our Artificial Intelligence Review Assistant (AIRA) verifies that scientific knowledge is accurately and honestly presented even before our people decide whether to review, endorse, or publish the research paper that contains it. AIRA reads every research manuscript we receive and makes up to 20 checks per second. These checks cover, among other things, language quality, the integrity of figures and images, plagiarism, and conflicts of interest. The results give editors and reviewers another perspective as they decide whether to put a research paper through our rigorous and transparent peer review process.

We face global, existential threats. From health emergencies to climate change, we see and feel them now. We can manage and reverse these threats, to live healthy lives on a healthy planet. But that will require political will, global collaboration, and scientific breakthrough at a scale not yet seen.

On all those counts, success will depend on the widespread sharing of the latest scientific knowledge. All of it. We think scale matters. Tackling these threats will require more than incremental change. Good research published at scale, shared globally, and able to be machine-read across large volumes of information, will grow our chances of success.

Leveraging AI to that end is already underway, and more can be done. But it is vital these AI solutions do not create or perpetuate inequity. The governance mechanisms and safeguards being proposed vary widely, and substantial new thinking and public funding will be required to bring that variance down and lift standards for compliance. The public funding of AI infrastructure and oversight must be as efficient, scalable, and as good a value for money as possible.

We think it is possible to achieve the fullest possible access to our collective knowledge – for fairer outcomes in all parts of society – in a business model that is cost-effective, commercially sustainable, and underpinned by private sector innovation. We stand ready to support the OSTP and its partners in the federal government. It is vital we back responsible AI efforts for the good of open science and to meet the public appetite for accountability, transparency, and trust.

Our detailed responses to the OSTP’s framing, specific to the RFI subsection “Promoting economic growth and good jobs,” are set out in the attached file:
FRONTIERS_response_OSTP_RFI_AI_Docket_ID_OSTP-TECH-2023-0007.pdf",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0223/attachment_1.pdf",
"OSTP-TECH-2023-0007-0224","OSTP","OSTP-TECH-2023-0007","ljs-rqnu-6p46","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0224/attachment_1.pdf",
"OSTP-TECH-2023-0007-0225","OSTP","OSTP-TECH-2023-0007","ljs-rvv6-cf0u","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comment attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0225/attachment_1.pdf",
"OSTP-TECH-2023-0007-0226","OSTP","OSTP-TECH-2023-0007","ljs-sjbt-fr51","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As an artist, discussions around the use of AI has been at an all time high as programs create ""AI Art"" off various prompts. Which in theory can be in good fun, but these programs are built off of stolen artwork. AI Art is fundamentally a randomized mosaic, and can only function if it has data to randomize into a different looking image. But as it is now, the data for these programs are often art work that permission was not given to use and the original artist is not compensated for it. These AI companies are making millions while the original artists get nothing. Also, there is the consequences of artists, as well as writers and similar positions, losing their jobs to these programs. There is discussion of with the Writers Strike going on right now, of studios using AI programs to write scripts and in general many talks about using AI for concept art/backgrounds/Marvel's Secret Invasion using AI for its title sequence etc. And as mentioned before, AI is built off stolen artwork (and in the writers case: writings). AI needs to be highly regulated and should be something that cannot be copywrited. There should be legal steps taken so that AI programs data is ethically sourced and is not built upon stolen art. AI can be a useful tool, but as it stands now it is used unethically. ",,,,,,,
"OSTP-TECH-2023-0007-0227","OSTP","OSTP-TECH-2023-0007","ljs-scz0-ef79","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The following memos are submitted by the GETTING Plurality Research Network at the Edmond & Lily Safra Center at Harvard University. In the Bolstering Democracy memo, we outline how to harness the opportunities this technology presents for a flourishing democracy, while also strengthening our democratic institutions against the threats posed by AI. In the National Security memo, we outline an analytical framework defining key concepts and hazard tiers for different categories of AI, as well as outline regulatory frameworks and structures for implementation. In the Economic Growth memo, we've partnered with New America to develop a set of policy recommendations to promote economic growth and good jobs. Thank you for the opportunity to comment on this important topic, we welcome any further discussion.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0227/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0227/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0227/attachment_1.pdf",
"OSTP-TECH-2023-0007-0228","OSTP","OSTP-TECH-2023-0007","ljs-ssv7-in8j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0228/attachment_1.docx",
"OSTP-TECH-2023-0007-0229","OSTP","OSTP-TECH-2023-0007","ljs-suv7-ohcy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0229/attachment_1.pdf",
"OSTP-TECH-2023-0007-0230","OSTP","OSTP-TECH-2023-0007","ljs-t1ud-8ckg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0230/attachment_1.pdf",
"OSTP-TECH-2023-0007-0231","OSTP","OSTP-TECH-2023-0007","ljs-t2ml-im1c","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0231/attachment_1.pdf",
"OSTP-TECH-2023-0007-0232","OSTP","OSTP-TECH-2023-0007","ljs-tcco-sefn","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached for our submission.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0232/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0232/attachment_1.pdf",
"OSTP-TECH-2023-0007-0233","OSTP","OSTP-TECH-2023-0007","ljs-tp90-qvam","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"OSTP-TECH-2023-0007-0001 - Response attached from Dev Technhology Group, Inc.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0233/attachment_1.pdf",
"OSTP-TECH-2023-0007-0234","OSTP","OSTP-TECH-2023-0007","ljs-twxe-ujtp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached the comment of the Emerging Technology Group (ETG) to the White House Office of Science and Technology Policy's Request for Information on National Priorities for Artificial Intelligence.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0234/attachment_1.pdf",
"OSTP-TECH-2023-0007-0235","OSTP","OSTP-TECH-2023-0007","ljs-u4v5-52w9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0235/attachment_1.pdf",
"OSTP-TECH-2023-0007-0236","OSTP","OSTP-TECH-2023-0007","ljs-u9oj-k16h","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0236/attachment_1.pdf",
"OSTP-TECH-2023-0007-0237","OSTP","OSTP-TECH-2023-0007","ljs-uqn3-qvdm","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"If you use data from people that didn't consent or were compensated, it should be illegal. ",,,,,,,
"OSTP-TECH-2023-0007-0238","OSTP","OSTP-TECH-2023-0007","ljs-ukyz-bg0u","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See Attached",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0238/attachment_1.pdf",
"OSTP-TECH-2023-0007-0239","OSTP","OSTP-TECH-2023-0007","ljs-v62y-8eog","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Question 9: AI doesn't solve these problems. By cutting the value of skilled labor involved in tasks like writing and other creative endeavors, it removes money that can be paid to up and coming workers in both white collar jobs and creative spaces. IT could potentially serve as a really useful tool in education - supplementing textbooks and the work of teachers, -but other commercial iterations of the technology would see decimation of the fields students are preparing for in the first place. Who is going to aspire to be a journalist or a writer in a world where everything is written by bots and the markets are so saturated, work only brings in pennies?

Question 10: This is poison for under-served communities. Our commercial creative output is the direct result of what populations have historically had the funds to create and distribute things like films/comics, etc. Attempts to make televisions more diverse in the now are only necessary because of that history. White families have had the luxury of sending their kids to school, building real-estate value family wealth, meaning that their kids can go to college for the creative arts and pool money to take a shot making a movie or launching another creative industry. The result of this has been a skewed perspective in our media. Output coming predominantly from a certain set of backgrounds and experiences. That money and those perspectives still drive the industry despite the window dressing. By making it impossible for new creatives to actually survive in a field saturated by cheapened ai output - ai really just solidifies the above reality. Minorities without deep pockets will remain beholden to the image on the lens other people choose to depict us through. Cherry on top being that the ai products don't work without images stolen from many middle class creatives, including minorities who have finally managed to take steps towards controlling their own images in pages and on tv. This tech is poison for us. In my opinion at least.

11. The united states can actually defend the intellectual property rights who have been looted by the data scraping used to build these AI systems. Otherwise, this whole thing is just sound and fury with very little genuine good-faith intent to help the middle class.

We don't just need better regulation of these systems, we need actual serious enforcement. All I've seen are politicians bewitched by tech tools that might make the value of their stock portfolios go up.",,,,,,,
"OSTP-TECH-2023-0007-0240","OSTP","OSTP-TECH-2023-0007","ljs-uuk0-ktb6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0240/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0240/attachment_1.pdf",
"OSTP-TECH-2023-0007-0241","OSTP","OSTP-TECH-2023-0007","ljs-uv5n-f729","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"These are comments from the International Center for Law & Economics on the OSTP's Request for Information on National Priorities for Artificial Intelligence. We have also attached the comments we recently submitted to the NTIA on similar subjects. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0241/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0241/attachment_1.pdf",
"OSTP-TECH-2023-0007-0242","OSTP","OSTP-TECH-2023-0007","ljs-uw9b-fomu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0242/attachment_1.pdf",
"OSTP-TECH-2023-0007-0243","OSTP","OSTP-TECH-2023-0007","ljs-v5ol-v7xe","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached CTIA's comments responding to OSTP's RFI on National Priorities for AI.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0243/attachment_1.pdf",
"OSTP-TECH-2023-0007-0244","OSTP","OSTP-TECH-2023-0007","ljs-v8ht-73ht","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached document for the comments from the ACT-IAC AI Working Group.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0244/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0244/attachment_1.pdf",
"OSTP-TECH-2023-0007-0245","OSTP","OSTP-TECH-2023-0007","ljs-vm23-73eb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Regarding Artificial Intelligence, companies should not be able to used data without the owner's consent  and compensatstion. 

Generative AI of the arts, such as visual and digital art, music, writing, ect, is plagiarism, copyright infringement, fraud and theft  of property and labor. The outputs of such systems should never be considered as candidates for copyright. It should be illegal to utilize these outputs for commercial use. Any platforms, companies, or businesses, found selling, buying, or marketing with generative Ai, should be held criminally,and legally liable. At most, any use of Generative AI should be limited to private or personal use.  It should be made explicitly illegal for companies to train their AI systems on the data of their users/ customers without consent. There should only be opt-in systems.It should not be the people's responsibility to have to go through the  labor or opting out. The CEOs and owners of Generative Ai companies and software ( ei Midjjourney, Stable Diffusion,Dall-E,Devietart, Adobe, Sudowrite, etc) should be held criminally and financially liable for the data they scrap and use. They should be held reliable for the generative outputs of their customers.
Without heavy laws and regulation , companies at home and internationally will use AI and generative Ai to steal, exploit, and profit from people and companies' data, works, and labor. ",,,,,,,
"OSTP-TECH-2023-0007-0246","OSTP","OSTP-TECH-2023-0007","ljs-vaz1-93i3","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see full REVISED/CORRECTED comments attached....

	The Association for Computing Machinery (ACM) is the longest established and – with more than 50,000 American members ¬– the largest association of individual professionals engaged in all aspects of computing in the nation. A non-lobbying and otherwise wholly apolitical organization, ACM’s mission includes providing unbiased, expert technical advice to policymakers on matters of our members’ wide-ranging expertise. That work is accomplished in the United States by and through ACM’s U.S. Technology Policy Committee (USTPC).

	USTPC commends its most recent products concerning artificial intelligence to OSTP for its general consideration. They are its: June 27 Principles for the Development, Deployment, and Use of Generative AI Technologies [https://www.acm.org/binaries/content/assets/public-policy/ustpc-approved-generative-ai-principles], January 2023 ACM TechBrief: Safer Algorithmic Systems [https://dl.acm.org/doi/pdf/10.1145/3582277], and joint Statement on Principles for Responsible Algorithmic Systems of October 2022 [https://www.acm.org/binaries/content/assets/public-policy/final-joint-ai-statement-update.pdf]. 

	USTPC also offers the attached specific responses to select questions posed (and as numbered) in OSTP's Request for Information in the present proceeding.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0246/attachment_1.pdf",
"OSTP-TECH-2023-0007-0247","OSTP","OSTP-TECH-2023-0007","ljs-vtiu-d3jc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Introduction:
This new wave of generative Ai that has emerged over the past year, and exploded with the release of OpenAI’s ChatGPT, is all built on scraped from the entire internet, the vast majority of which is copyrighted. 

Impacts of Generative Ai:
I, and many working in creative professions, and terrified that these technologies are going to destroy entire job sectors, and severely worsen the working conditions in other fields. These fields include, but are not limited to digital illustration, concept art, graphic design, stock image creation, copywriting, entry-level programming, office admin, HR and more. 

Ai image generators like DALL-E, Midjourney, and Stable Diffusion can produce in seconds what could take an artist to produce in many hours or days. The datasets powering these applications are billions of images, again most of which are copyrighted. 

Generative Ai does not “learn” the way humans do:
There are many who will argue that GenAi “learns” to create art by drawing “inspiration” from existing images, and creating something new. There are many examples that show GenAi just straight up copying existing work, which could be confused for the original by a reasonable person. In addition, many people using Ai image generators will write an artist’s name in their text prompts, which actively encourages plagiarism. 

Even for work that looks new, the way GenAi takes input and processes data is completely different from the way humans do. Not to mention there are restrictions in creative professionals can use references in legal and ethical ways. Furthermore, this line of reasoning seems to want to see Ai as the same as humans. It makes Ai the protagonist of rules, regulations, and law. But laws are made to serve humans, they should not be made to serve technology. Technology does not eat or drink or need shelter, it does not have emotions, it cannot reproduce, it does not have consciousness. The push to say GenAi draws ‘inspiration’ from existing art like humans do is an opportunistic attempt to see these technologies as similar to humans, when they obviously are not. 

Copyright and lawsuits:
Some regulation is already occurring. The US Copyright Office is already says Ai generative images cannot be copyrighted without significant changes. Lawsuits are being brought against Ai companies like OpenAI and Stability AI by creative professionals as we speak, but those could take years to litigate. Government has the opportunity to get out in front of these technologies and regulate them sooner, and ensure the rights of dignity of creative professionals, and other jobs affected by GenAi are preserved. 

Conclusion: 
Protection of property is a cornerstone of western systems of government. I believe ownership of what a person creates is a big part of that. I hope future rules, regulations, and laws about these new Ai technologies puts human being, especially the dignity of creative professionals at the forefront. I hope people in these professions, are thoroughly consulted in the creation of new regulatory frameworks, and the enforcement of existing ones. I also hope you speak to Ai/Machine Learning experts like Timnit Gebru, Emily Bender, Margaret Mitchell and others in their orbit as you consider your options.",,,,,,,
"OSTP-TECH-2023-0007-0248","OSTP","OSTP-TECH-2023-0007","ljs-vht4-11nb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Automatic Data Processing, Inc. (ADP) is pleased to submit the attached comments in response to the Request for Information on National Priorities for Artificial Intelligence issued by the Office of Science and Technology Policy.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0248/attachment_1.pdf",
"OSTP-TECH-2023-0007-0249","OSTP","OSTP-TECH-2023-0007","ljs-vx6v-aa8f","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI needs to be banned or taxed 100%: it threatens millions of jobs and because it is a REPLACEMENT there are no new jobs to be had from it. It only decreases the number of available jobs. Where do you think people who loose their entire careers to this are going to go? To all these retail stores that are shutting down because the tech industry is also pushing them out of the market? Aside from clamping down on ai, the government needs to stop giving subsidies to tech companies and make it illegal to profit from data mining/scraping. Data mining/scraping happens without consent, you cannot use the ""don't use it"" excuse because these companies are just scraping everything off the web regardless of whether anyone even uses their services or agrees to their terms of service at all. A tech company that I don't even use any of the products of nor have ever signed any TOS for still is scraping my private data without my consent: that is a violation of my civil rights. Why is the government permitting this to happen? ",,,,,,,
"OSTP-TECH-2023-0007-0250","OSTP","OSTP-TECH-2023-0007","ljs-vppu-m44n","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Joint Comments of The Songwriters Guild of America, the Society of Composers & Lyricists, and the Music Creators North America Coalition are attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0250/attachment_1.pdf",
"OSTP-TECH-2023-0007-0251","OSTP","OSTP-TECH-2023-0007","ljs-w3do-8dtr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative AI is jeopardizing American jobs and American culture. Artists, actors, musicians, and writers are having their works and performances treated as nothing more than ""data"" to be fed into generative AI. This alone is dehumanizing, but the fact that they don't even receive any kind of income or royalties from the AI trained on their work is absolutely infuriating.

The nature of generative AI also puts American culture in danger, as generative AI cannot create something new on its own. That means that if Generative AI becomes the norm, American culture will become stagnant.

To protect the creative workers of America and to ensure American culture stays lively, we need to crack down on Generative AI.",,,,,,,
"OSTP-TECH-2023-0007-0252","OSTP","OSTP-TECH-2023-0007","ljs-wa46-gch9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Training AI off of people's work without their consent should not be legal. This applies to ANYTHING. In order to train AI you should be have to get the Explicit, In Paper, Consent of the person or persons who own the data that you want to train off of. This includes visual, written, and auditory datasets. There should also be monetary compensation for those who agree to have their data be used for training, and a way to take decisive legal action against those who violate this rule. There also needs to be a way to request for removal on any AI's database.

AI must also not be used for insidious means, such as surveillance.

The main goal is to prevent AI from being Abused and harming creatives, as well as being used as a threat to keep workers in poor working conditions. The culture surrounding AI should be built upon explicit consent between both parties, and compensation towards those who agree to cooperate.",,,,,,,
"OSTP-TECH-2023-0007-0253","OSTP","OSTP-TECH-2023-0007","ljs-w9p5-qp5h","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments from the Workgroup for Electronic Data Interchange (WEDI). Thank you for the opportunity to provide feedback on this important topic. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0253/attachment_1.pdf",
"OSTP-TECH-2023-0007-0254","OSTP","OSTP-TECH-2023-0007","ljs-wbck-fxeq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Alliance for Automotive Innovation (Auto Innovators) Comments to OSTP on National AI Priorities 7.7.2023",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0254/attachment_1.pdf",
"OSTP-TECH-2023-0007-0255","OSTP","OSTP-TECH-2023-0007","ljs-wcuu-8cah","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0255/attachment_1.pdf",
"OSTP-TECH-2023-0007-0256","OSTP","OSTP-TECH-2023-0007","ljs-wfll-r4xw","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Catalyte has chosen to respond directly to the Request for Information: National Priorities for Artificial Intelligence – Docket OSTP-TECH-2023-0007-0001.  Attached is a WORD document containing our comments on four of the Topic Areas included in the RFI.  Each topic number and question are listed within with our answers to follow.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0256/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0256/attachment_1.pdf",
"OSTP-TECH-2023-0007-0257","OSTP","OSTP-TECH-2023-0007","ljs-wjxl-ww7p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Code.org leads the steering committee for TeachAI, an initiative that is committed to providing thought leadership to guide governments and educational leaders in aligning education with the needs of an increasingly AI-driven world and connecting the discussion of teaching with AI to teaching about AI and computer science. The TeachAI steering committee includes ETS, the International Society for Technology in Education, and Khan Academy, and is in coordination with the World Economic Forum.

Code.org welcomes the partnership of the OSTP and the US Department of Education to address the recommendations in the responses below. We also welcome the opportunity to engage in policy discussions as part of the development of the National AI Strategy. We invite representatives from the OSTP and the US Department of Education to participate in our AI-related events, engage with US stakeholders, and learn alongside global leaders. Please contact pat@code.org for more information.

An initial draft of the responses below was informed, in part, by text created by ChatGPT. The text has been edited to reflect recommendations for making the most of the opportunities that AI provides, as well as addressing the challenges.


Advancing equity and strengthening civil rights
9. What are the opportunities for AI to enhance equity and how can these be fostered? For example, what are the potential benefits for AI in enabling broadened prosperity, expanding economic and educational opportunity, increasing access to services, and advancing civil rights?

AI can improve equity and education: 
Personalized Learning: AI can customize education for each student, understanding their pace, style, and areas of improvement, helping bridge knowledge gaps. 
Accessible Education: AI enhances accessibility in education. It can offer real-time translation for language learners or speech-to-text for hearing-impaired students, provided they have reliable internet and a computer. 
Predictive Analytics: AI can predict students at risk of lagging or dropout, enabling early interventions. 
Bias Reduction: AI can potentially reduce bias by objectively assessing performance, though caution is needed to prevent inadvertent bias propagation.

To harness AI's potential in education:
Define AI Literacy: This should encompass the responsible use of AI, its workings, and creative application, focusing on computer science foundations.
Teach AI: AI should be introduced at all educational levels, including K-12, higher education, and professional continuing education, with specialized degrees and certifications for up-to-date knowledge.
AI Policy Guidance: Educate policymakers to update policies, protecting student data, ensuring AI's ethical use, and promoting transparency in AI decisions.
Educator Training: Teachers need training to use AI ethically and understand its limitations. Grants should fund this professional learning.
Equity in AI Design: AI tools should be designed with equity, using diverse training data and checking for bias regularly.
Tech Access: All students need access to required technology, ensuring AI tools are accessible, including for those with disabilities.
Invest in Research: Research is necessary to study AI's application in education, its impact on learning, and potential downsides.

Promoting economic growth and good jobs
17. What will the principal benefits of AI be for the people of the United States? How can the United States best capture the benefits of AI across the economy, in domains such as education, health, and transportation? 

AI can ease teachers' administrative burden, allowing more focus on impactful teaching aspects:
Automated Grading: AI can grade tests, including complex responses like essays, saving time.
Learning Analytics: AI can spot patterns in student performance, identifying struggling topics or students at risk, saving analysis time.
Personalized Learning Plans: AI can develop tailored learning plans per student, reducing manual plan creation.
Administrative Tasks: AI can automate tasks like scheduling, parent communication, and record-keeping.

The saved time enables:
Individual Attention: More one-on-one time with students for personalized feedback.
In-Depth Instruction: Deeper exploration into complex topics for thorough student understanding.
Social-Emotional Learning: Focus on skills like empathy and collaboration, nurturing student relationships.
Professional Development: Extra time for teachers to learn new strategies or update educational research knowledge.
Creative Learning: Incorporation of engaging methods like project-based learning to enhance student understanding.

By reducing the administrative burden on teachers, AI can allow teachers to focus more on their core mission: facilitating learning and growth for their students. By improving teacher satisfaction, the teaching profession may be more attractive, and more teachers may be retained, leading to a reduction in local teacher shortages.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0257/attachment_1.pdf",
"OSTP-TECH-2023-0007-0258","OSTP","OSTP-TECH-2023-0007","ljs-wl03-ipbo","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0258/attachment_1.pdf",
"OSTP-TECH-2023-0007-0259","OSTP","OSTP-TECH-2023-0007","ljs-wyq3-pfnd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI will have negative widespread consequences across all media.
It is merely a machine that spits out reorganized content with no care for accuracy or artistic integrity. 
We have already seen the negative side affects of this technology and how it has harmed and misinformed large numbers of people.",,,,,,,
"OSTP-TECH-2023-0007-0260","OSTP","OSTP-TECH-2023-0007","ljs-wobo-gv4z","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Bank Policy Institute, through its technology policy division known as BITS, appreciates the opportunity to respond to OSTP’s National Priorities for Artificial Intelligence request for information. Please see our comments in the attached document.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0260/attachment_1.pdf",
"OSTP-TECH-2023-0007-0261","OSTP","OSTP-TECH-2023-0007","ljs-wv3p-dvfm","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0261/attachment_1.pdf",
"OSTP-TECH-2023-0007-0262","OSTP","OSTP-TECH-2023-0007","ljs-wvpq-xz7r","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0262/attachment_1.pdf",
"OSTP-TECH-2023-0007-0263","OSTP","OSTP-TECH-2023-0007","ljs-xa3e-lwtz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI was once thought to be a potentially good addition to the technological world as we advance towards futuristic opportunities. However, with its present emergence, the technology itself is being used to steal and use what it has taken from creatives, such as authors and artists from around the world, against their wishes of keeping copyright. As it is well stated within regulations, copyright to a work such as art or a piece or writing is automatically granted the moment the process starts by the original creator. AI “learns” of course, but like humans it can only learn from the information fed into it. It is not taking “inspiration”, it is downright absorbing styles from authors’ writing and artists’ years of developing their own unique style—all without permission. 

There are many individuals today who just upload an author’s unfinished work into AI and with one command to tell the technology to finish it, it will do so. Giving the original work an ending mechanically written not relaying the original creator’s wishes or thoughts. That in itself is immoral similarly to if someone were to steal an engineer’s project and then complete it on their own and putting their name on it at the end. Before AI, if a regular person were to do this to another person with their own two hands, it would be noted as plagiarism and copyright infringement. 

With Google’s alarming change in privacy policy stating that they are able scrape web data as soon as information is made public by users, such as authors posting chapters on a blog or novel site, it is all fair play to get scraped for the AI. While the policies aren’t specific as of yet for how private data goes into it, a lot of companies use Google services in order to do collaborative work. Some of that work is protected by NDA and in some cases HIPAA. 

AI must be limited and regulated in order to protect privacy rights of individuals and to protect the copyright that creators have worked so hard to sculpt with their hands. Compensation should be provided if AI has wrongly absorbed works before a law has passed, and permission must be obtained from the creator before anything can be put in. People should be able to take legal action if they find out their works were stolen and put into AI without their permission. Companies such as ChatGPT, Fotor AI, Midjourney should not allow users to create generic images or writing for commercial user and should not be allowed to apply for copyright as the elements used is pulled from original creatives without their permission. 

We have seen over the news that AI can absorb voices: tones of voices, way of speaking, etc. This can create a very dangerous environment for scammers as there are cases where scammers are now able to mimic voices of family members or programmed AI that can call thousands of people a day compared to what it could have been before but all in a more susceptible tone. People on the internet use AI to replicate the voices and speech of past presidents for their entertainment as well, it’s all on YouTube. 

AI is something that was supposed to be innovative leaning towards the benefits of humans. However, without proper regulation and protection, it is becoming a tool many people are afraid of and are bound to be afraid of. Companies like Google who will scrape web data even in private places, emails and documents, if they aren’t regulated for privacy are cause for concern. Without proper laws to limit and protect works and copyright, to protect individual elements of privacy, there is no room for growth to what would be the potential benefits of AI. For now, the only thing AI is doing is mainly harming the livelihoods of creators and posing a potential danger for scams and identity risks. 

Please regulate and limit AI usage to protect works, privacy, and identities of creatives and individuals online as well as limiting the companies developing this technology.",,,,,,,
"OSTP-TECH-2023-0007-0264","OSTP","OSTP-TECH-2023-0007","ljs-wyuk-jsgr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Response from Maximus Federal for the RFI on National Priorities for Artificial Intelligence",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0264/attachment_1.pdf",
"OSTP-TECH-2023-0007-0265","OSTP","OSTP-TECH-2023-0007","ljs-xcso-wl40","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is no ethical way of using AI. By default it is a system that takes input, rarely at with the consent of the original artists or creators, and those who would use AI would claim such content as there own.
The only situation where it would be even remotely ethical to use AI is with the express consent from the authors and creators for their works to be fed into the data. However this is a logistical impossibility as there is no way to account for those who would copy data wholesale and enter it in anonymously.
As such AI should not be considered for professional use or for personal gain for any reason and those who would do so should be  charged for crimes of theft.",,,,,,,
"OSTP-TECH-2023-0007-0266","OSTP","OSTP-TECH-2023-0007","ljs-x69n-sj2e","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0266/attachment_1.pdf",
"OSTP-TECH-2023-0007-0267","OSTP","OSTP-TECH-2023-0007","ljs-xdij-3beu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1.)
As it stands, there are no regulations when it comes to input and output stages of generative AI. Without consent, compensation or credit, large tech companies have used billions of copyrighted images, texts, voice recordings and music for profit. All negative consequences of AI on the labor market of the near future will be due to this untethered scraping and reappropriating 
of data. 

The way these models can store so much data is by encoding differences between inputs, so for instance with photos of shoes, it would not store the same background multiple times, but rather it encodes the deltas - the differences - between them. The same applies to large LLMs. Stable Diffusion, a freely shared model, and others contain billions of images stored in their models, which is possible due to probability space compression that far exceeds human capabilities. Out of these reasons, comparing an AI agent to humans is not realistic.

In specific examples, it has been found that these models can overfit and output almost 1 to 1 copies of their original dataset, which is especially the case with outlier data or data that appears multiple times. Is it acceptable that these original creators have their copyright trampled on in this most direct manner, their data being accessible to anyone using AI models? Attached is a study going over diffusion models’ capability to plagiarize. The trend of these programs to overfit and memorize is worrying given that the datasets of image generators contain private photos, non-consensual sexual images and private medical data among others.
Looking across the aisle at the music industry, Google did not dare to release their music AI model, and Dance Diffusion, Stable Diffusion’s music AI, is trained on public domain and consensually given samples in order to ""honor the intellectual property of artists"". Songs made in the likeness of famous musicians have been pulled immediately from social media. In this hypocrisy it becomes clear that generative AI developers do not see their programs as ""just like how humans do it"". It is clear that with their fidelity and accuracy in copying, it goes far beyond human capability, and it should be treated as such. 

No human copying is going to impact the original like a program that can generate endless imitations. This abuse is not in the spirit of the law of fair use, it stifles creators and makes it seemingly impossible to stand out amidst billions of AI clones. All that while these programs rely on original creators to improve their models. A model doesn’t discern like a human would, trained on its own output, its performance degrades as the mistakes it makes are encoded deeper. This is also the reason why Stability AI founder, Emad Mostaque, has advocated for ""going behind the firewalls if you’re smart and getting private data"" [see attachments]. One party is being ripped off for the benefit of the other.

Companies like OpenAI themselves do not allow others to use their data to train competitive models [see attachments]. They have the backing and manpower to wage legal campaigns against anyone that breaks their conditions, individual creators on the other hand are left helplessly watching as the livelihoods they built for themselves come crumbling down. All these works were created in an environment without AI, a human-centric space, and now creators are left blindsided by this novel misuse of their works.

To prepare society for the challenges of the 21st century, AI has to be treated differently from human agents. The flood of content AI can generate uproots the original market unlike anything in history, all the while using the data of original creators to unseat them. No such thing has ever happened in human history at such a scale; novel inventions that caused similar upheavals for workers like sewing machines did not rely on the work of these creators to do so. Is it fair that the very work one makes to support themselves and their families ends up being used to threaten that very thing? 

It is the purpose of the government to protect the people that can’t protect themselves against such abuse; to consider the will of the people over the pull of giant corporations. 

Please take action to protect millions of creators from this data harvesting and misuse of their labor. Suggestions for the Copyright Office are:

1. Upholding Fair Use, particularly the 4th clause about the impact on the original's market and value.  It is not fair use to have creators' own work used against themselves in this manner.
2. Wherever necessary, updating copyright law that was meant for human agents in order to prevent AI clones and identity theft. As it stands, simple prompts with original creators' names can be used to create less and less distinguishable clones in writing, composing, voice acting, painting and so on, far beyond human capabilities.

Further, it is necessary for the Department of Justice to enforce consent at the training level.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_10.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_10.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_7.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_7.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_4.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_4.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_1.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_1.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_9.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_9.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_5.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_5.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_3.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_8.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_8.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_6.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_6.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_2.jpg,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0267/attachment_2.pdf",
"OSTP-TECH-2023-0007-0268","OSTP","OSTP-TECH-2023-0007","ljs-xjnc-p58i","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0268/attachment_1.pdf",
"OSTP-TECH-2023-0007-0269","OSTP","OSTP-TECH-2023-0007","ljs-xlid-krlt","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Alliance for Learning Innovation (ALI) brings together education nonprofits,
philanthropy, and the private sector, to advocate for building a better research and
development (R&D) infrastructure in education. Considering that R&D is a relatively
untapped engine of innovation in the education sector, ALI advocates for increased capacity
of education R&D and supports the research and development of evidence-based
innovation that centers students and practitioners, advances equity, improves talent
pathways, and expands the workforce needed in a globally competitive world.

ALI sees great promise and opportunity for artificial intelligence to improve education, equity,
economic opportunity, and national security. In order to realize this opportunity and mitigate
risks, we must ensure that the US has a robust, inclusive, and updated education R&D
ecosystem that crosscuts federal agencies, and with the Institute of Education Sciences (IES)
playing a key role in driving forward an AI agenda that improves educational outcomes,
mitigates the risks associated with AI, and that guides critical policies and guidelines for its use.

Stunning advancements in generative AI, most recently demonstrated by ChatGPT, show the
potential of what R&D could do. With careful design, stakeholder engagement and attention to
research and development, there is potential for AI to improve teaching, learning, and equity. A
healthy education R&D ecosystem will cultivate future generations of talent in the STEM fields
(including AI) and lead to innovations that strengthen national security and our global
competitiveness. However, this cannot be accomplished without simultaneously investing in
strong education R&D infrastructure that helps us develop equitable and safe uses of AI
technologies.

One strong existing Federal example are the AI Institutes supported by the National Science
Foundation (NSF) and the U.S. Department of Education (ED). Earlier this year, NSF and IES
established the AI Institute for Exceptional Children, which capitalizes on the latest AI research
to serve children with speech and language pathology needs. Communities would benefit from
additional AI Institutes that meet the moment and deliver solutions for today’s teaching and
learning challenges. Privacy and bias considerations need to be inherent in the research
questions being tackled by these and other federally funded AI research efforts.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0269/attachment_1.pdf",
"OSTP-TECH-2023-0007-0270","OSTP","OSTP-TECH-2023-0007","ljs-y1id-5t9i","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Artificial Intelligence results will undoubtedly be seen before the public, and the danger of Deep-Fakes, A.I. created ""news stories"" are bound to plague the media and space of public discourse.  We need strong laws to identify and enforce those who would misuse this technology, be it foreign adversaries, criminals within our border, or those intent of disrupting the publics right to good and truthful information.  Strong legislation must require a logo ""created with A.I."" to identify all information (text, graphic, musical, or any design not human-created including that with editing and without editing by humans) which has at its root Artificial Intelligence. I propose that this logo (branding for A.I.) be available as a logo and with a sister character to be available in all commercially available fonts, such as UTF-8 and all other character sets.  There is sufficient concern to retroactively include it in the EBCDIC and ASCII character sets.",,,,,,,
"OSTP-TECH-2023-0007-0271","OSTP","OSTP-TECH-2023-0007","ljs-xvht-wlh9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached for comments of the Connected Health Initiative",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0271/attachment_1.pdf",
"OSTP-TECH-2023-0007-0272","OSTP","OSTP-TECH-2023-0007","ljs-xw5w-1zqt","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On behalf of Palantir Technologies Inc. (“Palantir”), we respectfully submit this response to the Office of Science and Technology Policy (“OSTP”) regarding the “Request for Information: National Priorities for Artificial Intelligence” (OSTP-TECH-2023-0007-0001). We welcome efforts by the OSTP in calling attention to the opportunities and challenges surrounding the development and adoption of Artificial Intelligence (“AI”), including the corresponding need to establish national priorities for this emerging technology. In the attached document, we provide our perspective – informed by over two decades of industry knowledge – on how the United States can create a National Artificial Intelligence (“NAI”) Strategy that successfully harnesses the benefits of AI while mitigating the risks associated with its development and use.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0272/attachment_1.pdf",
"OSTP-TECH-2023-0007-0273","OSTP","OSTP-TECH-2023-0007","ljs-xyan-o66q","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0273/attachment_1.pdf",
"OSTP-TECH-2023-0007-0274","OSTP","OSTP-TECH-2023-0007","ljs-y0zq-akji","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Climate Change AI is pleased to respond to OSTP’s Request for Information on National Priorities for Artificial Intelligence. Please see the attached file for our comment. 
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0274/attachment_1.pdf",
"OSTP-TECH-2023-0007-0275","OSTP","OSTP-TECH-2023-0007","ljs-y1r1-1w8w","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments submitted on behalf of the Center for Data Innovation.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0275/attachment_1.pdf",
"OSTP-TECH-2023-0007-0276","OSTP","OSTP-TECH-2023-0007","ljs-y646-wpu6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This brief letter provides initial comments from the education perspective that should inform a national AI strategy, including the need to maximize education opportunities and minimize education risks. AI has profound implications for education, and these should be front of mind in designing an overall national AI strategy. To start, this means we must ensure that critical actors and stakeholders from the education community are at the table as a national AI strategy is developed, implemented, and continuously improved.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0276/attachment_1.pdf",
"OSTP-TECH-2023-0007-0277","OSTP","OSTP-TECH-2023-0007","ljs-y6mk-ctsj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached file for full comment.

Thank you for the opportunity to respond to the White House Office of Science and Technology Policy’s Request for Information (RFI) regarding national priorities for artificial intelligence (AI). 

This comment is submitted by Accountable Tech, a nonpartisan, nonprofit organization that advocates for structural reforms to repair our information ecosystem and foster a healthier and more equitable democracy. This comment pertains to questions 1, 7, 10, 11, 14, 15, 16, 26, and 29 in OSTP’s request for comment. 

The potential economic and social benefits of AI-powered technologies – along with the hype cycle surrounding it – have understandably generated a swell of excitement. Unfortunately, the current trajectory of the AI arms race has us far away from realizing those rosy visions, and instead demands we grapple with the urgent threats these systems are exacerbating.  

Accountable Tech has spent years working to address the systemic drivers of the information crisis we are living in, which has pushed democracy to the brink – from campaigning to end the surveillance advertising business model that rewards harmful lies and extremist content, to devising a sweeping election integrity roadmap to combat efforts to deceive voters and manipulate public discourse. 

The arrival of generative AI adds harrowing new layers to the ever-deepening information crisis. Generative AI tools are capable of producing fake news articles, social media posts, videos, and audio clips that are becoming less and less distinguishable from authentic content. These tools are widely accessible today and are already being used to wage coordinated propaganda campaigns that threaten to undermine elections and democratic institutions, posing an immediate and urgent threat. 

We applaud the Biden administration for the steps it has already taken to harness the good and confront the harms of AI writ-large – from engaging key stakeholders, to hosting learning sessions, and releasing an AI Bill of Rights, among many other efforts – and for issuing this RFI to solicit input from public interest groups like Accountable Tech and other stakeholders as that critical work continues.  

Please continue to read this comment in the attached file.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0277/attachment_1.pdf",
"OSTP-TECH-2023-0007-0278","OSTP","OSTP-TECH-2023-0007","ljs-y6o7-3w6w","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached for comments of ACT | The App Association",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0278/attachment_1.pdf",
"OSTP-TECH-2023-0007-0279","OSTP","OSTP-TECH-2023-0007","ljs-ycfu-rmm9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0279/attachment_1.pdf",
"OSTP-TECH-2023-0007-0280","OSTP","OSTP-TECH-2023-0007","ljs-yhun-hw8d","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We are pleased to contribute to this request to information. Please find WITNESS' submission attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0280/attachment_1.pdf",
"OSTP-TECH-2023-0007-0281","OSTP","OSTP-TECH-2023-0007","ljs-ykcp-42ri","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1. While considering regulations, it’s important to ensure startups' and small businesses' voices are represented in discussing the opportunities and risks of AI systems. 
Diverse Perspectives: Startups and small businesses often bring fresh perspectives and innovative ideas. Their unique experiences and approaches can contribute to a more holistic understanding of the opportunities and risks associated with AI systems in cybersecurity.
Tailored Solutions: Small businesses may face different cybersecurity challenges than larger enterprises due to limited resources, budget constraints, or specific industry requirements. By including their voices, policymakers can better understand their needs and develop realistic, scalable, and practical regulations for these businesses.
Economic Growth: Startups and small businesses drive economic growth and foster innovation. Regulations that disproportionately burden smaller players could hinder their ability to compete and thrive in the market. Engaging with them in regulatory discussions ensures that the rules are not overly burdensome, allowing them to continue innovating and contributing to the cybersecurity ecosystem.
Access to Expertise: Startups and small businesses may have expertise in niche areas of cybersecurity or AI technology. Their participation in discussions allows policymakers to tap into this specialized knowledge and gain insights that might be overlooked otherwise. 

 2. Regulation should be scoped to not deter startups and small businesses from using AI to ensure a broad and diverse array of businesses can access economic growth.  
Risk-based approach: Implement regulations proportionate to the potential risks AI applications pose in the cybersecurity industry. Tailor the regulatory requirements based on the scale, complexity, and potential impact of the AI systems used. This approach ensures that startups and small businesses with lower-risk AI applications face less burdensome regulations while addressing critical concerns.
Clear guidelines and standards: Develop clear guidelines and industry standards that outline best practices and security measures for AI in the cybersecurity domain. These guidelines help startups and small businesses understand the expectations and requirements for the safe and responsible use of AI technologies. Promote transparency and provide educational resources to assist businesses in meeting these standards.
Regulatory sandboxes: Establish regulatory sandboxes or innovation zones where startups and small businesses can test and deploy AI technologies in a controlled environment. These sandboxes can provide exemptions or streamlined regulatory processes, allowing businesses to experiment with AI solutions while adhering to essential safety and security principles. This approach fosters innovation while ensuring potential risks are adequately addressed.
Collaboration and consultation: Engage in active collaboration and consultation with stakeholders from the startup and small business community, including industry associations, entrepreneurs, and technology experts. Solicit their input and feedback during the regulatory development process to ensure that the needs and challenges of these businesses are understood and appropriately addressed.
Supportive policies and funding: Implement supportive policies and funding initiatives targeting startups and small businesses in the cybersecurity industry. Provide financial assistance, grants, or tax incentives to encourage the adoption of AI technologies while ensuring compliance with relevant regulations. Such measures can help alleviate the financial burden associated with compliance and spur growth in the sector.
Flexibility and adaptability: Foster a regulatory framework that can adapt to the rapidly evolving nature of AI technologies. Establish mechanisms for periodic review and update of regulations to incorporate advancements and emerging best practices. This approach enables startups and small businesses to leverage the latest AI innovations without being hindered by outdated or overly rigid regulatory requirements.
Regulatory coordination and harmonization: Promote coordination and harmonization of AI regulations at national and international levels. Inconsistencies and fragmented regulations can create barriers for startups and small businesses operating across different jurisdictions. Encouraging alignment and cooperation among regulatory bodies can facilitate a more accessible and level playing field for businesses in the cybersecurity industry.
Please see the attached file for more comments.


",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0281/attachment_1.pdf",
"OSTP-TECH-2023-0007-0282","OSTP","OSTP-TECH-2023-0007","ljs-yxce-w2md","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI was trained on the works and writings of millions of individuals and now every one of us has to compete with a machine we helped train but receive marginal benefits from while these corporations that stole our data rake in millions. The workers that are likely be affected by this need to be prioritized, artists need their work protected and everyone needs more digital privacy protection so these technologies are not trained on pictures of us and our families that we post for ourselves and our friends. These corporations are disrupting several pillars of society and their replacement is tangibly worse than what we have. The main focus when approaching AI issues should be “how does this effect our workers?” As these AI models cannot be trained without the unethical scraping of art and digital information, one must wonder if this technology deserves to exist at all. In addition to those issues, AI Deepfakes must be regulated, especially with the ability to put anyone’s face on sexually explicit content. Many women have already been victim to deepfake harassment, one may even argue that it is the equivalent of revenge porn. It may sound like a stretch calling it the equivalent of revenge porn, but when it is not made explicitly clear that it is a fake video or image it can be incredibly hard to figure out wether or not the content is real or fake, and to the passerby who won’t investigate any further, for all they know they saw a genuine image of that woman. ",,,,,,,
"OSTP-TECH-2023-0007-0283","OSTP","OSTP-TECH-2023-0007","ljs-yn53-z969","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comments from the ACT-IAC AI Working Group. Thank you.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0283/attachment_1.docx",
"OSTP-TECH-2023-0007-0284","OSTP","OSTP-TECH-2023-0007","ljs-yqak-mn3u","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find comments from Digital Content Next (DCN), the only association exclusively focused on paving the future for high-quality digital media companies. We appreciate your solicitation for comments and look forward to working with you.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0284/attachment_1.pdf",
"OSTP-TECH-2023-0007-0285","OSTP","OSTP-TECH-2023-0007","ljs-ywfl-6kxt","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please accept this final version of SHRM's comments.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0285/attachment_1.pdf",
"OSTP-TECH-2023-0007-0286","OSTP","OSTP-TECH-2023-0007","ljs-z131-uzbr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The attached comment is submitted on behalf of AASA, The School Superintendents Association and the AASA Student and Child Privacy Center.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0286/attachment_1.pdf",
"OSTP-TECH-2023-0007-0287","OSTP","OSTP-TECH-2023-0007","ljs-z2ie-anc2","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0287/attachment_1.pdf",
"OSTP-TECH-2023-0007-0288","OSTP","OSTP-TECH-2023-0007","ljs-zfsv-u53l","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generative AI (genAI) is being touted as a benevolent technology that can improve society, but the reality is that genAI is causing widespread harm and is emboldening tech companies to push ethical boundaries.

First, LAION5B has been proven to have the faces and names of real people in their datasets as well as addresses, emails, and bank accounts. Stable Diffusion and Lensa took users' private medical data and facial biometrics without the users' consent. The founder of Stability AI has stated that if public data would be exhausted, bypassing firewalls would be the next option (i.e. hacking users for their private information). Currently, Google has changed their privacy policy that allows Google to scrape users' private data to train Google's AI projects-but again- without users' consent and no prior notice to allow users to wipe their data.

What about the dangers of genAI being built from this data and having this technology available for everyone to use? Thanks to the scraping of biometric data, it is possible for users of genAI to create massive quantities of pornography based on real people without their consent (this is extends to children as well). Despite what AI advocates may say, this data cannot be unlearned without replacing current AI models with older versions. What that means is the identities and likenesses of these people will inevitably resurface as AI develops, even if users do not intend it.

Another concern of AI is how it contributes to spread of misinformation. But before that, it must be understood that AI is not actually intelligent; it only resembles human intelligence. That is why if one were to ask ChatGPT-for example- ""What does 2 + 2 equal?"" ChatGPT may get it right, maybe even on the first try. But ask again, and ChatGPT may respond with 5. Or one can simply insist the answer is 5, and ChatGPT will eventually agree. AI is incapable of being intelligent because it is unable to conceptualize ideas like mathematics. AI can only make approximations based on the data given, and AI ingests data indiscriminately.

Therefore, it would be unwise to have AI at the forefront of most logical or creative endeavors unless the AI models in question were carefully trained in closed environments by professionals. But most models like ChatGPT are not trained like that. Even more concerning, tech companies are insistent on selling users these public models on the premise that AI can do almost anything: journalism, therapy, movie directing, policing, etc. We have already seen cases of how unreliable or dangerous AI can be like a lawyer using an AI for assistance only to discover the AI fabricated court cases. Or how one user committed suicide when encouraged by an AI. And do not discount the usage of AI in creating political propaganda. For instance, there were photos circulating at an alleged French protest rally that looked convincing-except for the photo of a six-fingered officer embracing a protester. The Republican party has already taken to using AI in their advertising; voice and image AI has already been well trained on prominent figures like Joe Biden and Donald Trump and is able to capture their likenesses fairly consistently. This usage of AI is unacceptable, especially in this current political climate. 

Lastly, there is the issue of how AI relates to the workforce. Another common selling point of genAI is how it can be a tool to aid workers with menial labor. While I could go on to dispute how such claims do not hold weight in creative fields like writing and digital art, the more important point of the matter is that AI is not being used to help workers but to replace them altogether. We can see this overseas where the Chinese video game industry has laid off nearly 70% of their artists in favor of AI. Voice actors are under threat of Hollywood replacing them with AI trained with their voices. ChatGPT is capable of creating fully-fleshed stories in minutes, and online stores are flooded with AI created content. And artists have been seeing a steady decline in online commissions which are crucial to an artist's livelihood. It is evident that AI is taking far too many jobs than creating them, and we could see a surge of unemployment in the coming years unless adequate AI regulation is drafted and enforced. 

When discussing AI regulation, it would be irresponsible to disregard these facts. Bearing that in mind, here are some of the regulations I would like to see:

1 - Require websites to tag AI content
2 - Enforce a reasonable limit on AI usage for companies to ensure stable human employment
3 - Restrict AI models to be trained opt-in only
4 - Full public disclosure of the datasets AI models were trained on

But above all, it is paramount to have real artists, writers, and various workers affected involved in these discussions of regulation. They would offer even greater insights to what regulations are needed to have AI ethically exist in our society.",,,,,,,
"OSTP-TECH-2023-0007-0289","OSTP","OSTP-TECH-2023-0007","ljs-z45m-cxxw","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Trustworthy AI depends on socio-techncial standards as described in “The Future of AI Governance” [attachment 1].  The G7 leaders' joint communiqué in May 2023 called for development and adoption “of international technical standards in standards development organizations through multi-stakeholder processes” to govern the development and deployment of AI.  The IEEE P2874 Spatial Web socio-technical standards respond to the G7 call by addressing national priorities for mitigating AI risks, protecting individuals’ rights and safety, and harnessing AI to improve lives. These points are discussed in the following paragraphs followed by commitments by the Spatial Web Foundation (SWF).

The IEEE Standards Association is developing a wide range of standards and methods to address safety, biases, transparency, privacy, and corporate governance in Artificial  Intelligence.   IEEE P2874 Spatial Web socio-technical standards provide for trustworthy collaboration of humans, machines, and AI in the next generation internet.  The IEEE Standards Association has identified IEEE P2874 as a “Public Imperative.” 

Identical to the G7 Hiroshima Leaders’ Communiqué, SWF advocates for “further advancing multi-stakeholder approaches to the development of standards for AI...and encourage the development and adoption of international technical standards in standards development organizations through multi-stakeholder processes.”

As described in “The Future of AI Governance” [attachment1], early incorporation of socio-technical standards into AI systems is critical as these systems are already rapidly integrating into society. We need to put measures in place to steer these systems before they become increasingly autonomous. Proactive governance measures are needed to efficiently integrate AI into daily life, foster innovation, and protect against harm while accelerating its benefits. IEEE P2874 provides the socio-techncial standards to meet these objectives.

The development and implementation of socio-technical standards, rather than solely focusing on ""technical"" standards, is the key to ensuring that AI systems are utilized in a manner that aligns with our societal values, safeguards our legal rights, and advances our collective well-being, all while fostering technical excellence and innovation.

The approach of IEEE P2874 as defined in The Future of AI Governance, is consistent with the OECD Agile Regulatory Governance to Harness Innovation recommendation to develop governance frameworks to enable the development of agile and future-proof regulation by: Developing more outcome-focused approaches to enable innovation and to Harness the opportunities provided by non-legally binding approaches either as an alternative or as a complement to other regulatory instruments.

Federal participation in open standards development is needed as it signals to industry the possible basis of future regulation.  Industry, including large companies, such as Microsoft and Google, have committed to working with other industry leaders and those in government to develop new and additional standards.  While these commitments are suggestive of interest in standards, often key interoperability standards are not of a priority to organizations that maintain large platforms.  For example, Microsoft’s Blueprint is silent on establishing open standards in the most key location of the technology stack; APIs for accessing AI.  As identified in the NAIAC Report, May 2023, it is imperative to empower small- and medium-sized organizations for trustworthy AI development and use.  Open standards are critical to enable industry organizations of all sizes to adopt trustworthy AI. SWF encourages government and diverse industry participation in IEEE P2874 Spatial Web working group.

The Spatial Web Foundation (SWF) commits to the White House to help develop consensus concepts for AI Governance using the Spatial Web and AI to drive value and lower risk in the next generation internet. SWF will chair the IEEE P2874 Standards Working Group and, working with IEEE, will spearhead global efforts with governments and regulators toward the adoption of open socio-technical standards for Trustworthy AI.    


Attached File:
- Attachment1_Future of AI Governance (executive summary)
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0289/attachment_1.pdf",
"OSTP-TECH-2023-0007-0290","OSTP","OSTP-TECH-2023-0007","ljs-z8p4-ppit","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"SWF Response to Question #1. 

Trustworthy AI depends on socio-techncial standards as described in “The Future of AI Governance” [attachment 1].  The G7 leaders' joint communiqué in May 2023 called for development and adoption “of international technical standards in standards development organizations through multi-stakeholder processes” to govern the development and deployment of AI.  The IEEE P2874 Spatial Web socio-technical standards respond to the G7 call by addressing national priorities for mitigating AI risks, protecting individuals’ rights and safety, and harnessing AI to improve lives. These points are discussed in the following paragraphs followed by commitments by the Spatial Web Foundation (SWF).

The IEEE Standards Association is developing a wide range of standards and methods to address safety, biases, transparency, privacy, and corporate governance in Artificial  Intelligence.   IEEE P2874 Spatial Web socio-technical standards provide for trustworthy collaboration of humans, machines, and AI in the next generation internet.  The IEEE Standards Association has identified IEEE P2874 as a “Public Imperative.” 

Identical to the G7 Hiroshima Leaders’ Communiqué, SWF advocates for “further advancing multi-stakeholder approaches to the development of standards for AI ... and encourage the development and adoption of international technical standards in standards development organizations through multi-stakeholder processes.”

As described in “The Future of AI Governance”, early incorporation of socio-technical standards into AI systems is critical as these systems are already rapidly integrating into society. We need to put measures in place to steer these systems before they become increasingly autonomous. Proactive governance measures are needed to efficiently integrate AI into daily life, foster innovation, and protect against harm while accelerating its benefits. IEEE P2874 provides the socio-techncial standards to meet these objectives.

The development and implementation of socio-technical standards, rather than solely focusing on ""technical"" standards, is the key to ensuring that AI systems are utilized in a manner that aligns with our societal values, safeguards our legal rights, and advances our collective well-being, all while fostering technical excellence and innovation.

The approach of IEEE P2874 as defined in The Future of AI Governance, is consistent with the OECD Agile Regulatory Governance to Harness Innovation recommendation to develop governance frameworks to enable the development of agile and future-proof regulation by: Developing more outcome-focused approaches to enable innovation and to Harness the opportunities provided by non-legally binding approaches either as an alternative or as a complement to other regulatory instruments.

Federal participation in open standards development is needed as it signals to industry the possible basis of future regulation.  Industry, including large companies, such as Microsoft and Google, have committed to working with other industry leaders and those in government to develop new and additional standards.  While these commitments are suggestive of interest in standards, often key interoperability standards are not of a priority to organizations that maintain large platforms.  For example, Microsoft’s Blueprint is silent on establishing open standards in the most key location of the technology stack; APIs for accessing AI.  As identified in the NAIAC Report, May 2023, it is imperative to empower small- and medium-sized organizations for trustworthy AI development and use.  Open standards are critical to enable industry organizations of all sizes to adopt trustworthy AI. SWF encourages government and diverse industry participation in IEEE P2874 Spatial Web working group.

The Spatial Web Foundation (SWF) commits to the White House to help develop consensus concepts for AI Governance using the Spatial Web and AI to drive value and lower risk in the next generation internet. SWF will chair the IEEE P2874 Standards Working Group and, working with IEEE, will spearhead global efforts with governments and regulators toward the adoption of open socio-technical standards for Trustworthy AI.  


Attached Files
Attachment_Future of AI Governance (executive summary)

(Note a duplicate version of this comment was previously submitted, but the previous response did not identify it was responding to question #1.  Delete the previous comment.  Retain this comment.) 
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0290/attachment_1.pdf",
"OSTP-TECH-2023-0007-0291","OSTP","OSTP-TECH-2023-0007","ljs-zagt-yv4g","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1. What specific measures – such as standards, regulations, investments, and improved trust and safety practices – are needed to ensure that AI systems are designed, developed, and deployed in a manner that protects people’s rights and safety? Which specific entities should develop and implement these measures?

The most important measure which could feasibly be implemented today is an indefinite moratorium on any training runs utilizing more than 10^23 FLOP (Floating Point Operations), per the recommendation of AI safety researchers via stop.ai/proposals. This is important because today's AI systems already have some dangerous capabilities, such as an understanding of how to synthesize lethal pathogens (Soice et al., 'Can large language models democratize access to dual-use biotechnology?'). Not only can these capabilities be misused by humans, but there is furthermore a risk of unknown likelihood that newer, more powerful models might utilize these dangerous capabilities in pursuit of their own goals (Benson-Tilsen et al., 'Formalizing Convergent Instrumental Goals'). 

The strength of a model's capabilities are largely a function of the amount of compute used to train that model (Kaplan et al., 'Scaling Laws for Neural Language Models'), alongside other factors such as software efficiency. By placing a limit on the amount of compute used to train a single model the advent of unprecedentedly dangerous models can be delayed until software efficiency catches up, and meanwhile the overwhelming majority of AI use cases for businesses and individuals can continue unabated (since very very few models are trained using this amount of compute). This would buy years worth of precious time for AI safety researchers to better understand exactly where the thresholds for danger lie, and to mitigate the risks posed both by bad human actors and by rogue AIs. 

In addition to the moratorium on large training runs, as a student working on entering a career in AI safety I wholeheartedly endorse all of the other policy recommendations on stop.ai/proposals as well. I would furthermore strongly encourage the US government to match or exceed the UK government's recent pledge of £50 million towards AI safety, as for the past decade the field of AI safety research has received less than 1% of the funding and personnel of AI capabilities research. Buying time for AI safety research is only one half of the equation, the other half is that large amounts of AI safety research must be done during that time.

These and any other AI-related policies should ideally be enacted and maintained by a new agency specialized in the sole task of AI regulation. This is necessary because AI is a fundamentally very different technology from other computer software due to its ability to automate human brain labor and the fact that it has its own goals. These differences pose significant new challenges that will require significant new regulatory solutions, and hence a new regulatory agency. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0291/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0291/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0291/attachment_1.pdf",
"OSTP-TECH-2023-0007-0292","OSTP","OSTP-TECH-2023-0007","ljs-zcfl-5z2q","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"SWF Response to Question #2: 

What level of autonomy in AI systems will maximize their potential and minimize our risk? This is a central question in “The Future of AI Governance” [attachment 1] as  eventually Autonomous Intelligent Systems (AIS) will become self-regulating.  Risk Management involves identifying and mitigation risk in development stages as well as active risk surveillance and reduction during operations.   Application of Socio-technical standards and collaborative prototyping are recommended during development.  Novel approaches to AI Governance during operations will be essential to address unanticipated AI activities. These points are discussed in the following paragraphs followed by commitments by the Spatial Web Foundation (SWF).

Balancing Risk Management and Innovation.  SWF supports fostering innovation while reducing or eliminating harmful activity in particular as identified in The Blueprint for an AI Bill of Rights.  Our objective should be to promote responsible AI innovation that respects rights and safety and ensures that AI provides benefits in line with our shared democratic values (U.S.-EU Joint Statement of the TTC).  This is consistent with the OECD recommendation development of governance frameworks to enable the development of agile innovation and future-proof AI systems and to develop outcome-focused regulatory approaches to enable innovation to thrive by harnessing the opportunities offered by digital technologies and big data. SWF advocates for development of a legal framework that enables AI innovation; and that advances regulation and policies to support AI innovation and responsible deployment.


Risk management during development.  The Blueprint for an AI Bill of Rights calls for Automated Systems to undergo pre-deployment testing, risk identification and mitigation.  The NIST AI Risk Management framework provides a methodology that is ready to be used by AI developers and AI standards bodies. These engineering practices can be tuned to the risk level of the AI application and are consistent with certification to the IEEE P2874 Spatial Web standards. Risk reduction by systems engineering is central to the IEEE Spatial Web standards.  Here are three examples: 1) SWF and VERSES have already demonstrated that autonomous compliance to law is possible by AIS’s without human intervention using IEEE P2874 HSML “law as code” design; 2) Innovative methods for Transparency in AI systems are provided by the approach defined in “Designing explainable AI with active inference” [attachment 2]; and, 3)  For testing regulatory options, SWF is developing the Prometheus sandbox as a multiple party collaboration - see The Future of AI Governance [attachment 1]. 

Risk management during operations.  As AI progresses, we must address the need to future-proof our ability to align, oversee, and override AI to prevent a potential loss of control and reduce harmful actions. Failure to establish proper governance measures now could lead to serious consequences in the near future.  While attention is often focused on individual AI systems, we are likely to find ourselves attempting to govern heterogeneous networks of AI that include different levels of intelligence, necessitating differing governance frameworks for Collective Intelligence [attachments 3 and 1].  SWF endorses the calls for public-private partnerships to address the inevitable societal challenges with AI technology and to develop concrete initiatives that bring together governments, respected companies, and energetic NGOs together to advance them. SWF endorses NAIAC’s call for an AI Research and Innovation Observatory to measure overall progress in the global AI ecosystem. 

The Spatial Web Foundation (SWF) is committing to the White House to help lead risk management and innovation activities through the IEEE P2874 Standards Working Group.  As defined in the Future of AI Governance, SWF supports: use of the NIST AI Risk Management Framework;  development of the Prometheus sandbox for collaborative development and testing of regulatory options for “code as law”; and to deploy operational AI Governance in the next generation internet by the Spatial Web Foundation, its members and constituent domains.

Attached Files
- Attachment1_Future of AI Governance (executive summary)
- Attachment2_Designing_explainable_AI_with_Active_Inference
- Attachment3_Shared_Intelligence_Friston_etal
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0292/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0292/attachment_3.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0292/attachment_1.pdf",
"OSTP-TECH-2023-0007-0293","OSTP","OSTP-TECH-2023-0007","ljs-zshd-qsg6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello and thank you for the opportunity to comment. I think AI technology needs a severe and regulatory check that involves consent from the ""data"" it scraps and/or a meaningful way to track and label where that information is sourced. The regulation, permissions, and consensual conversation about where the use of the data should come from should be controlled by each individual American an AI program chooses to train on. 

Companies across America are trying to bullhead this technology and training terms into their rules without properly preparing their consumer base. I am an artist who used the website haveibeentrained(.)com to discover artwork I made at the age of 11 was used to train AI Art systems without my consent. 

Furthermore, all regulation when it comes to journalism, news, and research involves a process that demands those sources are listed and referenced. In a world where we are constantly fighting misinformation, technology like ChatGPT and other OpenAI technology can't continue to take information from unknown sources then present them as fact without naming them. Whether it's artwork, writing, or voice work and music, a good portion of people this technology has been sourcing itself from have not been consulted, paid, or recognized.

It's not just about the loss of jobs - although this would be an immeasurably large loss - it's about the amount of people's hard work and passions being stripped for profit. It's about people's memories being warped and distorted by people who simply want to imitate them. It's also about families who's dead relatives and loved ones who's likeness is being used in a ""Frankenstein""-like and horrific manner.

On Tiktok people are using AI Deepfakes to retell stories of children's murders. (https://nypost.com/2023/05/31/real-child-murder-victims-recreated-by-ai-in-sick-tiktok-trend/)

And on more than one occasion deceased artists styles were imitated on AI, and example being Kim Jung Gi (https://restofworld.org/2022/ai-backlash-anime-artists/)

In a lot of ways, even the act of properly sourcing the origins of the hard work, blood sweat and tears analyzed by AI tech does not fully account for the more important needs of consent and permissions.

By allowing AI to go unchecked or even have ""light"" regulations in comparison to the rest of the world worsens our current misinformation war to unfathomable heights, it gives unearned power and credit to a crowd of people who don't want to learn anything, don't want to work hard to develop a skill, and don't care about the ethics surrounding using other hardworking Americans - dead or alive - for their own profit with no oversight.

Please consider the weight of the regulations needed on this technology. The regulations we enforce on human beings that involve copyright, consent, proper sourcing, and a presumption of good will should all also apply to this technology. AI can do amazing things and be productive - but only if the general public can trust that they aren't being forced to comply with the theft and plagiarism of their own hard work.",,,,,,,
"OSTP-TECH-2023-0007-0294","OSTP","OSTP-TECH-2023-0007","ljs-zghu-6wm6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"SWF Response to Question #3  

Clear oversight is a rightful expectation identified in The Blueprint for an AI Bill of Rights. Independent evaluation and reporting to confirm that systems are safe and effective should be based on socio-technical standards.  Oversight of AI Systems based on legal frameworks can adapt and apply previous successful voluntary oversight by private industry. Novel innovations in governance and oversight will become possible with shared autonomic systems as described in The Future of AI Governance [attached]. These points are discussed in the following paragraphs followed by commitments by the Spatial Web Foundation (SWF).

Oversight of AI Systems based on legal frameworks to exercise oversight and override measures is described in the Future of AI Governance [attached].  To be most effective, independent evaluation depends upon consensus criteria for the safe and effective use of AI and Autonomous Intelligent Systems (AIS).  As a neutral global technical organization and a champion of engineering excellence, the IEEE Standards Association is engaged in forward-looking measures to establish necessary standards and guidelines for evaluation and reporting for AI and AIS.  The IEEE P2874 standards development, led by the Spatial Web Foundation, provides socio-technical standards for the alignment, interoperability, and governance of AI and AIS in the next generation internet.

A properly-situated private standards organization, such as SWF, could help facilitate voluntary oversight by a variety of stakeholders (large and small) in the AI market sector. For example, rampant online fraud during the late 90s and early 2000s caused the major credit / debit card brands to develop a variety of different approaches to combating it. This patchwork approach did not fully address all the concerns, and government regulators (such as the FDIC) pushed the major players to work collaboratively to standardize these measures into a more cohesive, uniform approach, or else the government would be forced to do so for them.  This resulted in the ""Payment Card Industry Data Security Standard"" (PCI-DSS), first launched in 2004, and administered by the PCI Security Standards Council, a group that includes VISA, Mastercard, American Express, Discover and JCB, among others. The PCI-DSS was immensely successful, and as a result the PCI Standards Council now serves a quasi-regulatory policing function, overseeing (with input from the FDIC, Office of Comptroller of the Currency and various state agencies) the payment-related activities of banks, payment processors and businesses that take credit / debit cards as payment for goods and services.  Likewise, a voluntary standards organization for AI could (with input from federal and state regulators) function in the same quasi-regulatory role as the PCI Council does for payments, overseeing various aspects of AI development, implementation and commercialization, such as facilitating increased transparency / explainability, reducing biases, guarding against data breaches or privacy violations, and helping to further the cause of democracy worldwide. SWF, for its part, could serve in this capacity as AI impacts the next-generation Internet (a/k/a the ""Spatial Web""), encompassing things like self-driving cars and smart cities. Participating stakeholders could include companies and trade associations from private industry, along with representatives of / state / local governments, NGOs, and even individual citizens (where appropriate). 

The Spatial Web Foundation (SWF) is committing to the White House to help develop socio-technical standards through the IEEE P2874 Standards Working Group.  SWF commits to supporting development of voluntary oversight of AI systems deployed in the Spatial Web.  SWF commits to continued research in governance methods based on advances in Autonomous Intelligent Systems (AIS) and experimentation like the Prometheus Project.


Attached Files
- Attachment1_Future of AI Governance (executive summary)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0294/attachment_1.pdf",
"OSTP-TECH-2023-0007-0295","OSTP","OSTP-TECH-2023-0007","ljs-zhem-vzvd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached comments from the Administrative Conference of the United States' Office of the Chair.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0295/attachment_1.pdf",
"OSTP-TECH-2023-0007-0296","OSTP","OSTP-TECH-2023-0007","ljs-zjbr-gp8m","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"SWF response to question #23

Innovation depends on companies of all sizes competing in the marketplace of advanced AI systems.  Open standards for the marketplace must reflect the needs of small, medium and large companies. The US government should set an objective to empower small- and medium-sized organizations for trustworthy AI development and use.  Innovation in AI governance including a cross section of perspectives is provided in The Future of AI Governance [attachment 1]. These points are discussed in the following paragraphs followed by commitments by the Spatial Web Foundation (SWF).

Open socio-technical standards can bridge the gap between organizations of all sizes, ensuring that emerging technologies are not only technically sound but also socially beneficial, safe, compliant with laws and regulations, aligned with societal norms and values, and permit robust competition in an open marketplace.  Socio-technical standards are unique because they aim to integrate and balance the technical, social, legal, and economic use of technology.  The IEEE P2874 Spatial Web standards process is developing open standards for the governance of an ecosystem composed of AI agents.  IEEE P2874 is identified by the IEEE Standards Association as a “Public Imperative” and open to all. 

As identified in the recent NAIAC Report May 2023,  it is imperative to empower small- and medium-sized organizations for trustworthy AI development and use.  Open standards are critical to enable industry organizations of all sizes to adopt trustworthy AI.  Trustworthy AI is enabled by open consensus socio-technical standards that define uniform specifications and criteria for the safe and ethical operations of AI.  Innovation in AI transparency may be most forthcoming from small and medium companies.  For example, VERSES, a cognitive computing company specializing in the next generation of artificial intelligence, recently published a landmark research paper that articulates unique methods for developing human-interpretable, explainable artificial intelligence (XAI) systems that can be applied across the AI marketplace. [attachment 2].

New methods for AI Governance and oversight will come from organizations of all sizes. While attention is currently focused on controlling powerful generative AI language models, the governance challenge extends far beyond individual AI systems. It encompasses the compounding complexity of networks, where interconnected AI systems interact, learn, adapt, and include and interact with humans further highlighting the need for advanced robust governance mechanisms.  The Future of AI Governance [attachment 1] seeks to answer this question by highlighting the work being done to develop a new generation of socio-technical standards that could enable the global governance of Autonomous Intelligent Systems. These standards, including IEEE P2874, could play a crucial role in steering us toward a safe, interoperable, equitable, and autonomous future. 

The Future of AI Governance [attachment 1] proposes The Prometheus Project, a  public-private initiative aimed at testing and exploring the potential of emerging technologies in a controlled environment.  According to the White House AI R&D Strategic Plan 2023 update, “Appropriate programs should be established for academic and industrial researchers to conduct research within secured and curated testbed environments established by federal agencies … Industry and academia are the primary sources for emerging AI systems.”   By creating a regulatory sandbox the Prometheus project can provide a space for regulators, manufacturers, and innovators and the public to work together in a collaborative and experimental way to test out the viability of the various stages of deployment before it is released upon the world.   The sandbox provides an opportunity for incumbents and challengers alike to experiment with new ideas outside of existing regulatory frameworks, which can lower the barriers to entry and reduce the cost and risk of innovation. This process removes ambiguity and streamlines the path to adoption and enables regulators to be proactive in their approach to regulating emerging technologies.

The Spatial Web Foundation (SWF) is committing to the White House to help develop socio-technical standards by leading the IEEE P2874 Standards Working Group.  SWF commits to continued innovation in AI Governance including the perspectives of organizations of all sizes.   SWF commits to continued development of the Prometheus Project as a public-private regulatory sandbox open to organizations of all sizes.


Attached Files
- Attachment1_Future of AI Governance (executive summary)
- Attachment2_Designing_explainable_AI_with_Active_Inference
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0296/attachment_1.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0296/attachment_2.pdf",
"OSTP-TECH-2023-0007-0297","OSTP","OSTP-TECH-2023-0007","ljs-zmff-zez8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Attached please find the comments of the Computer & Communications Industry Association.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0297/attachment_1.pdf",
"OSTP-TECH-2023-0007-0298","OSTP","OSTP-TECH-2023-0007","ljs-zpw3-suwk","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0298/attachment_1.pdf",
"OSTP-TECH-2023-0007-0299","OSTP","OSTP-TECH-2023-0007","ljs-zq78-sl8a","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Pleased find Workday's comments attached. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0299/attachment_1.pdf",
"OSTP-TECH-2023-0007-0300","OSTP","OSTP-TECH-2023-0007","ljt-04ea-p5oa","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We need strict regulations on disclosure of AI use. It enables easy impersonation, which is dangerous for many reasons on many scales- politicians and celebrities may be impersonated, as well as the work of specific artists, actors, and other workers, therefore eliminating jobs.",,,,,,,
"OSTP-TECH-2023-0007-0301","OSTP","OSTP-TECH-2023-0007","ljs-zrp1-dpik","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Thank you for reaching out regarding the National Priorities for this very important subject.

The comment is attached, dealing with point 13.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0301/attachment_2.pdf,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0301/attachment_1.pdf",
"OSTP-TECH-2023-0007-0302","OSTP","OSTP-TECH-2023-0007","ljs-zt13-750c","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0302/attachment_1.pdf",
"OSTP-TECH-2023-0007-0303","OSTP","OSTP-TECH-2023-0007","ljt-06rq-ro3d","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Artificial intelligence must be regulated and training data sets must be held accountable for the industrial scale theft they have committed. The LAION dataset which powers most AI generators has scraped the entirety internet of art, music, writing, personal information, medical photos, and countless other things without consent or compensation. Working artists are being put out of work by platforms like MidJourney and Stable Diffusion, Amazon books is flooded with AI-generated books scraped off living authors' work, generative sound AI can create nearly-perfect voice clones of any public figure saying anything. The potential harm to the economy and misinformation is unfathomable and these systems must not be allowed to go unchecked. Innovation is not an excuse for global copyright infringement, deliberate destruction of jobs and creative's rights over how their work can be used, and the enormous potential to mislead and manipulate public narrative on important issues.

If these AI generators are to continue, they should be required to abolish all their training data and begin from the ground up with OPT-IN ONLY machine learning. No art, writing, sound, or information should be allowed to train an AI without the express consent and compensation of the original copyright holder, and the companies developing these tools must be required to keep strictly accurate documentation of ALL data that has been fed into their training data to ensure they are not violating the works and rights of others. Proof of the harm these current models cause is readily available online, and the perpetrators must be held accountable. ""It's too hard to get the permission of millions of people for training data"" is not an excuse to violate copyright law and build systems that proactively destroy the industries they feed upon.",,,,,,,
"OSTP-TECH-2023-0007-0304","OSTP","OSTP-TECH-2023-0007","ljt-07ga-s4cp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello! I’m an independent artist and I run a single-owner LLC that organizes anthology projects with dozens of other artists, like books and card decks. I love my industry but it’s an extremely risky path that requires a lot of hard work over many, many years to succeed in. Rampant and unregulated data scraping that current datasets are reliant upon is an extreme threat to the entire creative industry, from film and tv to writing, music and of course the visual arts and design. These industries thrive on diligence and hard work- most people working in creative fields live under the poverty line for a huge portion of their lives. Unregulated AI has stolen the fruit of our labor and is repackaging it with a subscription fee for customers of machine-learning services like Stability AI. AI systems must be examined with the highest degree of care so that datasets include only legal and consent-based material. Please take this issue seriously. A lot of people’s livelihoods, ambitions and labor are at risk along with the cultural and educational legacy of the next decade.",,,,,,,
"OSTP-TECH-2023-0007-0305","OSTP","OSTP-TECH-2023-0007","ljs-zuxp-ml98","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0305/attachment_1.pdf",
"OSTP-TECH-2023-0007-0306","OSTP","OSTP-TECH-2023-0007","ljs-zvef-426y","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0306/attachment_1.pdf",
"OSTP-TECH-2023-0007-0307","OSTP","OSTP-TECH-2023-0007","ljs-zx2m-ppax","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Re: Request for Information: National Priorities for Artificial Intelligence (OSTP-TECH-2023-0007)

Dear Mr. Marda,

Premier Inc. appreciates the opportunity to submit comments to the White House Office of Science and Technology Policy (OSTP) regarding the request for information (RFI) to develop National Priorities for Artificial Intelligence (AI). As described, this RFI will help inform the Biden-Harris Administration as it develops a National AI Strategy, charting a path for the United States to harness the benefits and mitigate the risks of emerging AI technologies. 
Premier appreciates OSTP’s commitment to leveraging AI to advance equity, promote economic growth and innovate in public service, while remaining mindful of the potential threats that AI could pose to individual safety and national security if misused. Premier applauds the actions that the federal government has already taken to responsibly advance the development and use of AI. Premier specifically requests that OSTP consider the following in developing a National AI Strategy:
•	Promote transparency by holding AI technology to publicly-reported metrics based on outcomes, not on inputs;
•	Mitigate risks of bias and discrimination by requiring publicly reported disparity testing results, both before and after technology deployment;
•	Incorporate guidelines for AI risk assessments that identify potential risks, potential mitigation strategies, detailed explanations of recommended uses for the tool and risks that could arise should the tool be used inappropriately;
•	Establish data standards that include an objective assessment of potential sources of bias or inaccuracy introduced through poor dataset construction, cleaning, or use;
•	Establish guidelines for proper data collection, storage and use that sufficiently protect patient rights and safety;
•	Prevent inappropriate or unintended use of AI technologies by requiring developers to clearly describe recommended and prohibited use cases;
•	Mitigate risk of automation bias through comprehensive risk assessment and workforce training efforts;
•	Avoid across-the-board freezes on AI technology development, which would put American companies at a competitive disadvantage globally;
•	Require agencies with sector-specific jurisdiction over AI policy to hire technologists with AI-specific expertise to incorporate into current industry and legal regulatory frameworks; and
•	Engage in public-private partnerships with AI industry experts to ensure any regulatory framework reflects the cutting edge of AI technology.

Our detailed recommendations are included in the attached file. Premier appreciates the opportunity to respond to OSTP’s RFI on National Priorities for AI. If you have any questions regarding our comments, or if Premier can serve as a resource on these issues to the Administration in its policy development, please contact our subject matter experts using the contact information in the attached file.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0307/attachment_1.pdf",
"OSTP-TECH-2023-0007-0308","OSTP","OSTP-TECH-2023-0007","ljs-zxu5-8jjp","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0308/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0308/attachment_1.pdf",
"OSTP-TECH-2023-0007-0309","OSTP","OSTP-TECH-2023-0007","ljt-03ns-2gme","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0309/attachment_1.pdf",
"OSTP-TECH-2023-0007-0310","OSTP","OSTP-TECH-2023-0007","ljt-05is-6ucx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0310/attachment_1.pdf",
"OSTP-TECH-2023-0007-0311","OSTP","OSTP-TECH-2023-0007","ljt-06md-eyco","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0311/attachment_1.pdf",
"OSTP-TECH-2023-0007-0312","OSTP","OSTP-TECH-2023-0007","ljt-08m0-59bx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached for Knowledge Ecology International's Comments in response to the Office of Science and Technology Policy (OSTP) Request for Information (RFI), regarding National Priorities for Artificial Intelligence, as noticed on May 23, 2023 in the Federal Register, 88 FR 34194.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0312/attachment_1.pdf",
"OSTP-TECH-2023-0007-0313","OSTP","OSTP-TECH-2023-0007","ljt-09rh-y5ev","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0313/attachment_1.pdf",
"OSTP-TECH-2023-0007-0314","OSTP","OSTP-TECH-2023-0007","ljt-0ekp-bbld","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hewlett Packard Enterprise (HPE) appreciates the opportunity to respond to the Request for Information (RFI) to assist Office of Science and Technology Policy (OSTP) in developing a National Artificial Intelligence (AI) Strategy RFI. HPE commends the Administration in its current approach to seek broad multistakeholder input as it seeks to chart a path for the United States to harness the benefits and mitigate the risks of AI. Our response to the RFI is attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0314/attachment_1.pdf",
"OSTP-TECH-2023-0007-0315","OSTP","OSTP-TECH-2023-0007","ljt-0ft9-czjx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0315/attachment_1.pdf",
"OSTP-TECH-2023-0007-0316","OSTP","OSTP-TECH-2023-0007","ljt-0i06-bcjb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0316/attachment_1.pdf",
"OSTP-TECH-2023-0007-0317","OSTP","OSTP-TECH-2023-0007","ljt-0n44-uems","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"NCTA - The Internet & Television Association submits the attached comments on the OSTP RFI National Priorities for AI. Thank you. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0317/attachment_1.pdf",
"OSTP-TECH-2023-0007-0318","OSTP","OSTP-TECH-2023-0007","ljt-0n5t-5ftv","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0318/attachment_1.pdf",
"OSTP-TECH-2023-0007-0319","OSTP","OSTP-TECH-2023-0007","ljt-0nix-kjde","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0319/attachment_1.pdf",
"OSTP-TECH-2023-0007-0320","OSTP","OSTP-TECH-2023-0007","ljt-0snc-oumb","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached for Google's comments ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0320/attachment_1.pdf",
"OSTP-TECH-2023-0007-0321","OSTP","OSTP-TECH-2023-0007","ljt-0tcn-if21","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached comments submitted by Accenture Security. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0321/attachment_1.pdf",
"OSTP-TECH-2023-0007-0322","OSTP","OSTP-TECH-2023-0007","ljt-0tkh-akj6","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached PDF CAP_RESPONSE_OSTP-TECH-2023-0007.pdf for CAP's full comment. 

The Center for American Progress (CAP) applauds the Office of Science and Technology Policy (OSTP) for undertaking this Request for Information to determine National Priorities for Artificial Intelligence (AI) to develop the National AI Strategy (Docket Number: OSTP-TECH-2023-0007). 

CAP is an independent, nonpartisan policy institute that is dedicated to improving the lives of all Americans through bold, progressive ideas, as well as strong leadership and concerted action. 

The Biden-Harris administration cannot afford to wait the many months it will take to digest this input to create a National AI Strategy. Generative AI is already commercially available to more than 100 million users, and these tools are now available for use by U.S. government agencies through leading government-used cloud computing services. Immediate action is required now to start an all-of-government effort to address the challenges of AI and set up the entities needed to execute the national AI strategy once it is developed.

The five categories outlined in the RFI all represent key priorities for a national AI strategy, and recommendations are detailed for each below along with overarching actions and legislation for AI. An all-of-government approach requires leveraging all the tools of government. CAP outlines recommendations and key thoughts that include a combination of potential executive actions, needed legislation, private/public sector goals, and more below.

Sincerely, 

Megan Shahi 
Director, Technology Policy
mshahi@americanprogress.org 

Adam Conner 
Vice President, Technology Policy
aconner@americanprogress.org 

The Center for American Progress 
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0322/attachment_1.pdf",
"OSTP-TECH-2023-0007-0323","OSTP","OSTP-TECH-2023-0007","ljt-19rk-vex4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dear Office of Science and Technology Policy,

I am writing to share my thoughts with regard to National Priorities for Artificial Intelligence (OSTP-TECH-2023-0007-0001). As an individual deeply engaged both professionally and personally with the field of machine learning and artificial intelligence, I can offer a unique perspective shaped by my experiences. Throughout my academic career, I utilized machine learning models to conduct research on climate change, harnessing the capabilities of these models to understand, describe, and propose solutions for one of humanity's most pressing challenges. Furthermore, as a lifelong experimental artist, I have incorporated generative AI technologies into my creative process, witnessing firsthand how AI can be a tool for extending human creativity rather than replacing it.

With this background, I recognize the potential of AI to transform various facets of our lives, from addressing global challenges like climate change to revolutionizing artistic expression. However, I am equally cognizant of the risks inherent in its misuse. With these considerations in mind, I would like to address the following points in response to the proposed regulation:

Innovation in AI: Artificial Intelligence holds enormous potential to address pressing issues in climate change, health, medicine, accessibility, creativity, and the future of work. It can empower people to augment their capabilities, fostering innovation and progress. I urge that any regulation should foster such innovation rather than stifling it. This can be achieved through appropriate oversight, encouraging research and development, and the promotion of responsible AI use.

Digital Literacy: As AI technologies become more prevalent, digital literacy becomes even more crucial. It is critical that the public understand these technologies to be aware of their capabilities and limitations. Any regulation should, therefore, encourage efforts to improve digital literacy across society.

Open Access to AI: While protecting intellectual property rights, regulations should ensure that there is open access to advanced AI models. This will promote transparency, inclusivity, and a level playing field for all.

Manipulation and Disinformation: AI can unfortunately be used for disinformation campaigns and manipulation. Regulations need to establish guidelines to prevent misuse, including the accurate detection and flagging of AI-generated content.

Data Privacy: As AI systems often rely on massive amounts of data, data privacy becomes a paramount concern. Regulations should ensure robust data protection measures, promoting transparency in data collection, storage, and use.

Algorithmic Bias: AI systems can inadvertently perpetuate bias if not properly addressed. Any regulation should emphasize the need to identify and minimize algorithmic bias, promoting fairness and equality in AI applications.

Labor Protections and Reskilling Programs: AI has the potential to displace jobs, necessitating the need for labor protections and reskilling programs. Regulations should address these issues, ensuring that the workforce is prepared for the future.

In light of these considerations, I urge that these specific points be included in the final regulation. By doing so, we can harness the potential of AI while mitigating its risks, fostering a society that is both innovative and inclusive.

Thank you for your consideration. I believe that thoughtful regulation can ensure the beneficial development and use of artificial intelligence.

Sincerely,
Robert Paul",,,,,,,
"OSTP-TECH-2023-0007-0324","OSTP","OSTP-TECH-2023-0007","ljt-0xld-djs7","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Thank you for the opportunity to submit our response. Please see attached document.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0324/attachment_1.pdf",
"OSTP-TECH-2023-0007-0325","OSTP","OSTP-TECH-2023-0007","ljt-15by-h7cu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0325/attachment_1.pdf",
"OSTP-TECH-2023-0007-0326","OSTP","OSTP-TECH-2023-0007","ljt-161o-f1ia","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0326/attachment_1.pdf",
"OSTP-TECH-2023-0007-0327","OSTP","OSTP-TECH-2023-0007","ljt-1j13-dtam","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1. AI should not be created at all without going through a process / board to ensure every step ensures Human Rights & Privacy are protected & Law-abiding first. No training should be done, as consent should be required, but AI companies have ignored laws & infringed on rights without obtaining any authorization.  
All current AI that involve training data on public data & private data should be purged as they are infringing on IP Laws & HIPAA, & rely on the people to 'opt-out' when people are not being aware their data is being exploited & profited off of.
The FTC should disgorge AI corporations instead of warning as many of these companies such as Google, Microsoft, Amazon, IBM, etc are laying off human workers to displace them with AI systems which do not compensate humanity as AI systems have stolen works & data. The FTC should protect consumers from misinformation & banning AI as it promotes scams & fraud.
The government should stop employing the usage of AI, creating AI campaigns & scanning faces for databases feeds private data into a system that is insecure as AI systems get hacked & leaked & enables viruses & misinformation.
Health companies should stop using AI to conduct human experiments.
Businesses need to uncompetitive & unfair business practices by stop infringing on copyright by using AI & using it to displace workser..



2. AI is not human & does not deserve rights.


3. AI does not mitigate risk; it creates risks & problems, as it hurts individuals.


7. AI can leak information, can be hacked into, can make viruses to disrupt systems, & create misinformation which can frame innocent individuals. There is no way to mitigate risks of AI without getting rid of it.

According to
https://www.washingtonpost.com/technology/2023/06/05/chatgpt-hidden-cost-gpu-compute/ AI also loses money every time using it. USA has a huge debt cannot be wasting money on a system that fuels scams & misinformation 


8. According to research, AI requires huge databases which requires wasting lot of water & electricy.
In https://interestingengineering.com/innovation/training-chatgpt-consumes-water , ChatGPT uses water to fill a nuclear power plant's cooling tower, its training alone uses 185,000 gallons of water  (meaning every interaction made with GPT can waste a bottle of water) 
It takes about 360,000 gallons of water daily to cool a middle-sized data centre, & humans drink about .5 gallon water a day which means we could have saved 720,000 people a day if these data centres did not waste water to fuel AI systems.


""Based on estimates of ChatGPT’s usage & computing needs, data scientist Kasper Groes Albin Ludvigsen estimated that it may have used as much electricity in January as 175,000 people — the equivalent of a midsize city.""  https://t.co/lo19HU8wj5


In this article https://www.pcmag.com/news/ai-could-save-the-world-if-it-doesnt-ruin-the-environment-first  ""All this computation requires a lot of electricity. According to a study(Opens in a new window) by researchers at the University of Massachusetts, Amherst, the electricity consumed during the training of a transformer, a type of deep-learning algorithm, can emit more than 626,000 pounds of carbon dioxide—nearly five times the emissions of an average American car. Another study(Opens in a new window) found that AlphaZero, Google’s Go- & chess-playing AI system, generated 192,000 pounds of CO2 during training.""

Using AI, USA will not be able to cut greenhouse gas at all or meet their commitment. Many states are in drought & in need of water & if we are in the future plan to use electric vehicles, so we should be prioritize not wasting energy resources on wasteful AI, but make sure water & electricity is available to every person.


9. There are no benefits to enhance equity, rather we are seeing corporations use AI to replace real humans (such as Levi's plan to use AI for their ad) in order to promote fake diversity. AI can create fake individuals that have biases & thus cannot be said to represent real humans. Using AI does not enhance opportunities rather, cuts out human workers & exploits their data & images


10. There are many issues with AIs being used to replace doctors & therapists. People with mental illnesses, disabilities, & minors are susceptible to using these AIs thinking they are credible humans with certifications, but are scammed with false information & regurgitation of any public internet comment as it is not filtered nor vetted by any medical institution. If a real person pretended to be a doctor they would be considered a fraud. But companies are doing the same with AI, & treated above the law which is illegal & unfair.",,,,,,,
"OSTP-TECH-2023-0007-0328","OSTP","OSTP-TECH-2023-0007","ljt-18nt-my69","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"On behalf of the Partnership for Transportation Innovation and Opportunity, please find the attached comments. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0328/attachment_1.pdf",
"OSTP-TECH-2023-0007-0329","OSTP","OSTP-TECH-2023-0007","ljt-1aaw-lsbx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Response to 88 FR 34194 is submitted in the file attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0329/attachment_1.pdf",
"OSTP-TECH-2023-0007-0330","OSTP","OSTP-TECH-2023-0007","ljt-1b05-b7xi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Thank you for the opportunity to provide comments on the National Priorities for Artificial Intelligence. Please find attached feedback from Palo Alto Networks, an AI-powered cybersecurity company. Our company is eager to be an active participant in the development of a National AI Strategy. We would be happy to discuss our submission, the defensive cyber use cases, and nuances of AI in greater detail. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0330/attachment_1.pdf",
"OSTP-TECH-2023-0007-0331","OSTP","OSTP-TECH-2023-0007","ljt-1o7j-hegu","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"#14 Strengthening civic engagement and improving interactions between people and their government could be achieved by not making individuals’ harms, safety, and rights to depend on policies and contracts of private companies (AI).

This RFI was poorly made known to the public. This results in a lopsided domination of input by business interest and government stakeholders.",,,,,,,
"OSTP-TECH-2023-0007-0332","OSTP","OSTP-TECH-2023-0007","ljt-1cco-y92m","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0332/attachment_1.pdf",
"OSTP-TECH-2023-0007-0333","OSTP","OSTP-TECH-2023-0007","ljt-1dmw-d1vq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached response from AHIP. Thank you for the opportunity to provide input. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0333/attachment_1.pdf",
"OSTP-TECH-2023-0007-0334","OSTP","OSTP-TECH-2023-0007","ljt-1i3m-78ao","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"TITLE: A Proposal to Provide a State-of-The-Art Large Language Model for the US Science and Engineering Research Community

SCOPE: This proposal concerns AI research infrastructure and addresses multiple topics raised in the RFI, including societal and economic impact and national defense.

EXECUTIVE SUMMARY:  To maintain US Artificial Intelligence (AI) research excellence and leadership with significant societal benefits and with human-aligned AI safety objectives, we propose that the U.S. government provide a state-of-the-art Large Language Model (LLM) for full use by the U.S. science and engineering research community. Development of such a model would require a direct investment at the level of around $20 billion. The LLM would significantly boost the US unique strengths in all areas of science, including biology and medicine, and engineering, and maintain the US position as the leading nation in science and engineering. The impact of such an investment would be comparable or even exceed the impact of the introduction of digital computing in science and engineering over the past several decades.

Prof. Carla Gomes and Prof. Bart Selman, Cornell University

Justification in separate pdf.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0334/attachment_1.pdf",
"OSTP-TECH-2023-0007-0335","OSTP","OSTP-TECH-2023-0007","ljt-1jli-w7ws","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Center for Democracy & Technology respectfully submits the attached comments in response to the Office of Science and Technology Policy's request for information on national priorities for artificial intelligence.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0335/attachment_1.pdf",
"OSTP-TECH-2023-0007-0336","OSTP","OSTP-TECH-2023-0007","ljt-1jr7-37ea","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0336/attachment_1.pdf",
"OSTP-TECH-2023-0007-0337","OSTP","OSTP-TECH-2023-0007","ljt-1k2v-phwd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments of the Software & Information Industry Association relating to the development of a National AI Strategy.

Paul Lekas
SVP, Global Public Policy",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0337/attachment_1.pdf",
"OSTP-TECH-2023-0007-0338","OSTP","OSTP-TECH-2023-0007","ljt-1lv1-l38s","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0338/attachment_1.pdf",
"OSTP-TECH-2023-0007-0339","OSTP","OSTP-TECH-2023-0007","ljt-1m36-viek","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0339/attachment_1.pdf",
"OSTP-TECH-2023-0007-0340","OSTP","OSTP-TECH-2023-0007","ljt-1p9m-m7iw","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0340/attachment_1.pdf",
"OSTP-TECH-2023-0007-0341","OSTP","OSTP-TECH-2023-0007","ljt-1raa-52ij","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s), submitted by Greater Boston Legal Services (GBLS), Massachusetts Law Reform Institute, Philadelphia Legal Assistance, and New York Legal Assistance Group. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0341/attachment_1.pdf",
"OSTP-TECH-2023-0007-0342","OSTP","OSTP-TECH-2023-0007","ljt-1sw3-ir8p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0342/attachment_1.pdf",
"OSTP-TECH-2023-0007-0343","OSTP","OSTP-TECH-2023-0007","ljt-1t6o-jc8x","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Our comment document is too large for 5000 characters, so we are attaching it to this as a PDF document.
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0343/attachment_1.pdf",
"OSTP-TECH-2023-0007-0344","OSTP","OSTP-TECH-2023-0007","ljt-1uxa-b19x","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Intel Corporation submission in response to the OSTP RFI on National Priorities for Artificial Intelligence",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0344/attachment_1.pdf",
"OSTP-TECH-2023-0007-0345","OSTP","OSTP-TECH-2023-0007","ljt-1v0r-a8ay","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached comments. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0345/attachment_1.pdf",
"OSTP-TECH-2023-0007-0346","OSTP","OSTP-TECH-2023-0007","ljt-28ft-5i6a","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"My name is Laura Rocha, I’m a Latina, co-founder of an early-stage data analytics startup based in New York, I hold a Master's in Public Administration and for the last four years I have been working on the intersection of AI and communities, focus on the latino and multicultural markets. I present the following considerations for question 10, with the aim to contribute to the analysis of how AI systems impact underserved communities. 
There are different impacts associated with the development of artificial intelligence algorithms throughout the entire process. It is important to consider the positive and negative implication throughout the process in the development, implementation, go-to-market, inspection, and vigilance. 

I focus my comments on the development and implementation phases. For one specific underserved community: Small and mid-sized business owners and minority business owners. 

AI and data industry is growing quickly, and it is a high revenue generating industry, it is determinant to consider how to incentivize and support SMB business owners to get into this industry. It would not only better distribute wealth across local communities but also incentive AI development to solve needs for underrepresented communities, as it already proved that SMB owners are more likely to create products and services to serve local needs. 

The development of artificial intelligence algorithms and AI-based solutions is very capital-intensive. Accessing big amounts of data, computational power, high-tech skilled workforce requires a lot of upfront cash flows. It’s well known that this industry is dominated by a few big players and coming startups that are VC funded by the same big tech players or top financial institutions. So, it is very important to consider regulations that incentive and also minimize the barriers for SMBs and minorities to enter the AI and data industry.

The implementation of AI technologies highly benefits SMBs, AI power technologies can reduce costs and improve efficiency in the supply chain, marketing, and operations. However, for SMB owners it’s difficult and highly capital intense to transition to cloud servers, implement CRMs and overall digitalize their business. 

Considerations from Economic incentives: provide capital and benefits for SMBs to come and grow in this industry, including underrepresented-owned startups. It’s also valuable to provide more education for SMBs on how and what opportunities exist to enter the AI and data industry and also opportunities for tax benefits for SMBs and underrepresented to take risks to enter this industry. In addition, it is important to provide technical support and capital, and education to help SMBs digitalize their business processes and to implement AI-based solutions. 

Regulations: It's undeniable the need for regulation for the AI and the data industry to protect human rights, fairness, and healthy market competition. During the development and implementation phase of AI technology, data collection, and data processing is a very important step in which regulation will impact SMBs and underrepresented communities. I encourage the administration to consider how excessive procedures in data collection, and process can increase administrative costs or create access barriers for small businesses. These companies don’t have access to legal advisors or highly technical teams that can lobby. ",,,,,,,
"OSTP-TECH-2023-0007-0347","OSTP","OSTP-TECH-2023-0007","ljt-28n8-8tq7","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is absolutely critical to recognize that 'AI' is currently built on the uncompensated use of copyrighted works (1, 2), underpaid human laborers (3), and the indiscriminate collection of images from the web, including illegal/nonconsenting images (4,5). Much of the work before governments is to ensure their human citizens are protected through enforcement of existing rights (copyright) and encouraging the adoption of rules which value human effort, activity, and output over and above the need of AI systems to consume those things.  In particular, I recommend working with the Creative Rights Coalition and scholars like Dr. Timnit Gebru, Dr. Alex Hanna, Dr. Joy Buolamwini, Dr Safiya Noble, and Dr. Emily M. Bender (6). 

1)https://pile.eleuther.ai/paper.pdf
2)https://www.polygon.com/23558946/ai-art-lawsuit-stability-stable-diffusion-deviantart-midjourney
3) https://time.com/6247678/openai-chatgpt-kenya-workers/
4) https://futurism.com/face-images-train-ai-consent
5) https://finance.yahoo.com/news/illegal-trade-ai-child-sex-210027001.html
6) https://dl.acm.org/doi/pdf/10.1145/3442188.3445922",,,,,,,
"OSTP-TECH-2023-0007-0348","OSTP","OSTP-TECH-2023-0007","ljt-1vu8-wdyy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0348/attachment_1.pdf",
"OSTP-TECH-2023-0007-0349","OSTP","OSTP-TECH-2023-0007","ljt-28sm-7u6n","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AI should not be allowed to be used in any sector to ensure the protection of human rights, copyrights, privacy, and data especially as AI is a security risk and wastes a huge amount of energy resources (water and electricity which both are necessity to survive in our modern society) & any current system should be 

11. We need to be assured it is not being used at all. AIs cannot be held accountable for decisions & are known for making up information in a black box as we cannot track how they arrive to their decisions nor do we know what information they are using to get their conclusions, & thus we should not be using them for employment, facial recognition, health or in general any sector


12. We need laws to ban AI systems outright especially unlawful ones that promote unfair competition & infringe on human rights. Companies should not be able to profit off stolen data & property & replace human workers, but are doing so with these AI systems.

13. Companies must disclose every piece of training data & their systems so people can ensure their data & copyrights & patents & human rights are not infringed on. Tech companies & developers should be held accountable for their software & harms it have created by creating misinformation & breaking laws. FTC needs to consumers & stop protecting corporations who keep breaking laws. Government should stay truthful & not lie to their voters with fake ai campaigns, as AI should be banned in all media to prevent misinformation & scams.
FBI needs to punish AI companies for violating copyright and theft of IP.


14-15. It cannot. Voters want to be heard by our politicians who represent us. We do not want to talk to a bot who can’t represent me especially one that is exploiting, infringing & misrepresents information. 
Using AI in politics is scam & fraud & misrepresentation of real world issue, people & events. With AI, we will doubt every media & even our government, & the only way to make sure there will never be inaccuracy is to not allow AI in any sector.


16. We should be aware that there are companies exploiting our data & have a right to never allow it to happen to protect ourselves.

17. AI enables cheating, scam, fraud, plagiarism, copyright infringement & thus is harmful for education & economy. 

18-20. It is not improving productivity & is rather displacing & replacing workers as many people are losing their jobs due to AI. Rather corporations use AI as a tool for unfair competition & human exploitation & control ignoring human worker rights & compensation. The economic market will fall apart as there is no safety net for humans as USA has no UBI or universal healthcare when companies planning to shift to AI only usage, rather the market will crash as AI proliferates. 
There have been no new job opportunities as AI companies have fired Americans to hire offshore workers for poor wages to continue feeding their AI with stolen public and private data. Rather there have been more fake job opportunies which scam Americans into sharing their data only to be used against them as blackmail. 

21. Using AI is internationally infringing on international agreed copyright, USA would be harming every human by exploiting people with their data ( https://justoutsourcing.blogspot.com/2022/03/gpts-plagiarism-links.html & https://www.tomsguide.com/news/google-bard-just-admitted-it-plagiarizes-content-and-thats-a-problem) . EU is set to ban various unethical AI & thus we will be at risk at losing sales in the overseas market if we are set on allowing AI in our industries.

And AI companies such as OpenAI, Google, Microsoft, Amazon additionally serves a global audience. That means AI companies are selling this country's intellectual property and citizen PII to foreigners and foreign governments.

22. It created the AI scammer job. People are using AI to lie creating misinformation to harm others by creating revenge porn and blackmail but also about their software & job capabilities & creditations.

23. USA needs to  the current AI systems & make sure they are not exploiting humans & their data & IP first.

24-28. AI can't be held accountable therefore cannot be leveraged; it is a full on risk to security

29. What is National AI Strategy's plan to protect citizens from AI especially agencies & corporations who use them to exploit humans & break laws? 
AI strategy should be based on how to protect our citizens from AI & create guardrails to people using AI & abusing us everyday by not follow laws & regulations and training its system on everything.

What is the strategy to compensate the billions of humans whose rights have been stripped by these AI companies? As this is a massive theft on a worldwide scale, multi-trillions should be compensated by these AI companies for stealing people's work and livelihood and exploiting children and violating HIPAA.

Why are AI companies such as Google, Microsoft, Amazon, OpenAI allowed to break laws and not be held accountable?

",,,,,,,
"OSTP-TECH-2023-0007-0350","OSTP","OSTP-TECH-2023-0007","ljt-28un-upzr","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"1. Generative AI - content generated for the purpose of advertising/marketing - should be regulated through an FTC requirement requiring watermarks (for text). Industry focus has been largely on images, however text has significantly larger market penetration and utility, especially in the form of consumer misleading advertising.
2. Generative AI - in the form of digital avatars created by companies like character.ai and my.pipio - will eliminate the line between human and non-human spoken content (primarily video) - which has vast implications for electoral, product and other misinformation. Government regulations should require that social media and video platform companies separate this content and restrict its use for specific categories (news, health, finance, elections) which have the potential for causing great harm before they can be addressed.
3. Large Language Models (LLMs) are rapidly passing beyond the range of industry regulation, and (as with Petals/Bloom) will quickly become distributed (similar to bittorrent) and open sourced (meaning anyone with a desktop and hard drive space can operate them). Requiring that LLMs disclose their training data will be a useful function for regulators to focus on.
4. Risk management structures for the antivirus and cryptocurrency industries have analogues with AI, and could serve as a template.
5. AI / LLMs used for software development risks repeating patterns that are found in the future to be vulnerable to attack. AI's best use case is in process optimization - finding anomalies in the data faster than a human, identifying trends with such anomalies, and implementing rapid detours around them.",,,,,,,
"OSTP-TECH-2023-0007-0351","OSTP","OSTP-TECH-2023-0007","ljt-1wik-xjgq","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached Credo AI's comments in response to the OSTP RFC, ""National Priorities for Artificial Intelligence"" written by staff of Credo AI and signed by Credo AI Founder and CEO, Navrina Singh.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0351/attachment_1.pdf",
"OSTP-TECH-2023-0007-0352","OSTP","OSTP-TECH-2023-0007","ljt-1xit-97bx","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0352/attachment_1.pdf",
"OSTP-TECH-2023-0007-0353","OSTP","OSTP-TECH-2023-0007","ljt-1z7l-zlal","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comment attached submitted on behalf of Booz Allen Hamilton.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0353/attachment_1.pdf",
"OSTP-TECH-2023-0007-0354","OSTP","OSTP-TECH-2023-0007","ljt-2113-nn1o","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0354/attachment_1.pdf",
"OSTP-TECH-2023-0007-0355","OSTP","OSTP-TECH-2023-0007","ljt-21ms-igpe","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0355/attachment_1.pdf",
"OSTP-TECH-2023-0007-0356","OSTP","OSTP-TECH-2023-0007","ljt-21tn-vhoz","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see my attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0356/attachment_1.pdf",
"OSTP-TECH-2023-0007-0357","OSTP","OSTP-TECH-2023-0007","ljt-22ri-nl25","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I appreciate that OSTP and its National AI Initiative Office (NAIIO) have requested public information about artificial intelligence technology to inform the development of a National AI Strategy. Please find attached my detailed information in this regard.
Thank you.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0357/attachment_1.pdf",
"OSTP-TECH-2023-0007-0358","OSTP","OSTP-TECH-2023-0007","ljt-23p9-wlax","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0358/attachment_1.pdf",
"OSTP-TECH-2023-0007-0359","OSTP","OSTP-TECH-2023-0007","ljt-23wx-bqe0","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s), I have answered 1-10,12, 13, 17. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0359/attachment_1.txt,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0359/attachment_1.pdf",
"OSTP-TECH-2023-0007-0360","OSTP","OSTP-TECH-2023-0007","ljt-2560-dybd","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0360/attachment_1.pdf",
"OSTP-TECH-2023-0007-0361","OSTP","OSTP-TECH-2023-0007","ljt-258k-0a2t","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Attached please find Scale AI's comment. ",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0361/attachment_1.pdf",
"OSTP-TECH-2023-0007-0362","OSTP","OSTP-TECH-2023-0007","ljt-25jz-cbge","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0362/attachment_1.pdf",
"OSTP-TECH-2023-0007-0363","OSTP","OSTP-TECH-2023-0007","ljt-25od-2a4p","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0363/attachment_1.pdf",
"OSTP-TECH-2023-0007-0364","OSTP","OSTP-TECH-2023-0007","ljt-278a-glll","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0364/attachment_1.pdf",
"OSTP-TECH-2023-0007-0365","OSTP","OSTP-TECH-2023-0007","ljt-27mb-mteo","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please, find attached the comment of SaferAI to OSTP's request for comment.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0365/attachment_1.pdf",
"OSTP-TECH-2023-0007-0366","OSTP","OSTP-TECH-2023-0007","ljt-27oo-4w3k","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0366/attachment_1.pdf",
"OSTP-TECH-2023-0007-0367","OSTP","OSTP-TECH-2023-0007","ljt-27sw-ncji","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see attached comments from Stability AI.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0367/attachment_1.pdf",
"OSTP-TECH-2023-0007-0368","OSTP","OSTP-TECH-2023-0007","ljt-28le-vkfs","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hyperscience is a developer of enterprise software, designed to extract and digitally transform data using AI machine learning technology. We are proud to serve as a business process software solution for several federal agencies, and are grateful for the opportunity to share our vision for safe, trustworthy and ethical AI below. More information about our ethical AI program can be found at: https://hyperscience.com/about-us/ethical-ai/.

See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0368/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0368/attachment_1.pdf",
"OSTP-TECH-2023-0007-0369","OSTP","OSTP-TECH-2023-0007","ljt-2a10-i1f8","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0369/attachment_1.pdf",
"OSTP-TECH-2023-0007-0370","OSTP","OSTP-TECH-2023-0007","ljt-2a7y-jw9j","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am filing these comments on behalf of the Public Interest Privacy Center and Public Interest Privacy Consulting, LLC. Please feel free to reach out if you have any questions.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0370/attachment_1.pdf",
"OSTP-TECH-2023-0007-0371","OSTP","OSTP-TECH-2023-0007","ljt-2ab9-6kn4","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We appreciate the opportunity to provide input on the Office of Science and Technology Policy’s National Priorities for Artificial Intelligence Request for Information.  

Artificial intelligence (AI) is only beginning to proliferate across sectors. Today’s nascent AI startups will evolve into dominant players, creating new jobs and facilitating economic gains. We believe that AI startup founders and the investors who fund their growth are uniquely positioned to mitigate the potential harms posed by AI systems, starting at the earliest stages of product development and continuing as companies grow. 

Given the importance of AI, we have convened a multi-sector responsible AI working group composed of leading generative AI startup founders, technology platform executives, academics, members of civil society, and venture capitalists. Our work is focused on translating responsible AI principles and practices from the Federal Government and others to ensure they meet the needs of the burgeoning AI startup sector. 

We respectfully offer the comments below in response to the questions posed and remain  engaged to advance evidence-based policy discussions in partnership with early-stage AI startups and investors.

Sincerely, 

The Responsible Innovation Labs coalition of U.S. startups and venture capital firms committed to building a better technology industry
",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0371/attachment_1.pdf",
"OSTP-TECH-2023-0007-0372","OSTP","OSTP-TECH-2023-0007","ljt-2e10-kerk","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached comments",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0372/attachment_1.pdf",
"OSTP-TECH-2023-0007-0373","OSTP","OSTP-TECH-2023-0007","ljt-2xk2-xbdg","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0373/attachment_1.pdf",
"OSTP-TECH-2023-0007-0374","OSTP","OSTP-TECH-2023-0007","ljt-389d-awup","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please find attached comments from Stability AI.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0374/attachment_1.pdf",
"OSTP-TECH-2023-0007-0375","OSTP","OSTP-TECH-2023-0007","ljt-3tt8-ci72","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0375/attachment_1.pdf",
"OSTP-TECH-2023-0007-0376","OSTP","OSTP-TECH-2023-0007","ljt-4j7t-nw1b","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Ever since i was a little girl i always dreamed of being an artist. I spent over 15 years practicing hard and studying to get better at painting and drawing i missed out on lots of normal kid stuff because i was working so hard because my dream meant so much to me. Ai ‘art’ isn’t a computer making art it is a computer stealing the life’s work of millions of artists writers and musicians to then mash it all together and call it something ‘new’ and then use that stolen life’s work to make it impossible for the human artists it stole from to ever make a living with their skills again. It’s evil and dystopian to the extreme. Do you really want to live in a world where tech billionaires have their computers make all the art and humans have to work soul crushing minimum wage jobs? I never really thought about suicide until ai started to take over but now i think about it nearly every day and I’ve heard many other artists say the same. Some have even gone beyond just thinking about it. This isn’t the world i want to live in and i hope to god we can fix it. Ai should not be allowed to use our work without consent. Even an opt out system will not work because there are many dead artists who would have never agreed to this. The ai should only be allowed if they completely start from scratch and use only work with explicit permission from the original artist/creator. This is the only way unless you want to live in a world that’s even more cruel and soulless than it already is. Thank you so much for reading. ",,,,,,,
"OSTP-TECH-2023-0007-0377","OSTP","OSTP-TECH-2023-0007","ljt-4j7y-mbyy","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Ever since i was a little girl i always dreamed of being an artist. I spent over 15 years practicing hard and studying to get better at painting and drawing i missed out on lots of normal kid stuff because i was working so hard because my dream meant so much to me. Ai ‘art’ isn’t a computer making art it is a computer stealing the life’s work of millions of artists writers and musicians to then mash it all together and call it something ‘new’ and then use that stolen life’s work to make it impossible for the human artists it stole from to ever make a living with their skills again. It’s evil and dystopian to the extreme. Do you really want to live in a world where tech billionaires have their computers make all the art and humans have to work soul crushing minimum wage jobs? I never really thought about suicide until ai started to take over but now i think about it nearly every day and I’ve heard many other artists say the same. Some have even gone beyond just thinking about it. This isn’t the world i want to live in and i hope to god we can fix it. Ai should not be allowed to use our work without consent. Even an opt out system will not work because there are many dead artists who would have never agreed to this. The ai should only be allowed if they completely start from scratch and use only work with explicit permission from the original artist/creator. This is the only way unless you want to live in a world that’s even more cruel and soulless than it already is. Thank you so much for reading. ",,,,,,,
"OSTP-TECH-2023-0007-0378","OSTP","OSTP-TECH-2023-0007","ljt-483c-le5v","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0378/attachment_1.pdf",
"OSTP-TECH-2023-0007-0379","OSTP","OSTP-TECH-2023-0007","ljt-5fgh-y10v","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As a creative individual, the first thing that I believe should be recognized is that use of a person's creative work to train AI should not be allowed without explicit consent from that person. This would include - but is not limited to: visual art, vocal talent of any kind, music of any genre, any written work, and any other creative field that requires open ended problem solving. In addition, any user based website - especially those which users are primarily creative individuals - that incorporates AI training into their site, should have it be that the option to have their work used to train AI is OPT-IN ONLY. By no means should it be allowed that any user who signs up is by default opted-in, and there should be a very clear and straight forward feature that allows users to make that decision for themselves. 
Use of AI should also not cost anyone their job, nor should it be used as an alternative to hiring new employees; this refers to all jobs of any field, but especially those that require creative input of some kind. Any company that has previously switched to using AI to replace human labor should be required to show proof that the well-being of previous employees has not been diminished by this change, and/or those affected can contest to whether or not that is true. AI training should remain as a tool that can aid us, but not as a total replacement for humane problem solving; none should be allowed to use AI to present it as their own original work, and any such claim should be punishable in some capacity (ex. expulsion from university for plagiarism). 
Any use of AI to create visual art or written work should come with a mandatory watermark of some kind to show proof of its use, and there should be no option for a user to purchase removal of that watermark. Any use of AI to replicate vocal talent or music should be limited whereas it's clear that it has been generated by AI (ex. the voice sounding ""robotic"", generated music lasting no longer than a few measures), especially in the case of vocal replication to mitigate the spread of misinformation. Depending on the extent of AI use, one shouldn't be allowed to profit off work generated by it; if there was absolutely no human intervention at some point in the creative process, no profit should be made off it at all (simple approval of result should not be considered a part of the process).
Overall, use of AI should not replace the creative abilities of the human mind, should not close doors to those seeking work, and should not be trained to replicate work without the creator's EXPLICIT consent.

Thank you",,,,,,,
"OSTP-TECH-2023-0007-0380","OSTP","OSTP-TECH-2023-0007","ljt-54dq-dz2r","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comments attached.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0380/attachment_1.pdf",
"OSTP-TECH-2023-0007-0381","OSTP","OSTP-TECH-2023-0007","ljt-5b4r-8adi","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please see the attached file.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0381/attachment_1.pdf",
"OSTP-TECH-2023-0007-0382","OSTP","OSTP-TECH-2023-0007","ljt-6fce-gsrc","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"See attached file(s)",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0382/attachment_1.pdf",
"OSTP-TECH-2023-0007-0383","OSTP","OSTP-TECH-2023-0007","ljt-73nz-ceb7","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello, AI databases are from stolen works and should count as infringement. They are also being used to take jobs and positions from the people they stole from.",,,,,,,
"OSTP-TECH-2023-0007-0384","OSTP","OSTP-TECH-2023-0007","ljt-ba17-bfi9","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello, this is my comment on National Priorities for Artificial Intelligence

Training Ai on copyrighted content without the consent of the copyright holders is completely unethical and it is a violation of human rights.
 
Using the works of creators, artists, musicians or writers without their informed consent to use them for training Ai systems is completely unethical and is theft and infringement of intellectual property.

SAi's training should only be done in an ethical and moral manner, using only licensed or copyright-free content.

SAi training should only be allowed through state licenses, and every one or two year checks should be done by appointed specialists (but not specialists appointed by companies creating their own Ai)who they willcontrol and check the training datasets for any copyrighted content in the training data without the informed consent of the copyright holders.
Any violationsthey should be punishedpicking up license.

I havehope that the United Stateswill show world, very decisive actions to make the training of Ai moral and ethical and block all Ai systems trained on data theft.

Thank you for considering my requests.",,,,,,,
"OSTP-TECH-2023-0007-0385","OSTP","OSTP-TECH-2023-0007","ljt-cl96-eukj","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"DON'T IGNORE THIS COMMENT PLEASE
I don't know if the day is right (to some people say it's until today, but to me and other people say it's until tomorrow), but I'm gonna put my comment here anyway
My comment is on the file below",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0385/attachment_1.docx,https://downloads.regulations.gov/OSTP-TECH-2023-0007-0385/attachment_1.pdf",
"OSTP-TECH-2023-0007-0386","OSTP","OSTP-TECH-2023-0007","ljt-gv4h-rm7c","Public Submission",2023-10-30T04:00Z,false,,,"Comment on FR Doc # 2023-11346",,,false,OSTP-TECH-2023-0007-0001,,,,2023-07-07T04:00Z,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Please view the pdf attached for the full comment, as it exceeds the text box character limit. Thank you for your time.",,,,,,"https://downloads.regulations.gov/OSTP-TECH-2023-0007-0386/attachment_1.pdf",
